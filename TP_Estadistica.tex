% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Trabajo Práctico-- IECD},
  pdfauthor={Grupo 11},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Trabajo Práctico-- IECD}
\author{Grupo 11}
\date{2025-12-8}

\begin{document}
\maketitle

\section{Parte I: Test perfecto
(baseline)}\label{parte-i-test-perfecto-baseline}

\subsubsection{\texorpdfstring{1.1 Observe
\(T_{per} \sim Bi(n,\theta)\)}{1.1 Observe T\_\{per\} \textbackslash sim Bi(n,\textbackslash theta)}}\label{observe-t_per-sim-bintheta}

Consideremos una población en la que cada individuo puede estar o no
enfermo. Sea la prevalencia verdadera de la enfermedad

\[
\theta = P(Y = 1)
\]

donde \(Y\) es la variable aleatoria que indica el estado verdadero de
una persona. Esto es, \(Y = 1\) si la persona está enferma y \(Y = 0\)
si no lo está.

Se asume, por enunciado, que el test diagnóstico es perfecto, es decir,
tanto la sensibilidad como la especificidad valen uno (\(Se = Sp = 1\)).
En este caso, el resultado del test coincide exactamente con el estado
verdadero del individuo.

Sea \(Y_1, \dots, Y_n\) una muestra aleatoria de tamaño \(n\) tomada de
la población. Suponemos que las variables \(Y_1, \dots, Y_n\) son
independientes e idénticamente distribuidas, con

\[
Y_i \sim Bernoulli(\theta)\quad \text{con}\quad i = 1,\dots,n
\]

Definimos la variable aleatoria que cuenta cuántas personas enfermas hay
en la muestra como

\[
T_{per} = \sum_{i=1}^n Y_i.
\]

Dado que \(T_{per}\) es la suma de \(n\) variables independientes con
distribución Bernoulli\((\theta)\), se sigue que \(T_{per}\) tiene una
distribución binomial. En efecto, para \(k = 0,1,\dots,n\) se cumple que

\[
P(T_{per} = k)= \binom{n}{k}\theta^{k}(1-\theta)^{n-k}.
\]

Por lo tanto, concluimos que

\[
T_{\text{per}} \sim \mathrm{Binomial}(n,\theta).
\]

\(\hspace{16cm} \boxtimes\)

\subsubsection{\texorpdfstring{1.2 Estimador de Máxima Verosimilitud de
\(\theta\)}{1.2 Estimador de Máxima Verosimilitud de \textbackslash theta}}\label{estimador-de-muxe1xima-verosimilitud-de-theta}

Como en el punto anterior, recordemos que bajo un test perfecto se tiene

\[
T_{per} \sim Binomial(n,\theta)
\]

y que podemos representar los datos mediante variables Bernoulli

\[
Y_1,\dots,Y_n \sim i.i.d. Bernoulli(\theta),
\]

donde \(Y_i = 1\) si la persona \(i\) está enferma y \(Y_i = 0\) si no
lo está.

Sea \(N_1 = \sum_{i=1}^n Y_i\) la cantidad de individuos enfermos en la
muestra y \(N_0 = n - N_1\) la cantidad de individuos sanos.

La función de verosimilitud viene dada por

\[
L(\theta)= \prod_{i=1}^n \theta^{Y_i}(1-\theta)^{1-Y_i}= (1-\theta)^{N_0}\,\theta^{N_1}.
\]

La log-verosimilitud resulta entonces

\[
\ell(\theta) = \ln L(\theta)= N_0 \ln(1-\theta) + N_1 \ln(\theta).
\]

Buscamos \(\theta \in (0,1)\) tal que

\[
\frac{\partial \ell(\theta)}{\partial \theta} = 0.
\]

Derivando:

\[
\frac{\partial \ell(\theta)}{\partial \theta}= \frac{N_0}{1-\theta}(-1) + \frac{N_1}{\theta}= -\frac{N_0}{1-\theta} + \frac{N_1}{\theta}.
\]

Igualamos a cero:

\[
-\frac{N_0}{1-\theta} + \frac{N_1}{\theta} = 0 \quad \Longleftrightarrow \quad \frac{N_1}{\theta} = \frac{N_0}{1-\theta}.
\]

Despejando:

\[
N_1(1-\theta) = N_0 \theta \quad \Longleftrightarrow \quad N_1 - N_1\theta = N_0\theta
\]

\[
\Longleftrightarrow \quad N_1 = (N_0 + N_1)\theta = n\theta.
\]

Por lo tanto,

\[
\hat{\theta}_{EMV} = \frac{N_1}{n}.
\]

Finalmente, como \(N_1 = T_{per}\), obtenemos

\[
\hat{\theta}_{per} = \frac{T_{per}}{n}.
\]

La segunda derivada confirma que se trata de un máximo, ya que

\[
\frac{\partial^2 \ell(\theta)}{\partial \theta^2}= -\frac{N_0}{(1-\theta)^2} - \frac{N_1}{\theta^2} < 0,\quad \forall \theta \in (0,1).
\]

\(\hspace{16cm} \boxtimes\)

\subsubsection{1.3 Sesgo, Varianza, Error cuadrático medio, consistencia
y distribución
asintótica}\label{sesgo-varianza-error-cuadruxe1tico-medio-consistencia-y-distribuciuxf3n-asintuxf3tica}

\begin{itemize}
\item
  \textbf{Sesgo:}\\
  El estimador \(\hat{\theta}_{per} = \frac{T_{\text{per}}}{n}\) es
  insesgado porque \[
  \mathbb{E}[\hat{\theta}_{per}]
    = \mathbb{E}\left[\frac{T_{\text{per}}}{n}\right]
    = \frac{1}{n}\mathbb{E}[T_{\text{per}}]
    = \frac{n\theta}{n}
    = \theta.
  \] Usamos que \(T_{\text{per}} \sim \mathrm{Binomial}(n,\theta)\), por
  lo que \(\mathbb{E}[T_{\text{per}}] = n\theta\).
\item
  \textbf{Varianza:}\\
  \[
  \operatorname{Var}(\hat{\theta}_{per})
    = \operatorname{Var}\left(\frac{T_{\text{per}}}{n}\right)
    = \frac{1}{n^2}\operatorname{Var}(T_{\text{per}})
    = \frac{n\theta(1-\theta)}{n^2}
    = \frac{\theta(1-\theta)}{n}.
  \] También utilizamos que \(T_{\text{per}}\) es binomial.
\item
  \textbf{Error cuadrático medio (ECM):}\\
  Como el sesgo es cero, \[
  \text{ECM}(\hat{\theta}_{per})
    = \operatorname{Var}(\hat{\theta}_{per})
    + \mathbb{B}^2(\hat{\theta}_{per})
    = \frac{\theta(1-\theta)}{n}.
  \]
\item
  \textbf{Consistencia:}\\
  Observamos que
  \(\hat{\theta}_{per} = \frac{T_{\text{per}}}{n} = \frac{1}{n}\sum_{i=1}^n Y_i\),
  donde \(\mathbb{E}[Y_i] = \theta\) y
  \(\operatorname{Var}(Y_i)=\theta(1-\theta)\).\\
  Por la Ley Fuerte de los Grandes Números, \[
  \hat{\theta}_{per} \xrightarrow{c.s.} \theta.
  \] Por lo tanto, \(\hat{\theta}_{per}\) es \textbf{fuertemente
  consistente}.
\item
  \textbf{Distribución asintótica:}\\
  Por el Teorema Central del Límite, \[
  \sqrt{n}\,(\hat{\theta}_{per} - \theta)
  \xrightarrow{d} N\bigl(0,\theta(1-\theta)\bigr).
  \]
\end{itemize}

\subsubsection{\texorpdfstring{1.4 Intervalo de confianza para
\(\theta\).}{1.4 Intervalo de confianza para \textbackslash theta.}}\label{intervalo-de-confianza-para-theta.}

Sabemos que por TCL:

\[
\sqrt{n}\,\frac{(\hat{\theta}_{per} - \theta)}{\sqrt{\theta(1-\theta)}}
\xrightarrow{d} N\bigl(0,1\bigr).
\]

Además, por ley débil de los grandes números:

\[
\hat{\theta}_{per} \xrightarrow{p} \theta
\]

Entonces, combinando los resultados anteriores con Slutsky:

\[
\sqrt{n}\,\frac{(\hat{\theta}_{per} - \theta)}{\sqrt{\hat{\theta}_{per}(1-\hat{\theta}_{per})}}
\xrightarrow{d} N\bigl(0,1\bigr).
\]

Como \(P(Z\ge1.96) = 0.025\), vale lo siguiente:

\[
P\!\left(-1.96 \le \sqrt{n}\,\frac{\hat{\theta}_{per} - \theta}{\sqrt{\hat{\theta}_{per}(1-\hat{\theta}_{per})}} \le 1.96\right)
\xrightarrow[n\to\infty]{} 0.95.
\]

Finalmente, se deduce el siguiente intervalo de nivel asintótico 0.95:

\[
IC_{0.95}(\theta) = \hat{\theta}_{per} \pm 1.96\sqrt{\frac{\hat{\theta}_{per}(1-\hat{\theta}_{per})}{n}}
\]

\subsubsection{1.5 Cubrimiento
empírico.}\label{cubrimiento-empuxedrico.}

Para evaluar el cubrimiento empírico del intervalo dado en \(1.4\), se
llevó a cabo una simulación Monte Carlo para los siguientes valores de
n:

\[
10, 20, 50, 100, 1000, 10000
\]

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#fijamos la semilla que se va a utilizar durante todo el tp.}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{43}\NormalTok{)}

\NormalTok{tita }\OtherTok{\textless{}{-}} \FloatTok{0.25}
\NormalTok{ns }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{1000}\NormalTok{, }\DecValTok{10000}\NormalTok{) }\CommentTok{\#valores de n para los cuales vamos a evaluar la cobertura}
\NormalTok{Nrep }\OtherTok{\textless{}{-}} \DecValTok{5000}                          \CommentTok{\#empirica}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}

\NormalTok{cubrimientoN }\OtherTok{\textless{}{-}} \DecValTok{0}

\CommentTok{\#para cada n:}
\ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(ns))\{}
\NormalTok{  n }\OtherTok{\textless{}{-}}\NormalTok{ ns[j]}
\NormalTok{  cubrimiento }\OtherTok{\textless{}{-}} \DecValTok{0}
  
  \CommentTok{\#repito el experimento 5000 veces.}
  \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{Nrep)\{                                         }
\NormalTok{    muestra }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{,n,tita)}
    
\NormalTok{    estTita }\OtherTok{\textless{}{-}}\NormalTok{ muestra}\SpecialCharTok{/}\NormalTok{n}
\NormalTok{    termino }\OtherTok{\textless{}{-}}\NormalTok{ z }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{((estTita}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{estTita))}\SpecialCharTok{/}\NormalTok{n)}
\NormalTok{    intervalo }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(estTita }\SpecialCharTok{{-}}\NormalTok{ termino, estTita }\SpecialCharTok{+}\NormalTok{ termino)}
    
\NormalTok{    cubrimiento[i] }\OtherTok{\textless{}{-}}\NormalTok{ intervalo[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\textless{}=}\NormalTok{ tita }\SpecialCharTok{\&\&}\NormalTok{ tita }\SpecialCharTok{\textless{}=}\NormalTok{ intervalo[}\DecValTok{2}\NormalTok{]}
\NormalTok{  \}}
  
  \CommentTok{\#promedio de veces que el valor real de tita cayó en el intervalo}
\NormalTok{  cubrimientoN[j] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(cubrimiento)                  }
\NormalTok{\}}

\NormalTok{cubrimientoEmpirico }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{n =}\NormalTok{ ns, }\AttributeTok{cubrimiento =}\NormalTok{ cubrimientoN)}
\end{Highlighting}
\end{Shaded}

Y se obtuvieron estos resultados:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(cubrimientoEmpirico, }\AttributeTok{digits =} \DecValTok{4}\NormalTok{, }\AttributeTok{caption =} \StringTok{"Cubrimiento empírico del intervalo"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rr@{}}
\caption{Cubrimiento empírico del intervalo}\tabularnewline
\toprule\noalign{}
n & cubrimiento \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
n & cubrimiento \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
10 & 0.9232 \\
20 & 0.8992 \\
50 & 0.9362 \\
100 & 0.9462 \\
1000 & 0.9472 \\
10000 & 0.9486 \\
\end{longtable}

Los resultados obtenidos son coherentes con la teoría. Al tratarse de un
intervalo asintótico, el cubrimiento empírico converge hacia el nivel
nominal del 0.95 conforme aumenta el tamaño muestral n.

\section{\texorpdfstring{Parte II: Test imperfecto con \(S_{e}\) y
\(S_{p}\)
conocidos}{Parte II: Test imperfecto con S\_\{e\} y S\_\{p\} conocidos}}\label{parte-ii-test-imperfecto-con-s_e-y-s_p-conocidos}

\subsubsection{\texorpdfstring{2.0.1 Estimador \(\hat{p}\) de \(p\) con
\(T_{per}\)}{2.0.1 Estimador \textbackslash hat\{p\} de p con T\_\{per\}}}\label{estimador-hatp-de-p-con-t_per}

En esta parte definimos

\(\hspace{7cm} p = P(T = 1),\)

donde \(T\) denota el resultado del test diagnóstico aplicado a un
individuo: \(T = 1\) si el test da positivo y \(T = 0\) si el test da
negativo. Suponemos que

\(\hspace{7cm} T_1,\dots,T_n \sim i.i.d. Bernoulli(p),\)

de modo que \(P(T_i=1)=p\) y \(P(T_i=0)=1-p\) para todo \(i=1,\dots,n\).

Definimos la variable aleatoria

\(\hspace{7cm} T_{per} = \sum_{i=1}^n T_i,\)

que representa la cantidad de tests positivos observados en la muestra
de tamaño \(n\). Por ser suma de variables Bernoulli independientes con
parámetro \(p\), se tiene que

\(\hspace{7cm} T_{per} \sim Binomial(n,p).\)

Un estimador para \(p\) puede ser la proporción de individuos de la
muestra cuyo test dio positivo. Por lo tanto, definimos

\(\hspace{7cm} \hat p = \frac{T_{per}}{n}.\)

Este estimador coincide además con el estimador de máxima verosimilitud
(EMV) de \(p\) en el modelo binomial, ya que la función de verosimilitud

\(\hspace{7cm} L(p) \approx p^{T_{per}}(1-p)^{n-T_{per}}\)

se maximiza en \(p = T_{per}/n\).

\subsubsection{\texorpdfstring{2.0.2 Relación entre \(p\), \(\theta\),
\(Se\) y
\(Sp\)}{2.0.2 Relación entre p, \textbackslash theta, Se y Sp}}\label{relaciuxf3n-entre-p-theta-se-y-sp}

Recordemos que \(\theta = P(Y=1)\) denota la prevalencia de la
enfermedad en la población, mientras que \(Y=1\) indica que el individuo
está enfermo y \(Y=0\) que está sano. La sensibilidad y especificidad
del test diagnóstico se definen como \[
Se = P(T=1 \mid Y=1)\quad y \quad Sp = P(T=0 \mid Y=0),
\] donde \(T\) es el resultado del test (\(T=1\) si el test es positivo,
\(T=0\) si es negativo). Además, \(P(Y=1)=\theta\) y
\(P(Y=0)=1-\theta\).

La probabilidad de obtener un resultado positivo en el test es \[
p = P(T=1).
\] Aplicando la ley de probabilidad total, se tiene \[
P(T=1)
= P(T=1 \mid Y=1)P(Y=1) + P(T=1 \mid Y=0)P(Y=0).
\] Sustituyendo las definiciones previas, \[
p = Se \cdot \theta + P(T=1 \mid Y=0)\,(1-\theta).
\] Como \(Sp = P(T=0 \mid Y=0)\), se sigue que \[
P(T=1 \mid Y=0) = 1 - Sp.
\] Por lo tanto, \[
p = Se\,\theta + (1-Sp)(1-\theta).
\] Equivalentemente, podemos escribir \[
p(\theta,Se,Sp) = (Se + Sp - 1)\,\theta + (1-Sp).
\]

\subsubsection{\texorpdfstring{2.0.3 Comportamiento de \(p\) en función
de \(\theta\), \(Se\) y
\(Sp\).}{2.0.3 Comportamiento de p en función de \textbackslash theta, Se y Sp.}}\label{comportamiento-de-p-en-funciuxf3n-de-theta-se-y-sp.}

Se analiza cómo varía la probabilidad de obtener un resultado positivo
en el test diagnóstico, \[
p = P(T = 1),
\] cuando se modifican la prevalencia verdadera \(\theta\), la
sensibilidad \(Se\) y la especificidad \(Sp\) del test. Recordemos que,
a partir de la ley de probabilidad total, se obtuvo la relación \[
p(\theta,Se,Sp) = Se\,\theta + (1-Sp)(1-\theta).
\]

Trabajaremos con los valores de referencia indicados en el enunciado: \[
Se = 0.9, \qquad Sp = 0.95, \qquad \theta = 0.25,
\] y, en cada caso, variamos una de las cantidades manteniendo las otras
dos fijas.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Valores fijos}
\NormalTok{Se\_fijo  }\OtherTok{\textless{}{-}} \FloatTok{0.9}
\NormalTok{Sp\_fijo  }\OtherTok{\textless{}{-}} \FloatTok{0.95}
\NormalTok{theta\_fijo }\OtherTok{\textless{}{-}} \FloatTok{0.25}

\DocumentationTok{\#\# a}
\NormalTok{theta\_grid }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{1000}\NormalTok{)}
\NormalTok{p\_theta }\OtherTok{\textless{}{-}}\NormalTok{ Se\_fijo }\SpecialCharTok{*}\NormalTok{ theta\_grid }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp\_fijo) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta\_grid)}

\FunctionTok{plot}\NormalTok{(theta\_grid, p\_theta, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{,}
     \AttributeTok{xlab =} \FunctionTok{expression}\NormalTok{(theta),}
     \AttributeTok{ylab =} \StringTok{"p"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Probabilidad de test positivo vs. theta"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ theta\_fijo, }\AttributeTok{col =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ Se\_fijo }\SpecialCharTok{*}\NormalTok{ theta\_fijo }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp\_fijo) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta\_fijo),}
       \AttributeTok{col =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{TP_Estadistica_files/figure-latex/unnamed-chunk-3-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# b}
\NormalTok{Se\_grid }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{1000}\NormalTok{)}
\NormalTok{p\_Se }\OtherTok{\textless{}{-}}\NormalTok{ Se\_grid }\SpecialCharTok{*}\NormalTok{ theta\_fijo }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp\_fijo) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta\_fijo)}

\FunctionTok{plot}\NormalTok{(Se\_grid, p\_Se, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Se"}\NormalTok{,}
     \AttributeTok{ylab =} \StringTok{"p"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Probabilidad de test positivo vs. sensibilidad"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ Se\_fijo, }\AttributeTok{col =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ Se\_fijo }\SpecialCharTok{*}\NormalTok{ theta\_fijo }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp\_fijo) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta\_fijo),}
       \AttributeTok{col =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{TP_Estadistica_files/figure-latex/unnamed-chunk-3-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# c}
\NormalTok{Sp\_grid }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{1000}\NormalTok{)}
\NormalTok{p\_Sp }\OtherTok{\textless{}{-}}\NormalTok{ Se\_fijo }\SpecialCharTok{*}\NormalTok{ theta\_fijo }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp\_grid) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta\_fijo)}

\FunctionTok{plot}\NormalTok{(Sp\_grid, p\_Sp, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Sp"}\NormalTok{,}
     \AttributeTok{ylab =} \StringTok{"p"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Probabilidad de test positivo vs. especificidad"}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ Sp\_fijo, }\AttributeTok{col =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =}\NormalTok{ Se\_fijo }\SpecialCharTok{*}\NormalTok{ theta\_fijo }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp\_fijo) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta\_fijo),}
       \AttributeTok{col =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{TP_Estadistica_files/figure-latex/unnamed-chunk-3-3.pdf}}

\subparagraph{\texorpdfstring{\(\underline{\text{(a) $p$ en función de $\theta$ con $Se$ y $Sp$ fijos.}}\)}{\textbackslash underline\{\textbackslash text\{(a) \$p\$ en función de \$\textbackslash theta\$ con \$Se\$ y \$Sp\$ fijos.\}\}}}\label{underlinetexta-p-en-funciuxf3n-de-theta-con-se-y-sp-fijos.}

En primer lugar, consideramos la función \[
p(\theta) = Se\,\theta + (1-Sp)(1-\theta),
\] tomando \(Se = 0.9\) y \(Sp = 0.95\) fijos, y dejando variar la
prevalencia \(\theta\) en el intervalo \([0,1]\).

El gráfico correspondiente muestra que \(p(\theta)\) es una función
lineal y creciente de \(\theta\). Cuando \(\theta\) es muy pequeña
(prevalencias cercanas a cero), la probabilidad de test positivo se
aproxima al término de falsos positivos \((1-Sp)\); en este caso,
\(p(\theta) \approx 1 - Sp = 0.05\). A medida que aumenta \(\theta\), el
término asociado a verdaderos positivos \(Se\),\(\theta\) domina y
\(p(\theta)\) crece. En el extremo \(\theta = 1\), se tiene
\(p(1) = Se\), es decir, la probabilidad de test positivo coincide con
la sensibilidad del test.

El valor específico \(\theta = 0.25\) se destaca sobre la curva para
visualizar la probabilidad de test positivo asociada a esa prevalencia,
que es \[
p(0.25) = 0.9 \times 0.25 + (1 - 0.95)(1 - 0.25)
= 0.225 + 0.05 \times 0.75
= 0.2625.
\]

\subparagraph{\texorpdfstring{\(\underline{\text{(b) $p$ en función de $Se$ con $\theta$ y $Sp$ fijos.}}\)}{\textbackslash underline\{\textbackslash text\{(b) \$p\$ en función de \$Se\$ con \$\textbackslash theta\$ y \$Sp\$ fijos.\}\}}}\label{underlinetextb-p-en-funciuxf3n-de-se-con-theta-y-sp-fijos.}

A continuación, estudiamos \(p\) como función de la sensibilidad \(Se\),
manteniendo fijos \(\theta = 0.25\) y \(Sp = 0.95\). En este caso, \[
p(Se) = Se \,\theta + (1-Sp)(1-\theta)
= Se \cdot 0.25 + 0.05 \cdot 0.75.
\]

Esta expresión también es lineal y creciente en \(Se\). El gráfico
muestra que, cuando \(Se\) es muy baja, la contribución de verdaderos
positivos es pequeña y \(p(Se)\) se mantiene próxima al valor provocado
por falsos positivos. Al aumentar la sensibilidad, el test detecta
correctamente a una mayor proporción de individuos enfermos y, en
consecuencia, la probabilidad total de obtener un test positivo aumenta.

El valor de referencia \(Se = 0.9\) se marca en el eje horizontal, junto
con la altura \(p(Se=0.9)\) en el gráfico, para visualizar el punto
correspondiente en la curva.

\subparagraph{\texorpdfstring{\(\underline{\text{(c) $p$ en función de $Sp$ con $\theta$ y $Se$ fijos.}}\)}{\textbackslash underline\{\textbackslash text\{(c) \$p\$ en función de \$Sp\$ con \$\textbackslash theta\$ y \$Se\$ fijos.\}\}}}\label{underlinetextc-p-en-funciuxf3n-de-sp-con-theta-y-se-fijos.}

Finalmente, analizamos el comportamiento de \(p\) en función de la
especificidad \(Sp\), manteniendo fijos \(\theta = 0.25\) y
\(Se = 0.9\). En este caso \[
p(Sp) = Se\,\theta + (1-Sp)(1-\theta)
= 0.9 \cdot 0.25 + (1-Sp)\cdot 0.75.
\]

Aquí \(p(Sp)\) es una función lineal y \(decreciente\) en \(Sp\). El
gráfico muestra que, cuando la especificidad es baja (es decir, el test
comete muchos falsos positivos), el término \((1-Sp)(1-\theta)\) es
grande y la probabilidad total de test positivo \(p\) toma valores
elevados, incluso si la prevalencia real no es muy grande. A medida que
\(Sp\) aumenta, el número de falsos positivos disminuye y, en
consecuencia, la probabilidad de observar un test positivo se reduce.

El valor de referencia \(Sp = 0.95\) se indica sobre el eje horizontal,
junto con la altura \(p(Sp=0.95)\), lo cual permite comparar la
situación real del test con otros posibles niveles de especificidad.

\subsubsection{2.1.4 Estimador de momentos
(MoM).}\label{estimador-de-momentos-mom.}

Por item \(2.0.2\), sabemos que:

\[
p = S_{e} \theta + (1-S_{p})(1-\theta)
\]

Reagrupando: \[
p = (S_{e}+S_{p}-1)\theta + 1 - S_{p}
\]

Entonces: \[
\theta = \frac{p + S_{p} - 1}{S_{e}+S_{p}-1}
\]

Como \(\mathbb{E}[T_{i}] = p\), el estimador de momentos de \(p\) es
\(\hat{p}_{MoM} = \frac{T_{per}}{n}\). Finalmente, el estiamdor plug-in
de momentos de \(\theta\) es el siguiente:

\[
\hat{\theta}_{MoM} = \frac{\hat{p}_{MoM} + S_{p} - 1}{S_{e}+S_{p}-1}
\]

\subsubsection{2.1.5 Sesgo, varianza y
ECM.}\label{sesgo-varianza-y-ecm.}

\begin{itemize}
\item
  \textbf{Sesgo}:

  Primero se observa que:

  \[
  \mathbb{E}[\hat{p}_{MoM}] = \mathbb{E}\left[\frac{T_{\text{per}}}{n}\right]= p = (S_{e}+S_{p}-1)\theta + 1 - S_{p}
  \]

  Luego:

  \[
  \mathbb{E}[\hat{\theta}_{MoM}] = \mathbb{E}\left[\frac{\hat{p}_{MoM}+S_{p}-1}{S_{e}+S_{p}-1}\right] = \frac{\mathbb{E}[\hat{p}_{MoM}] + S_{p} - 1}{S_{e}+S_{p}-1} = \theta
  \]

  Por lo tanto \(\hat{\theta}_{MoM}\) es un estimador insesgado de
  \(\theta\).
\item
  \textbf{Varianza}:

  Primero se observa que:

  \[
  Var[\hat{p}_{MoM}] = Var\left[\frac{T_{\text{per}}}{n}\right]=\frac{np(1-p)}{n^2} = \frac{p(1-p)}{n}
  \]

  Luego:

  \[
  \operatorname{Var}[\hat{\theta}_{MoM}] = \operatorname{Var}\left[\frac{\hat{p}_{MoM}+S_{p}-1}{S_{e}+S_{p}-1}\right] = \frac{\operatorname{Var}[\hat{p}_{MoM} + S_{p} -1]}{(S_{e}+S_{p}-1)^2} = \frac{\operatorname{Var}[\hat{p}_{MoM}]}{(S_{e}+S_{p}-1)^2} = \frac{p(1-p)}{n(S_{e}+S_{p}-1)^2}
  \]
\item
  \textbf{ECM}:

  Como el sesgo es 0:

  \[
  \text{ECM}(\hat{\theta}_{MoM})
    = \operatorname{Var}[\hat{\theta}_{MoM}]
    + \mathbb{B}^2[\hat{\theta}_{MoM}]
    =\frac{p(1-p)}{n(S_{e}+S_{p}-1)^2}
  \]
\item
  \textbf{Consistencia}

  Observemos que, por ley fuerte de los grandes números:

  \[
  \hat{p}_{MoM} = \frac{T_{per}}{n} \xrightarrow{cs} p
  \]

  Luego, como \(\hat{\theta}_{MoM}\) es una función continua de
  \(\hat{p}_{MoM}\):

  \[
  \hat{\theta}_{MoM} \xrightarrow{cs} \frac{p + S_{p}-1}{S_{e}+S_{p}-1} = \theta
  \]

  Por lo tanto, \(\hat{\theta}_{MoM}\) es fuertemente consistente.
\end{itemize}

\subsubsection{2.1.6 ECM del test perfecto y test imprefecto en funcion
de n}\label{ecm-del-test-perfecto-y-test-imprefecto-en-funcion-de-n}

\begin{itemize}
\item
  \textbf{ECM del test perfecto e imperfecto:}

  Recordemos que el ECM del test perfecto es:

  \[
  \text{ECM}(\hat{\theta}_{per})
    = \frac{\theta(1-\theta)}{n}.
  \]

  Y el ECM del tets imperfecto es:

  \[
  \text{ECM}(\hat{\theta}_{MoM})
    = \frac{p(1-p)}{n(S_{e}+S_{p}-1)^2}
  \]
\end{itemize}

Podemos ver que el ECM del tets perfecto es mas chico que el del test
imperfecto gracias a un factor:

\[
  \frac{1}{(S_{e}+S_{p}-1)^2}
  \]

Lo que hace que con los valores anteriormente usados, \(Se = 0.9\),
\(Sp = 0.95\);

\[
Se + Sp - 1 = 0.85
\] Por lo tanto,

\[
  \frac{1}{0.85^2} \approx 1.38
  \]

Osea que \textbf{el ECM del test imperfecto es 38\% mas grande} que el
del test perfecto.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Parámetros}
\NormalTok{tita }\OtherTok{\textless{}{-}} \FloatTok{0.25}
\NormalTok{Se }\OtherTok{\textless{}{-}} \FloatTok{0.9}
\NormalTok{Sp }\OtherTok{\textless{}{-}} \FloatTok{0.95}

\CommentTok{\# p real del test imperfecto}
\NormalTok{p }\OtherTok{\textless{}{-}}\NormalTok{ (Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{tita }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp)}

\CommentTok{\# Rango de n}
\NormalTok{ns }\OtherTok{\textless{}{-}} \DecValTok{10}\SpecialCharTok{:}\DecValTok{1000}

\CommentTok{\# ECM del test perfecto}
\NormalTok{ECM\_perfecto }\OtherTok{\textless{}{-}}\NormalTok{ tita}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ tita) }\SpecialCharTok{/}\NormalTok{ ns}

\CommentTok{\# ECM del test imperfecto }
\NormalTok{ECM\_imperfecto }\OtherTok{\textless{}{-}}\NormalTok{ p}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p) }\SpecialCharTok{/}\NormalTok{ (ns }\SpecialCharTok{*}\NormalTok{ (Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}

\CommentTok{\# Gráfico}
\FunctionTok{plot}\NormalTok{(ns, ECM\_imperfecto,}
     \AttributeTok{type=}\StringTok{"l"}\NormalTok{, }\AttributeTok{col=}\StringTok{"orange"}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}
     \AttributeTok{xlab=}\StringTok{"n"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"ECM"}\NormalTok{,}
     \AttributeTok{main=}\StringTok{"ECM vs n: Test perfecto vs imperfecto"}\NormalTok{)}

\FunctionTok{lines}\NormalTok{(ns, ECM\_perfecto, }\AttributeTok{col=}\StringTok{"blue"}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{,}
       \AttributeTok{legend=}\FunctionTok{c}\NormalTok{(}\StringTok{"ECM test imperfecto"}\NormalTok{, }\StringTok{"ECM test perfecto"}\NormalTok{),}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"orange"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{TP_Estadistica_files/figure-latex/unnamed-chunk-4-1.pdf}}

Podemos ver que para todos los tamaños muestrales n, el ECM del test
imperfecto es mayor que el del test perfecto. A medida que n crece,
ambos ECM tienden a 0, pero el imperfecto siempre queda más arriba que
el perfecto. Cuanto más pequeño sea \(Se+Sp-1\) (es decir, cuanto peor
sea el test), mayor será la brecha entre las dos curvas.

\subsubsection{2.1.7 Comparo valores teoricos hallados con los
simulados}\label{comparo-valores-teoricos-hallados-con-los-simulados}

\paragraph{Comparación: valores teóricos vs simulados (test
imperfecto)}\label{comparaciuxf3n-valores-teuxf3ricos-vs-simulados-test-imperfecto}

Para el test imperfecto consideramos un modelo donde la variable
observada \(T\) proviene de un test con sensibilidad \(Se\) y
especificidad \(Sp\).

La probabilidad real de obtener un test positivo es:

\[
p = P(T = 1) = Se\,\theta + (1 - Sp)(1 - \theta),
\]

de modo que, para un tamaño muestral \(n\),

\[
T_1, \ldots, T_n \sim \text{Bernoulli}(p).
\]

El estimador de momentos para \(\theta\) es:

\[
\hat{\theta} = \frac{\hat{p}_T - (1 - Sp)}{Se + Sp - 1},
\qquad
\hat{p}_T = \frac{1}{n}\sum_{i=1}^n T_i.
\]

Para cada tamaño muestral\\
\[
n \in \{10,\,20,\,50,\,100,\,200\},
\] se simulan \(R = 10000\) réplicas de \(\hat{\theta}\).\\
A partir de ellas se estiman:

\begin{itemize}
\tightlist
\item
  el sesgo,\\
\item
  la varianza simulada,\\
\item
  el error cuadrático medio (ECM) simulado.
\end{itemize}

Además, la teoría indica que, como el estimador es insesgado, su
varianza es:

\[
\operatorname{Var}(\hat{\theta}) 
= \frac{p(1 - p)}{n(Se + Sp - 1)^2},
\]

y el ECM teórico coincide con la varianza teórica.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{R }\OtherTok{\textless{}{-}} \DecValTok{10000}
\NormalTok{ns }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{) }

\CommentTok{\# Función estimador de momentos}
\NormalTok{tita\_corregida }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(p\_hat, Se, Sp) \{}
\NormalTok{  (p\_hat }\SpecialCharTok{{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp)) }\SpecialCharTok{/}\NormalTok{ (Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\NormalTok{\}}

\CommentTok{\# resultados}
\NormalTok{resultados\_imp }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{n =}\NormalTok{ ns,}
  \AttributeTok{bias\_sim =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{var\_sim  =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{ecm\_sim  =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{var\_teo  =} \ConstantTok{NA}\NormalTok{,}
  \AttributeTok{ecm\_teo  =} \ConstantTok{NA}
\NormalTok{)}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(ns)) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}}\NormalTok{ ns[i]}
\NormalTok{  est\_imp }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(R)}

  \CommentTok{\# Probabilidad real del test positivo}
\NormalTok{  p\_Y }\OtherTok{\textless{}{-}}\NormalTok{ Se}\SpecialCharTok{*}\NormalTok{tita }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp)}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ tita)}

  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{R) \{}

    \CommentTok{\# 1) Genero la muestra de T correctamente}
\NormalTok{    T }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(n, }\DecValTok{1}\NormalTok{, p\_Y)}

    \CommentTok{\# 2) Estimador de momentos}
\NormalTok{    p\_hat }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(T)}
\NormalTok{    est\_imp[r] }\OtherTok{\textless{}{-}} \FunctionTok{tita\_corregida}\NormalTok{(p\_hat, Se, Sp)}
\NormalTok{  \}}

  \CommentTok{\# {-}{-}{-} Estadísticos simulados {-}{-}{-}}
\NormalTok{  bias\_sim }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(est\_imp) }\SpecialCharTok{{-}}\NormalTok{ tita}
\NormalTok{  var\_sim  }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(est\_imp)}
\NormalTok{  ecm\_sim  }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((est\_imp }\SpecialCharTok{{-}}\NormalTok{ tita)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}

  \CommentTok{\# {-}{-}{-} Valores teóricos {-}{-}{-}}
\NormalTok{  p\_true }\OtherTok{\textless{}{-}}\NormalTok{ p\_Y}
\NormalTok{  denom  }\OtherTok{\textless{}{-}}\NormalTok{ Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}
\NormalTok{  var\_teo }\OtherTok{\textless{}{-}}\NormalTok{ (p\_true}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_true)) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{*}\NormalTok{ denom}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{  ecm\_teo }\OtherTok{\textless{}{-}}\NormalTok{ var\_teo   }\CommentTok{\# insesgado}

  \CommentTok{\# {-}{-}{-} Guardar {-}{-}{-}}
\NormalTok{  resultados\_imp}\SpecialCharTok{$}\NormalTok{bias\_sim[i] }\OtherTok{\textless{}{-}}\NormalTok{ bias\_sim}
\NormalTok{  resultados\_imp}\SpecialCharTok{$}\NormalTok{var\_sim[i]  }\OtherTok{\textless{}{-}}\NormalTok{ var\_sim}
\NormalTok{  resultados\_imp}\SpecialCharTok{$}\NormalTok{ecm\_sim[i]  }\OtherTok{\textless{}{-}}\NormalTok{ ecm\_sim}
\NormalTok{  resultados\_imp}\SpecialCharTok{$}\NormalTok{var\_teo[i]  }\OtherTok{\textless{}{-}}\NormalTok{ var\_teo}
\NormalTok{  resultados\_imp}\SpecialCharTok{$}\NormalTok{ecm\_teo[i]  }\OtherTok{\textless{}{-}}\NormalTok{ ecm\_teo}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \textbf{Diferencia entre sesgo teorico y en la simulacion para
  distintos n}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# SESGO (teórico = 0)}
\FunctionTok{plot}\NormalTok{(resultados\_imp}\SpecialCharTok{$}\NormalTok{n, resultados\_imp}\SpecialCharTok{$}\NormalTok{bias\_sim,}
     \AttributeTok{type=}\StringTok{"b"}\NormalTok{, }\AttributeTok{pch=}\DecValTok{19}\NormalTok{,}
     \AttributeTok{xlab=}\StringTok{"n"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Sesgo"}\NormalTok{,}
     \AttributeTok{main=}\StringTok{"Sesgo: Simulado vs Teórico"}\NormalTok{,}
     \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(resultados\_imp}\SpecialCharTok{$}\NormalTok{bias\_sim), }\FunctionTok{max}\NormalTok{(resultados\_imp}\SpecialCharTok{$}\NormalTok{bias\_sim)))}

\CommentTok{\# línea de sesgo teórico = 0}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \DecValTok{0}\NormalTok{, }\AttributeTok{col=}\StringTok{"blue"}\NormalTok{, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{, }\AttributeTok{lty=}\DecValTok{2}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{,}
       \AttributeTok{legend=}\FunctionTok{c}\NormalTok{(}\StringTok{"Sesgo sim."}\NormalTok{, }\StringTok{"Sesgo teórico (0)"}\NormalTok{),}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{,}\StringTok{"blue"}\NormalTok{), }\AttributeTok{pch=}\FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{, }\ConstantTok{NA}\NormalTok{), }\AttributeTok{lty=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{TP_Estadistica_files/figure-latex/unnamed-chunk-6-1.pdf}}

\begin{itemize}
\tightlist
\item
  \textbf{Diferencia entre varianza teorica y en la simulacion para
  distintos n}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# VARIANZA}
\FunctionTok{plot}\NormalTok{(resultados\_imp}\SpecialCharTok{$}\NormalTok{n, resultados\_imp}\SpecialCharTok{$}\NormalTok{var\_sim,}
     \AttributeTok{type=}\StringTok{"b"}\NormalTok{, }\AttributeTok{pch=}\DecValTok{19}\NormalTok{,}
     \AttributeTok{xlab=}\StringTok{"n"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Varianza"}\NormalTok{,}
     \AttributeTok{main=}\StringTok{"Varianza: Simulado vs Teórica"}\NormalTok{,}
     \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{max}\NormalTok{(resultados\_imp}\SpecialCharTok{$}\NormalTok{var\_sim, resultados\_imp}\SpecialCharTok{$}\NormalTok{var\_teo)))}

\FunctionTok{lines}\NormalTok{(resultados\_imp}\SpecialCharTok{$}\NormalTok{n, resultados\_imp}\SpecialCharTok{$}\NormalTok{var\_teo,}
      \AttributeTok{type=}\StringTok{"b"}\NormalTok{, }\AttributeTok{pch=}\DecValTok{17}\NormalTok{, }\AttributeTok{col=}\StringTok{"blue"}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{,}
       \AttributeTok{legend=}\FunctionTok{c}\NormalTok{(}\StringTok{"Var sim."}\NormalTok{, }\StringTok{"Var teórica"}\NormalTok{),}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{,}\StringTok{"blue"}\NormalTok{), }\AttributeTok{pch=}\FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{,}\DecValTok{17}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{TP_Estadistica_files/figure-latex/unnamed-chunk-7-1.pdf}}

\begin{itemize}
\tightlist
\item
  \textbf{Diferencia entre ECM teorico y en la simulacion para distintos
  n}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# ECM}
\FunctionTok{plot}\NormalTok{(resultados\_imp}\SpecialCharTok{$}\NormalTok{n, resultados\_imp}\SpecialCharTok{$}\NormalTok{ecm\_sim,}
     \AttributeTok{type=}\StringTok{"b"}\NormalTok{, }\AttributeTok{pch=}\DecValTok{19}\NormalTok{,}
     \AttributeTok{xlab=}\StringTok{"n"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"ECM"}\NormalTok{,}
     \AttributeTok{main=}\StringTok{"ECM: Simulado vs Teórico"}\NormalTok{,}
     \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{max}\NormalTok{(resultados\_imp}\SpecialCharTok{$}\NormalTok{ecm\_sim, resultados\_imp}\SpecialCharTok{$}\NormalTok{ecm\_teo)))}

\FunctionTok{lines}\NormalTok{(resultados\_imp}\SpecialCharTok{$}\NormalTok{n, resultados\_imp}\SpecialCharTok{$}\NormalTok{ecm\_teo,}
      \AttributeTok{type=}\StringTok{"b"}\NormalTok{, }\AttributeTok{pch=}\DecValTok{17}\NormalTok{, }\AttributeTok{col=}\StringTok{"blue"}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{,}
       \AttributeTok{legend=}\FunctionTok{c}\NormalTok{(}\StringTok{"ECM sim."}\NormalTok{, }\StringTok{"ECM teórico"}\NormalTok{),}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{,}\StringTok{"blue"}\NormalTok{), }\AttributeTok{pch=}\FunctionTok{c}\NormalTok{(}\DecValTok{19}\NormalTok{,}\DecValTok{17}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{TP_Estadistica_files/figure-latex/unnamed-chunk-8-1.pdf}}

\textbf{Conclusiones }:

\begin{itemize}
\item
  Los valores simulados de varianza y ECM están muy cercanos a los
  valores teóricos para todos los tamaños muestrales considerados,
  confirmando la validez de las expresiones teóricas.
\item
  A medida que \(n\) aumenta, tanto la varianza simulada como el ECM
  tienden a disminuir y se aproximan fuertemente al valor teórico
  (convergencia concordante con la ley de los grandes números y la
  aproximación asintótica).
\item
  El sesgo empírico del estimador corregido es cercano a cero en todas
  las réplicas (coincidiendo con la insesgabilidad teórica).
\end{itemize}

\subsubsection{2.1.8 Muestras bootstrap para el estimador de
momentos}\label{muestras-bootstrap-para-el-estimador-de-momentos}

Para \(\theta = 0.25\), \(S_{e} = 0.9\) y \(S_{p} = 0.95\), construyo
muestras bootstrap para observar la distribución del estimador de
momentos de \(\theta\) cuando \(n = 10\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{10}     \CommentTok{\# tamaño de la muestra}
\NormalTok{B }\OtherTok{\textless{}{-}} \DecValTok{5000}   \CommentTok{\# cantidad de réplicas bootstrap}

\CommentTok{\# Probabilidad real de T = 1 bajo test imperfecto}
\NormalTok{p\_Y }\OtherTok{\textless{}{-}}\NormalTok{ Se }\SpecialCharTok{*}\NormalTok{ tita }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ tita)}

\CommentTok{\# Genero una muestra original de T}
\NormalTok{T }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(n, }\DecValTok{1}\NormalTok{, p\_Y)}

\CommentTok{\# Bootstrap no paramétrico}
\NormalTok{boot\_est }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(B)}

\ControlFlowTok{for}\NormalTok{ (b }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{B) \{}
\NormalTok{  T\_boot }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(T, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  p\_hat\_boot }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(T\_boot)}
\NormalTok{  boot\_est[b] }\OtherTok{\textless{}{-}} \FunctionTok{tita\_corregida}\NormalTok{(p\_hat\_boot, Se, Sp)}
\NormalTok{\}}

\CommentTok{\# Histograma}
\FunctionTok{hist}\NormalTok{(boot\_est, }\AttributeTok{breaks =} \DecValTok{15}\NormalTok{, }\AttributeTok{freq =} \ConstantTok{TRUE}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Distribución bootstrap del estimador de momentos (n = 10)"}\NormalTok{,}
     \AttributeTok{xlab =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{hat}\NormalTok{(theta)[}\StringTok{"bootstrap"}\NormalTok{]))}

\FunctionTok{abline}\NormalTok{(}\AttributeTok{v =}\NormalTok{ tita, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)  }\CommentTok{\# valor verdadero}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{TP_Estadistica_files/figure-latex/unnamed-chunk-9-1.pdf}}

La distribución bootstrap del estimador de momentos para \(n=10\)
muestra una alta dispersión, lo que muestra una fuerte inestabilidad del
estimador cuando el tamaño muestral es chico. Además, el centro de la
distribución bootstrap es mayor que el valor real de \(\theta\), lo que
indica la presencia de un sesgo positivo.

Estos resultados muestran que, con \(n=10\), el estimador es altamente
variable y poco confiable. Por lo tanto, se recomienda aumentar el
tamaño muestral para obtener una distribución más concentrada del
estimador. Con un n mayor, el estimador estaria más centrado alrededor
del valor real (\(\theta = 0.25\)) y su varianza disminuiría.

\subsubsection{2.2.9 Intervalos de confianza
bootstrap.}\label{intervalos-de-confianza-bootstrap.}

Se quiere calcular intervalos de confianza bootstrap para \(\theta\)
basandose en \(\hat{\theta}_{MoM}\). A partir de la técnica bootstrap no
paramétrico obtenemos \(1000\) estimaciones de \(\theta\) y para
construir el intervalo de confianza tomamos como límite inferior al
cuantil 0.025 y como límite superior al cuantil 0.975.

También se quieren realizar simulaciones, para evaluar el cubrimiento
empirico y la longitud promedio de los intervalos.

En el siguiente código se realiza lo mencionado anteriormente.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Definimos los valores a utilizar.}
\NormalTok{tita }\OtherTok{\textless{}{-}} \FloatTok{0.25}
\NormalTok{Se }\OtherTok{\textless{}{-}} \FloatTok{0.9}
\NormalTok{Sp }\OtherTok{\textless{}{-}} \FloatTok{0.95}
\NormalTok{p\_Y }\OtherTok{\textless{}{-}}\NormalTok{ Se }\SpecialCharTok{*}\NormalTok{ tita }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ tita)}

\NormalTok{ns }\OtherTok{\textless{}{-}}  \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{1000}\NormalTok{)}
\NormalTok{R }\OtherTok{\textless{}{-}} \DecValTok{700} \CommentTok{\#replicas Monte Carlo}
\NormalTok{B }\OtherTok{\textless{}{-}} \DecValTok{1000} \CommentTok{\#remuestreos bootstrap}

\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}

\NormalTok{res\_list }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{,}\FunctionTok{length}\NormalTok{(ns))}
\FunctionTok{names}\NormalTok{(res\_list) }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(ns)}

\CommentTok{\#para cada n:}
\ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(ns))\{}
\NormalTok{  n }\OtherTok{\textless{}{-}}\NormalTok{ ns[j]}
\NormalTok{  cubrimientos }\OtherTok{\textless{}{-}} \FunctionTok{logical}\NormalTok{(R)}
\NormalTok{  longitudes }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(R)}
  
  \CommentTok{\#repito el experimento R veces }
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{R)\{}
\NormalTok{     T }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(n,}\DecValTok{1}\NormalTok{,p\_Y)}
\NormalTok{     boot\_est }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(B)}
     
     \CommentTok{\#genero B muestras bootstrap.}
     \ControlFlowTok{for}\NormalTok{ (b }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{B)\{}
\NormalTok{       T\_boot }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(T, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{       p\_hat\_boot }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(T\_boot)}
\NormalTok{       boot\_est[b] }\OtherTok{\textless{}{-}} \FunctionTok{tita\_corregida}\NormalTok{(p\_hat\_boot, Se, Sp)}
\NormalTok{     \}}
     
\NormalTok{     lower }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(boot\_est, }\AttributeTok{probs =} \FloatTok{0.025}\NormalTok{, }\AttributeTok{names =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{     upper }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(boot\_est, }\AttributeTok{probs =} \FloatTok{0.975}\NormalTok{, }\AttributeTok{names =} \ConstantTok{FALSE}\NormalTok{)}
     
\NormalTok{     cubrimientos[r] }\OtherTok{\textless{}{-}}\NormalTok{ (lower }\SpecialCharTok{\textless{}=}\NormalTok{ tita) }\SpecialCharTok{\&\&}\NormalTok{ (tita }\SpecialCharTok{\textless{}=}\NormalTok{ upper)}
\NormalTok{     longitudes[r] }\OtherTok{\textless{}{-}}\NormalTok{ (upper }\SpecialCharTok{{-}}\NormalTok{ lower)}
\NormalTok{  \}}
  
  \CommentTok{\#resultados para cada n}
\NormalTok{  res\_list[[j]] }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{n =}\NormalTok{ n,}
    \AttributeTok{cubrimiento =} \FunctionTok{mean}\NormalTok{(cubrimientos),}
    \AttributeTok{longitud\_media =} \FunctionTok{mean}\NormalTok{(longitudes)}
\NormalTok{  )}
   
\NormalTok{\}}

\NormalTok{res\_df }\OtherTok{\textless{}{-}} \FunctionTok{do.call}\NormalTok{(rbind, }\FunctionTok{lapply}\NormalTok{(res\_list, }\ControlFlowTok{function}\NormalTok{(z)\{}
  \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{n =}\NormalTok{ z}\SpecialCharTok{$}\NormalTok{n,}
             \AttributeTok{cubrimiento =}\NormalTok{ z}\SpecialCharTok{$}\NormalTok{cubrimiento,}
             \AttributeTok{longitud\_media =}\NormalTok{ z}\SpecialCharTok{$}\NormalTok{longitud\_media)}
\NormalTok{\}))}
\FunctionTok{rownames}\NormalTok{(res\_df) }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\end{Highlighting}
\end{Shaded}

\subsubsection{2.2.10 Intervalo de confianza
asintótico.}\label{intervalo-de-confianza-asintuxf3tico.}

Recordemos que:

\begin{itemize}
\item
  \(\hat{p}_{MoM} = \frac{T_{per}}{n}\)
\item
  \(\mathbb{E}[\hat{p}_{MoM}] = p\)
\item
  \(\operatorname{Var}[\hat{p}_{MoM}] = \frac{p(1-p)}{n}\)
\item
  \(\hat{\theta}_{MoM} = \frac{\hat{p}_{MoM} + S_{p} - 1}{S_{e}+S_{p}-1}\)
\item
  \(\mathbb{E}[\hat{\theta}_{MoM}] = \theta\)
\item
  \(\operatorname{Var}[\hat{\theta}_{MoM}] = \frac{p(1-p)}{n(S_{e}+S_{p}-1)^2}\)
\end{itemize}

Entonces por TCL:

\[
\sqrt{n} (\hat{p}_{MoM} - p) \xrightarrow{D}  N\bigl(0,(p(1-p)\bigr)
\]

Defino \(g(x) = \frac{x+S_{p}-1}{S_{e}+S_{p}-1}\) y
\(g'(x) = \frac{1}{S_{e} + S_{p} -1}\). Notar que \(g(x)\) es \(C^1\).

Entonces, por Método Delta:

\[
\sqrt{n}(g(\hat{p}_{MoM}) - g(p)) \xrightarrow{D} N\bigl(0, \frac{p(1-p)}{(S_{e}+S_{p}-1)^2}\bigr)
\]

Luego,

\[
\frac{\hat{\theta}_{MoM}-\theta}{\sqrt{\operatorname{Var}[\hat{\theta}_{MoM}]}} \xrightarrow{D} N\bigl(0,1\bigr)
\]

Además \(\hat{p}_{MoM} = \frac{T_{per}}{n} \xrightarrow{cs} p\),
entonces:

\[ 
\sqrt{\frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{p(1-p)}} \xrightarrow{P} 1 
\]

debido a que \(h(x)= \sqrt{\frac{x(1-x)}{p(1-p)}}\) es continua en
\((0,1)\).

Si
\(\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}] =\frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{n(S_{e}+S_{p}-1)^2}\),
usando teorema de Slutsky:

\[
\frac{\hat{\theta}_{MoM} - \theta}{\sqrt{\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}]}} = \frac{\hat{\theta}_{MoM} - \theta}{\sqrt{\operatorname{Var}[\hat{\theta}_{MoM}]}\sqrt{\frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{p(1-p)}}} \xrightarrow{D}  N\bigl(0,1\bigr)
\]

Por lo tanto, se deduce el siguiente intervalo de nivel asintótico
\(0.95\).

\[
IC^{\theta}_{0.95} = \hat{\theta}_{MoM}\pm 1.96\sqrt{\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}]}
\]

En el siguiente código se calcula el intervalo asintótico mencionado y
se realizan simulaciones para evaluar cubrimiento empírico y longitud
promedio.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_listAsint }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\FunctionTok{length}\NormalTok{(ns))}
\FunctionTok{names}\NormalTok{(res\_listAsint) }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(ns)}

\CommentTok{\#para cada n:}
\ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(ns))\{}
\NormalTok{  n }\OtherTok{\textless{}{-}}\NormalTok{ ns[j]}
\NormalTok{  cubrimientos }\OtherTok{\textless{}{-}} \FunctionTok{logical}\NormalTok{(R)}
\NormalTok{  longitudes }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(R)}
  
  \CommentTok{\#repito el experimento R veces.}
  \ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{R)\{}
\NormalTok{    T }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(n, }\DecValTok{1}\NormalTok{, p\_Y)}
    
\NormalTok{    p\_hat }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(T)}
\NormalTok{    tita\_hat }\OtherTok{\textless{}{-}} \FunctionTok{tita\_corregida}\NormalTok{(p\_hat,Se,Sp)}
\NormalTok{    est\_Var }\OtherTok{\textless{}{-}}\NormalTok{ (p\_hat}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p\_hat))}\SpecialCharTok{/}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{(Se}\SpecialCharTok{+}\NormalTok{Sp}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
    
\NormalTok{    termino }\OtherTok{\textless{}{-}}\NormalTok{ z}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(est\_Var)}
\NormalTok{    lower }\OtherTok{\textless{}{-}}\NormalTok{ tita\_hat }\SpecialCharTok{{-}}\NormalTok{ termino}
\NormalTok{    upper }\OtherTok{\textless{}{-}}\NormalTok{ tita\_hat }\SpecialCharTok{+}\NormalTok{ termino}
    
\NormalTok{    cubrimientos[r] }\OtherTok{\textless{}{-}}\NormalTok{ (lower }\SpecialCharTok{\textless{}=}\NormalTok{ tita) }\SpecialCharTok{\&\&}\NormalTok{ (tita }\SpecialCharTok{\textless{}=}\NormalTok{ upper)}
\NormalTok{    longitudes[r] }\OtherTok{\textless{}{-}}\NormalTok{ (upper }\SpecialCharTok{{-}}\NormalTok{ lower)}
\NormalTok{  \}}
  
  \CommentTok{\#resultados para cada n.}
\NormalTok{  res\_listAsint[[j]] }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{n =}\NormalTok{ n,}
    \AttributeTok{cubrimiento =} \FunctionTok{mean}\NormalTok{(cubrimientos),}
    \AttributeTok{longitud\_media =} \FunctionTok{mean}\NormalTok{(longitudes)}
\NormalTok{  )}
\NormalTok{\}}

\NormalTok{resAsint\_df }\OtherTok{\textless{}{-}} \FunctionTok{do.call}\NormalTok{(rbind, }\FunctionTok{lapply}\NormalTok{(res\_listAsint, }\ControlFlowTok{function}\NormalTok{(z)\{}
  \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{n =}\NormalTok{ z}\SpecialCharTok{$}\NormalTok{n,}
             \AttributeTok{cubrimiento =}\NormalTok{ z}\SpecialCharTok{$}\NormalTok{cubrimiento,}
             \AttributeTok{longitud\_media =}\NormalTok{ z}\SpecialCharTok{$}\NormalTok{longitud\_media)}
\NormalTok{\}))}
\FunctionTok{rownames}\NormalTok{(resAsint\_df) }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\end{Highlighting}
\end{Shaded}

\subsubsection{2.2.11 Comparación entre ambos
intervalos.}\label{comparaciuxf3n-entre-ambos-intervalos.}

Comparemos los resultados obtenidos.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(res\_df, }\AttributeTok{digits =} \DecValTok{4}\NormalTok{, }\AttributeTok{caption =} \StringTok{"Bootstrap Percentil"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrr@{}}
\caption{Bootstrap Percentil}\tabularnewline
\toprule\noalign{}
n & cubrimiento & longitud\_media \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
n & cubrimiento & longitud\_media \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
10 & 0.9329 & 0.5680 \\
20 & 0.9186 & 0.4285 \\
50 & 0.9314 & 0.2782 \\
100 & 0.9429 & 0.2006 \\
1000 & 0.9514 & 0.0638 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(resAsint\_df, }\AttributeTok{digits =} \DecValTok{4}\NormalTok{, }\AttributeTok{caption =} \StringTok{"Intervalos Asintóticos"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrr@{}}
\caption{Intervalos Asintóticos}\tabularnewline
\toprule\noalign{}
n & cubrimiento & longitud\_media \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
n & cubrimiento & longitud\_media \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
10 & 0.9257 & 0.5930 \\
20 & 0.9186 & 0.4366 \\
50 & 0.9200 & 0.2836 \\
100 & 0.9414 & 0.2013 \\
1000 & 0.9457 & 0.0641 \\
\end{longtable}

\begin{itemize}
\item
  El bootstrap parece ser más robusto en muestras pequeñas, lo cual es
  esperable porque no depende de aproximaciones normales ni del método
  delta.
\item
  El método asintótico da intervalos ligeramente más largos.
\item
  A medida que aumenta \(n\) los resultados convergen a los valores
  esperados.
\end{itemize}

\subsubsection{2.3.12 Comportamiento del estimador de
momentos.}\label{comportamiento-del-estimador-de-momentos.}

Recordemos que el estimador de momentos de la prevalencia se obtiene
despejando \(\theta\) en la expresión \[
p = Se\,\theta + (1-Sp)(1-\theta),
\] y reemplazando \(p\) por su estimador \(\hat p = T_{\text{per}}/n\).
Esto produce \[
\hat{\theta}_{MoM}
= \frac{\hat p + S_{p} - 1}{S_{e}+S_{p}-1}.
\]

Si bien \(\hat p \in [0,1]\), la transformación anterior es lineal y
puede llevar a que el estimador resultante tome valores fuera del
intervalo válido para una probabilidad. En particular, \[
\hat{\theta}_{MoM} < 0
\quad\Longleftrightarrow\quad
\hat p < 1 - Sp,
\] lo cual ocurre en muestras donde se observan menos resultados
positivos de los esperados, mientras que \[
\hat{\theta}_{MoM} > 1
\quad\Longleftrightarrow\quad
\hat p > Se,
\] lo cual puede suceder cuando la muestra presenta un número
inusualmente alto de resultados positivos.

\subparagraph{\texorpdfstring{\(\underline{\text{Ejemplos numéricos}}\)}{\textbackslash underline\{\textbackslash text\{Ejemplos numéricos\}\}}}\label{underlinetextejemplos-numuxe9ricos}

Consideremos los valores utilizados en esta parte del trabajo: \[
Se = 0.9,\qquad Sp = 0.95.
\] Entonces, \[
1 - Sp = 0.05,
\qquad
Se + Sp - 1 = 0.85.
\]

\(\underline{\text{Ejemplo 1:}}\quad  \hat{\theta}_{MoM} < 0.\)

Si en una muestra particular no se observan resultados positivos,
entonces \[
\hat p = 0.
\] Reemplazando en la fórmula del estimador: \[
\hat{\theta}_{MoM}
   = \frac{0 + 0.95 - 1}{0.85}
   = \frac{-0.05}{0.85}
   \approx -0.0588.
\] En este caso, el estimador toma un valor negativo, aun cuando la
prevalencia real sea positiva.

\(\underline{\text{Ejemplo 2:}}\quad \hat{\theta}_{MoM} > 1.\)

Si por azar la muestra produce un valor muy alto de \(\hat p\), por
ejemplo \[
\hat p = 0.95,
\] entonces \[
\hat{\theta}_{MoM}
   = \frac{0.95 + 0.95 - 1}{0.85}
   = \frac{0.90}{0.85}
   \approx 1.0588.
\] En este caso, el estimador supera el valor máximo admisible para una
prevalencia.

Estos ejemplos ilustran que el estimador \(\hat{\theta}_{MoM}\) puede
ubicarse fuera de \([0,1]\) para ciertas muestras.

\subsubsection{2.3.13 Estudio del estimador
truncado}\label{estudio-del-estimador-truncado}

Recordemos que el estimador de momentos puede tomar valores fuera del
intervalo \([0,1]\). Para evitar esta situación, definimos el estimador
truncado como \[
\hat\theta_{\text{trunc}} =
\begin{cases}
\hat\theta_{\text{MoM}}, & 0 \le \hat\theta_{\text{MoM}} \le 1, \\[6pt]
0, & \hat\theta_{\text{MoM}} < 0, \\[6pt]
1, & \hat\theta_{\text{MoM}} > 1.
\end{cases}
\]

Este estimador coincide con \(\hat\theta_{\text{MoM}}\) en la región
central y recorta los valores imposibles asignándolos al borde del
intervalo.

Para estudiar sus propiedades, realizamos simulaciones Monte Carlo para
\(\theta = 0.25\), \(Se = 0.9\), \(Sp = 0.95\) y tamaños muestrales
\(n = 10, 100\) y \(1000\). En cada caso generamos \(N_{\text{rep}}\)
réplicas independientes, calculamos \(\hat\theta_{\text{trunc}}\) y
estimamos el sesgo, la varianza, el error cuadrático medio (ECM) y la
forma empírica de la distribución.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Parámetros}
\NormalTok{theta\_verdadera }\OtherTok{\textless{}{-}} \FloatTok{0.25}
\NormalTok{Se\_fijo         }\OtherTok{\textless{}{-}} \FloatTok{0.9}
\NormalTok{Sp\_fijo         }\OtherTok{\textless{}{-}} \FloatTok{0.95}

\CommentTok{\# Probabilidad verdadera de test positivo bajo el modelo}
\NormalTok{p\_verdadera }\OtherTok{\textless{}{-}}\NormalTok{ Se\_fijo }\SpecialCharTok{*}\NormalTok{ theta\_verdadera }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp\_fijo) }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta\_verdadera)}

\CommentTok{\# Número de réplicas para Monte Carlo}
\NormalTok{N\_rep }\OtherTok{\textless{}{-}} \DecValTok{10000}


\CommentTok{\# Funciones para los estimadores}

\CommentTok{\# Estimador de momentos de theta}
\NormalTok{theta\_mom }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(T\_obs, n, }\AttributeTok{Se =}\NormalTok{ Se\_fijo, }\AttributeTok{Sp =}\NormalTok{ Sp\_fijo) \{}
\NormalTok{  p\_muestral }\OtherTok{\textless{}{-}}\NormalTok{ T\_obs }\SpecialCharTok{/}\NormalTok{ n}
\NormalTok{  theta\_mom\_est }\OtherTok{\textless{}{-}}\NormalTok{ (p\_muestral }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(theta\_mom\_est)}
\NormalTok{\}}

\CommentTok{\# Estimador truncado de theta}
\NormalTok{theta\_trunc }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(T\_obs, n, }\AttributeTok{Se =}\NormalTok{ Se\_fijo, }\AttributeTok{Sp =}\NormalTok{ Sp\_fijo) \{}
\NormalTok{  theta\_mom\_est }\OtherTok{\textless{}{-}} \FunctionTok{theta\_mom}\NormalTok{(T\_obs, n, Se, Sp)}
\NormalTok{  theta\_trunc\_est }\OtherTok{\textless{}{-}} \FunctionTok{pmin}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{pmax}\NormalTok{(}\DecValTok{0}\NormalTok{, theta\_mom\_est))}
  \FunctionTok{return}\NormalTok{(theta\_trunc\_est)}
\NormalTok{\}}

\DocumentationTok{\#\# Tamaños muestrales a estudiar}
\NormalTok{n\_valores }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{1000}\NormalTok{)}

\DocumentationTok{\#\# Data frame para almacenar resultados}
\NormalTok{resultados }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{n     =}\NormalTok{ n\_valores,}
  \AttributeTok{media =} \ConstantTok{NA\_real\_}\NormalTok{,}
  \AttributeTok{sesgo =} \ConstantTok{NA\_real\_}\NormalTok{,}
  \AttributeTok{var   =} \ConstantTok{NA\_real\_}\NormalTok{,}
  \AttributeTok{ECM   =} \ConstantTok{NA\_real\_}
\NormalTok{)}



\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(n\_valores)) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}}\NormalTok{ n\_valores[i]}
  
  \CommentTok{\# Simular T\_obs \textasciitilde{} Binomial(n, p\_verdadera) N\_rep veces}
\NormalTok{  T\_sim }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(N\_rep, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{prob =}\NormalTok{ p\_verdadera)}
  
  \CommentTok{\# Estimaciones truncadas}
\NormalTok{  theta\_trunc\_sim }\OtherTok{\textless{}{-}} \FunctionTok{theta\_trunc}\NormalTok{(T\_sim, n)}
  
  \CommentTok{\# media}
\NormalTok{  media\_hat }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(theta\_trunc\_sim)}
  
  \CommentTok{\# sesgo}
\NormalTok{  sesgo\_hat }\OtherTok{\textless{}{-}}\NormalTok{ media\_hat }\SpecialCharTok{{-}}\NormalTok{ theta\_verdadera}
  
  \CommentTok{\# varianza}
\NormalTok{  var\_hat }\OtherTok{\textless{}{-}} \FunctionTok{var}\NormalTok{(theta\_trunc\_sim)}
  
  \CommentTok{\# ECM}
\NormalTok{  ECM\_hat }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((theta\_trunc\_sim }\SpecialCharTok{{-}}\NormalTok{ theta\_verdadera)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
  
  \CommentTok{\# resultados}
\NormalTok{  resultados}\SpecialCharTok{$}\NormalTok{media[i] }\OtherTok{\textless{}{-}}\NormalTok{ media\_hat}
\NormalTok{  resultados}\SpecialCharTok{$}\NormalTok{sesgo[i] }\OtherTok{\textless{}{-}}\NormalTok{ sesgo\_hat}
\NormalTok{  resultados}\SpecialCharTok{$}\NormalTok{var[i]   }\OtherTok{\textless{}{-}}\NormalTok{ var\_hat}
\NormalTok{  resultados}\SpecialCharTok{$}\NormalTok{ECM[i]   }\OtherTok{\textless{}{-}}\NormalTok{ ECM\_hat}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(resultados, }\AttributeTok{digits =} \DecValTok{9}\NormalTok{, }\AttributeTok{caption =} \StringTok{"Resultados"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrrrr@{}}
\caption{Resultados}\tabularnewline
\toprule\noalign{}
n & media & sesgo & var & ECM \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
n & media & sesgo & var & ECM \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
10 & 0.2485059 & -0.001494118 & 0.024626528 & 0.024626298 \\
100 & 0.2500482 & 0.000048235 & 0.002685104 & 0.002684837 \\
1000 & 0.2500671 & 0.000067059 & 0.000262917 & 0.000262895 \\
\end{longtable}

\subparagraph{\texorpdfstring{\(\underline{\text{Sesgo:}}\)}{\textbackslash underline\{\textbackslash text\{Sesgo:\}\}}}\label{underlinetextsesgo}

Para \(n=10\) el estimador presenta un sesgo notable. Esto se debe a que
el estimador de momentos frecuentemente cae por debajo de \(0\) y es
truncado a cero, lo cual desplaza el valor medio del estimador hacia la
región central del intervalo. A medida que el tamaño muestral aumenta,
la frecuencia de truncamientos disminuye y el sesgo se aproxima a cero.
En consecuencia, el estimador truncado es asintóticamente insesgado.

\subparagraph{\texorpdfstring{\(\underline{\text{Varianza:}}\)}{\textbackslash underline\{\textbackslash text\{Varianza:\}\}}}\label{underlinetextvarianza}

La varianza disminuye al crecer \(n\), como es esperable para un
estimador consistente. Para \(n=10\) la varianza es elevada debido a la
alta variabilidad de \(\hat p\), mientras que para \(n=1000\) el
estimador muestra muy poca dispersión.

\subparagraph{\texorpdfstring{\(\underline{\text{Error cuadrático medio:}}\)}{\textbackslash underline\{\textbackslash text\{Error cuadrático medio:\}\}}}\label{underlinetexterror-cuadruxe1tico-medio}

El ECM refleja el compromiso entre sesgo y varianza: \[
ECM = \operatorname{Sesgo}^2 + \operatorname{Var}.
\] Para tamaños muestrales pequeños, el ECM se ve afectado tanto por el
sesgo inducido por el truncamiento como por la alta varianza. Para
tamaños muestrales grandes, el ECM resulta muy pequeño, consistente con
la convergencia del estimador.

\subparagraph{\texorpdfstring{\(\underline{\text{Distribución asintótica:}}\)}{\textbackslash underline\{\textbackslash text\{Distribución asintótica:\}\}}}\label{underlinetextdistribuciuxf3n-asintuxf3tica}

Hacemos los siguientes gráficos para la distribución asintótica:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))  }\DocumentationTok{\#\# grid para los gráficos}

\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in}\NormalTok{ n\_valores) \{}
  \CommentTok{\# nueva data para cada n}
\NormalTok{  T\_sim }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(N\_rep, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{prob =}\NormalTok{ p\_verdadera)}
\NormalTok{  theta\_trunc\_sim }\OtherTok{\textless{}{-}} \FunctionTok{theta\_trunc}\NormalTok{(T\_sim, n)}
  
  \CommentTok{\# Histograma}
  \FunctionTok{hist}\NormalTok{(theta\_trunc\_sim,}
       \AttributeTok{breaks =} \DecValTok{40}\NormalTok{,}
       \AttributeTok{main =} \FunctionTok{paste}\NormalTok{(}\StringTok{"Histograma de theta\_trunc, n ="}\NormalTok{, n),}
       \AttributeTok{xlab =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{hat}\NormalTok{(theta)[trunc]),}
       \AttributeTok{probability =} \ConstantTok{TRUE}\NormalTok{)}
  
\NormalTok{  media\_hat }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(theta\_trunc\_sim)}
\NormalTok{  sd\_hat    }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(theta\_trunc\_sim)}
\NormalTok{  x\_grid    }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{200}\NormalTok{)}
  \FunctionTok{lines}\NormalTok{(x\_grid, }\FunctionTok{dnorm}\NormalTok{(x\_grid, }\AttributeTok{mean =}\NormalTok{ media\_hat, }\AttributeTok{sd =}\NormalTok{ sd\_hat), }\AttributeTok{col =} \StringTok{"red"}\NormalTok{)}
\NormalTok{\}}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{TP_Estadistica_files/figure-latex/unnamed-chunk-16-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{T\_sim }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(N\_rep, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{prob =}\NormalTok{ p\_verdadera)}
\NormalTok{theta\_trunc\_sim }\OtherTok{\textless{}{-}} \FunctionTok{theta\_trunc}\NormalTok{(T\_sim, n)}

\FunctionTok{qqnorm}\NormalTok{(theta\_trunc\_sim,}
       \AttributeTok{main =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"QQ{-}plot de "}\NormalTok{, }\FunctionTok{hat}\NormalTok{(theta)[trunc], }\StringTok{" para n=1000"}\NormalTok{)),}
       \AttributeTok{xlab=} \StringTok{""}\NormalTok{,}
       \AttributeTok{ylab=} \StringTok{""}\NormalTok{)}
\FunctionTok{qqline}\NormalTok{(theta\_trunc\_sim)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{TP_Estadistica_files/figure-latex/unnamed-chunk-16-2.pdf}}

Para \(n\) pequeños, la distribución empírica de
\(\hat\theta_{\text{trunc}}\) muestra acumulación de masa en los puntos
\(0\) y \(1\), debido al truncamiento. Por ello, la distribución no es
aproximadamente normal. Sin embargo, para \(n\) grandes el truncamiento
ocurre con probabilidad prácticamente nula, y la distribución empírica
se aproxima bien a una normal, coincidiendo en este caso con la
distribución asintótica del estimador de momentos no truncado.

En conjunto, estos resultados muestran que el truncamiento introduce
sesgo en muestras pequeñas, pero el estimador es asintóticamente
equivalente al estimador de momentos original, preservando sus
propiedades cuando \(n\) es grande.

\section{3 Parte III: Dos muestras (pre-post
intervención)}\label{parte-iii-dos-muestras-pre-post-intervenciuxf3n}

En esta sección analizamos si la prevalencia verdadera de la enfermedad
cambió después de implementar una campaña de vacunación. Para ello se
toman dos muestras independientes:

\begin{itemize}
\tightlist
\item
  Una \textbf{antes} de la campaña, de tamaño \(n_{\text{pre}}\), con
  número de test positivos \(X_{\text{pre}}\).
\item
  Otra \textbf{después}, de tamaño \(n_{\text{post}}\), con número de
  test positivos \(X_{\text{post}}\).
\end{itemize}

En ambos casos se utiliza el mismo test diagnóstico imperfecto,
caracterizado por su \textbf{sensibilidad} \(Se\) y
\textbf{especificidad} \(Sp\).

Los conteos observados siguen: \[
X_{\text{pre}} \sim \text{Binomial}(n_{\text{pre}}, p_{\text{pre}}), \quad 
X_{\text{post}} \sim \text{Binomial}(n_{\text{post}}, p_{\text{post}})
\] donde\\
\[
p_A = (Se + Sp - 1)\theta_A + (1 - Sp), \qquad A \in \{\text{pre}, \text{post}\}
\]

Nuestro objetivo es inferir la \textbf{diferencia de prevalencias
verdaderas}: \[
\Delta = \theta_{\text{post}} - \theta_{\text{pre}}
\]

\subsubsection{3.1.1 Test de Hipótesis.}\label{test-de-hipuxf3tesis.}

Se quiere plantear un test de nivel aproximado \(0.05\) para las
siguientes hipótesis, basandose en el estimador \(\hat{\theta}_{MoM}\):

\[
H_{0} : \Delta = 0 \quad \text{vs.} \quad H_{1} : \Delta
\]

Tenemos:

\[
\hat{\theta}_{post} = \frac{\hat{p}_{post} + S_{p} - 1}{S_{e}+S_{p}-1} \quad \text{y} \quad \hat{\theta}_{pre} = \frac{\hat{p}_{pre} + S_{p} - 1}{S_{e}+S_{p}-1}
\]

Y por el item \(2.1.10\), se deduce que:

\[
\hat{\theta}_{post} \approx N\bigl(\theta_{post},\; \widehat{\operatorname{Var}}(\hat{\theta}_{post})\bigr)
\quad\text{y}\quad
\hat{\theta}_{pre} \approx N\bigl(\theta_{pre},\; \widehat{\operatorname{Var}}(\hat{\theta}_{pre})\bigr)
\]

\[
\hat{\theta}_{post} - \hat{\theta}_{pre}
\approx
N\!\Bigl(\theta_{post}-\theta_{pre},\; \widehat{\operatorname{Var}}(\hat{\theta}_{post}) + \widehat{\operatorname{Var}}(\hat{\theta}_{pre})\Bigr)
\]

\[
U_{\Delta}(X_{pre},X_{post})
=
\frac{\hat{\theta}_{post} - \hat{\theta}_{pre} - \Delta}
     {\sqrt{\widehat{\operatorname{Var}}(\hat{\theta}_{post}) + \widehat{\operatorname{Var}}(\hat{\theta}_{pre})}}
\approx N(0,1)
\]

Tenemos un pivote decreciente en \(\Delta\) con distribución aproximada
conocida independiente de \(\Delta\). Entonces, utilizando método del
pivote, resulta el siguiente test de nivel aproximado 0.05.

\[
\Phi(X_{pre},X_{post}) =
\begin{cases}
1 & \text{si } \bigl|U_{0}(X_{pre},X_{post})\bigr| > z_{1-\alpha/2} = z_{0.975} \approx 1.96, \\
0 & \text{c.c.}
\end{cases}
\]

\subsubsection{3.1.2 Aplicación en caso
ficticio.}\label{aplicaciuxf3n-en-caso-ficticio.}

Vamos a aplicar el test dado en el item anterior a un caso ficticio con
\(n_{pre} = n_{post} = 100\), \(S_{e} = 0.9\), \(S_{p} = 0.95\),
\(\theta_{pre} = 0.2\), \(\theta_{post} = 0.15\) y \(\alpha = 0.05\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Definimos los valores.}
\NormalTok{n\_pre }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{n\_post }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{Se }\OtherTok{\textless{}{-}} \FloatTok{0.9}
\NormalTok{Sp }\OtherTok{\textless{}{-}} \FloatTok{0.95}
\NormalTok{tita\_pre }\OtherTok{\textless{}{-}} \FloatTok{0.2}
\NormalTok{tita\_post }\OtherTok{\textless{}{-}} \FloatTok{0.15}

\CommentTok{\#Calculamos p\_pre y p\_post:}

\NormalTok{p\_pre }\OtherTok{\textless{}{-}}\NormalTok{ (Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{ tita\_pre }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp)}
\NormalTok{p\_post }\OtherTok{\textless{}{-}}\NormalTok{ (Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{ tita\_post }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp)}


\CommentTok{\#Generamos ambas muestras (pre y post):}

\NormalTok{Xpre }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(n\_pre, }\DecValTok{1}\NormalTok{, p\_pre)}
\NormalTok{Xpost }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(n\_post, }\DecValTok{1}\NormalTok{, p\_post)}

\CommentTok{\#Ahora calculamos U(Xpre, Xpost):}
\NormalTok{p\_preHat }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Xpre)}
\NormalTok{p\_postHat }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Xpost)}

\NormalTok{tita\_preHat }\OtherTok{\textless{}{-}}\NormalTok{ (p\_preHat }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\NormalTok{tita\_postHat }\OtherTok{\textless{}{-}}\NormalTok{ (p\_postHat }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}

\NormalTok{Var\_preHat }\OtherTok{\textless{}{-}}\NormalTok{ (p\_preHat}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p\_preHat))}\SpecialCharTok{/}\NormalTok{(n\_pre}\SpecialCharTok{*}\NormalTok{(Se}\SpecialCharTok{+}\NormalTok{Sp}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{Var\_postHat }\OtherTok{\textless{}{-}}\NormalTok{ (p\_postHat}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p\_postHat))}\SpecialCharTok{/}\NormalTok{(n\_post}\SpecialCharTok{*}\NormalTok{(Se}\SpecialCharTok{+}\NormalTok{Sp}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}


\NormalTok{U }\OtherTok{\textless{}{-}}\NormalTok{ (tita\_postHat }\SpecialCharTok{{-}}\NormalTok{ tita\_preHat)}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(Var\_postHat }\SpecialCharTok{+}\NormalTok{ Var\_preHat))}
\end{Highlighting}
\end{Shaded}

El estadístico observado tiene el siguiente valor:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{U}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.3414939
\end{verbatim}

Por lo tanto, no hay evidencia suficiente como para rechazar \(H_{0}\) a
nivel aproximado 0.05. Esto quiere decir que no se afirma que la vacuna
es realmente efectiva. Es razonable porque la diferencia real entre
prevalencias es pequeña (\(0.05\)).

\begin{itemize}
\tightlist
\item
  ¿Qué pasa si se achica la muestra? A continuación se realizan las
  mismas simulaciones variando n.
\end{itemize}

Observemos que pasa para \(n = 50\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{U50}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.162476
\end{verbatim}

El valor del estadístico observado sigue estando en la región de
aceptación. Igualmente, al haber menos muestras la varianza aumenta y el
resultado es distinto de 0.

Y ahora con \(n = 10\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{U10}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.5198752
\end{verbatim}

Para una muestra tan pequeña el test se vuelve inestable y es
practicamente inútil, ya que nuetsro test es de nivel asintótico.

\subsubsection{\texorpdfstring{3.1.3 Intervalo de confianza de nivel
asintotico 0.95 para
\(\Delta\).}{3.1.3 Intervalo de confianza de nivel asintotico 0.95 para \textbackslash Delta.}}\label{intervalo-de-confianza-de-nivel-asintotico-0.95-para-delta.}

Usamos el estimador de momentos (no truncado):

\[
\hat\theta_A \;=\; \frac{\hat p_A + (Sp - 1)}{Se + Sp - 1}, 
\qquad A \in \{\text{pre}, \text{post}\},
\]

donde \(\hat p_A = X_A / n_A\) y \(X_A\) es el número de tests positivos
observados.

El pivote utilizado es:

\[
Z \;=\; 
\frac{
\widehat{\Delta} - \Delta
}{
\sqrt{
\widehat{Var}(\hat\theta_{\text{post}}) +
\widehat{Var}(\hat\theta_{\text{pre}})
}
},
\]

el cual tiene distribución aproximada \(N(0,1)\).

El intervalo de confianza asintótico al 95\% para la diferencia

\[
\Delta = \theta_{\text{post}} - \theta_{\text{pre}}
\]

es

\[
\widehat{\Delta} \;\pm\;
1.96 \sqrt{
\widehat{Var}(\hat\theta_{\text{post}}) +
\widehat{Var}(\hat\theta_{\text{pre}})
}.
\]

donde
\(\widehat{\Delta} = \hat\theta_{\text{post}} - \hat\theta_{\text{pre}}\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Estimador de Delta y su desvío estándar}
\NormalTok{DeltaHat }\OtherTok{\textless{}{-}}\NormalTok{ tita\_postHat }\SpecialCharTok{{-}}\NormalTok{ tita\_preHat}
\NormalTok{se\_Delta }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(Var\_preHat }\SpecialCharTok{+}\NormalTok{ Var\_postHat)}

\CommentTok{\# Intervalo asintotico 95\%}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}
\NormalTok{IC\_lower }\OtherTok{\textless{}{-}}\NormalTok{ DeltaHat }\SpecialCharTok{{-}}\NormalTok{ z }\SpecialCharTok{*}\NormalTok{ se\_Delta}
\NormalTok{IC\_upper }\OtherTok{\textless{}{-}}\NormalTok{ DeltaHat }\SpecialCharTok{+}\NormalTok{ z }\SpecialCharTok{*}\NormalTok{ se\_Delta}

\FunctionTok{cat}\NormalTok{(}\StringTok{"DeltaHat ="}\NormalTok{, }\FunctionTok{round}\NormalTok{(DeltaHat, }\DecValTok{4}\NormalTok{), }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## DeltaHat = 0.1176
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"IC 95\% para Delta: ["}\NormalTok{, }\FunctionTok{round}\NormalTok{(IC\_lower, }\DecValTok{4}\NormalTok{), }\StringTok{","}\NormalTok{, }\FunctionTok{round}\NormalTok{(IC\_upper, }\DecValTok{4}\NormalTok{), }\StringTok{"]}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## IC 95% para Delta: [ -0.3259 , 0.5612 ]
\end{verbatim}

Con los datos simulados, el intervalo calculado fue:

\[
IC_{95\%}(\Delta)
=
[-0.3259,\; 0.5612].
\]

Podemos ver que el intervalo incluye al 0, por lo tanto no hay evidencia
suficiente para decir que hay un cambio real entre pre y post. El
intervalo es bastante ancho, se puede decir que hay alta incertidumbre.
Pero podemos ver tambien que el limite superior es bastante grande
(\(\approx 0.50\)) lo cual muestra que con nuestros datos todavia es
posible un aumento grande entre pre y post. Y como el limite inferior es
negativo tambien puede haber una disminucion moderada.

\subsubsection{3.1.4 Nivel empírico del
test.}\label{nivel-empuxedrico-del-test.}

Se quiere calcular el nivel empírico del test dado en \(3.1.2\). Para
ello, se define una grilla de valores de \(n\) para calcular el nivel
para cada valor. Se sabe que el nivel de un test está definido por el
supremo de los errores de tipo 1. Entonces, también se define una grilla
de valores de \(\theta\) y se realizan las simulaciones pertinentes.
Este proceso se encuentra en el código siguiente.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Definimos los valores a utilizar.}
\NormalTok{Nrep }\OtherTok{\textless{}{-}} \DecValTok{2000}
\NormalTok{ns }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{1000}\NormalTok{, }\DecValTok{10000}\NormalTok{)}
\NormalTok{alpha }\OtherTok{\textless{}{-}} \FloatTok{0.05}
\NormalTok{Se }\OtherTok{\textless{}{-}} \FloatTok{0.9}
\NormalTok{Sp }\OtherTok{\textless{}{-}} \FloatTok{0.95}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{)}

\CommentTok{\# Como queremos nivel, definimos prevalencias iguales para pre y post (H0 delta = 0).}
\CommentTok{\#Además queremos el supremo de los errores de tipo 1, entonces hay que variar tita.}
\NormalTok{grid\_tita }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\FloatTok{0.99}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{20}\NormalTok{)}
  

\CommentTok{\#Vector que va a tener el nivel empírico para cada n.}
\NormalTok{nivelN }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\FunctionTok{length}\NormalTok{(ns))}


\CommentTok{\#para cada n:}
\ControlFlowTok{for}\NormalTok{ (r }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(ns))\{}
\NormalTok{  n }\OtherTok{\textless{}{-}}\NormalTok{ ns[r]}
  
  \CommentTok{\#vector que va a tener error de tipo 1 para cada tita.}
\NormalTok{  errorTipo1 }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\FunctionTok{length}\NormalTok{(grid\_tita))}
  
  \CommentTok{\#para cada tita:}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(grid\_tita))\{}
\NormalTok{    tita }\OtherTok{\textless{}{-}}\NormalTok{ grid\_tita[j]}
\NormalTok{    p }\OtherTok{\textless{}{-}}\NormalTok{ (Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{ tita }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ Sp)}
    
    \CommentTok{\#vector que va a tener si rechazo o no el test en cada pos.}
\NormalTok{    rechazos }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(Nrep)}
    
    \CommentTok{\#repito el experimento Nrep veces:}
    \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{Nrep)\{                                        }
\NormalTok{      Xpre }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(n,}\DecValTok{1}\NormalTok{,p)}
\NormalTok{      Xpost }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(n,}\DecValTok{1}\NormalTok{,p)}
      
      \CommentTok{\#Ahora calculamos U(Xpre, Xpost):}
\NormalTok{      p\_preHat }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Xpre)}
\NormalTok{      p\_postHat }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Xpost)}
      
\NormalTok{      tita\_preHat }\OtherTok{\textless{}{-}}\NormalTok{ (p\_preHat }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\NormalTok{      tita\_postHat }\OtherTok{\textless{}{-}}\NormalTok{ (p\_postHat }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{/}\NormalTok{(Se }\SpecialCharTok{+}\NormalTok{ Sp }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
      
\NormalTok{      Var\_preHat }\OtherTok{\textless{}{-}}\NormalTok{ (p\_preHat}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p\_preHat))}\SpecialCharTok{/}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{(Se}\SpecialCharTok{+}\NormalTok{Sp}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{      Var\_postHat }\OtherTok{\textless{}{-}}\NormalTok{ (p\_postHat}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{p\_postHat))}\SpecialCharTok{/}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{(Se}\SpecialCharTok{+}\NormalTok{Sp}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
      
\NormalTok{      U }\OtherTok{\textless{}{-}}\NormalTok{ (tita\_postHat }\SpecialCharTok{{-}}\NormalTok{ tita\_preHat)}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(Var\_postHat }\SpecialCharTok{+}\NormalTok{ Var\_preHat)) }
      
      \CommentTok{\#rechazo o no H0.}
\NormalTok{      rechazos[i] }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(U) }\SpecialCharTok{\textgreater{}}\NormalTok{ z}
\NormalTok{    \}}
    
    \CommentTok{\#proporción de rechazos.(ignoro nan en caso de que el p estimado sea 0 o 1 }
    \CommentTok{\#pues sucede un div por 0)}
\NormalTok{    errorTipo1[j] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(rechazos, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)                    }
    
\NormalTok{  \}}
  
\NormalTok{  nivelN[r] }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(errorTipo1)}
\NormalTok{\}}

\NormalTok{nivelEmpirico }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{n =}\NormalTok{ ns, }\AttributeTok{nivel =}\NormalTok{ nivelN)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(nivelEmpirico, }\AttributeTok{digits =} \DecValTok{4}\NormalTok{, }\AttributeTok{caption =} \StringTok{"Nivel empírico del test"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rr@{}}
\caption{Nivel empírico del test}\tabularnewline
\toprule\noalign{}
n & nivel \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
n & nivel \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
10 & 0.1098 \\
20 & 0.0895 \\
50 & 0.0650 \\
100 & 0.0585 \\
1000 & 0.0570 \\
10000 & 0.0595 \\
\end{longtable}

Se observa claramente el comportamiento asintótico del test. A medida
que aumenta n, el nivel del test se acerca a 0.05.

\end{document}
