---
title: "Trabajo Práctico – IECD"
author: "Grupo 11"
date: "2025-12-08"
output:
  beamer_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introducción

## Objetivo del trabajo

Análisis de propiedades estadísticas de tests diagnósticos:

1. **Test perfecto** (baseline)
2. **Test imperfecto** con $S_e$ y $S_p$ conocidos  
3. **Dos muestras** (pre-post intervención)

---

\centering
\vspace{2cm}
\Huge
**Parte I**  
\Large
Test perfecto (baseline)

---

## 1.1 Distribución de $T_{per}$

### Contexto
- Población con prevalencia $\theta = P(Y=1)$
- Test perfecto: $Se = Sp = 1$
- $Y_i \sim \text{Bernoulli}(\theta)$, i.i.d.

### Variable de interés
$$T_{per} = \sum_{i=1}^n Y_i$$

### Distribución
$$T_{per} \sim \text{Binomial}(n,\theta)$$

$$\boxed{P(T_{per} = k) = \binom{n}{k}\theta^{k}(1-\theta)^{n-k}}$$

---

## 1.2 Estimador de Máxima Verosimilitud

### Función de verosimilitud
$$L(\theta) = \prod_{i=1}^n \theta^{Y_i}(1-\theta)^{1-Y_i} = (1-\theta)^{N_0}\,\theta^{N_1}$$

### Log-verosimilitud
$$\ell(\theta) = N_0 \ln(1-\theta) + N_1 \ln(\theta)$$

### Estimador EMV
$$\hat{\theta}_{per} = \frac{N_1}{n} = \frac{T_{per}}{n}$$

---

## 1.3 Sesgo, Varianza, Error cuadrático medio, consistencia y distribución asintótica

* **Sesgo:**  
  El estimador \(\hat{\theta}_{per} = \frac{T_{\text{per}}}{n}\) es insesgado porque
  \[
  \mathbb{E}[\hat{\theta}_{per}]
    = \mathbb{E}\left[\frac{T_{\text{per}}}{n}\right]
    = \frac{1}{n}\mathbb{E}[T_{\text{per}}]
    = \frac{n\theta}{n}
    = \theta.
  \]
  Usamos que \(T_{\text{per}} \sim \mathrm{Binomial}(n,\theta)\), por lo que  \(\mathbb{E}[T_{\text{per}}] = n\theta\).

---

* **Varianza:**  
  \[
  \operatorname{Var}(\hat{\theta}_{per})
    = \operatorname{Var}\left(\frac{T_{\text{per}}}{n}\right)
    = \frac{1}{n^2}\operatorname{Var}(T_{\text{per}})
    = \frac{n\theta(1-\theta)}{n^2}
    = \frac{\theta(1-\theta)}{n}.
  \]
  También utilizamos que \(T_{\text{per}}\) es binomial.
  
\vspace{0.5cm}

* **Error cuadrático medio (ECM):**  
  Como el sesgo es cero,
  \[
  \text{ECM}(\hat{\theta}_{per})
    = \operatorname{Var}(\hat{\theta}_{per})
    + \mathbb{B}^2(\hat{\theta}_{per})
    = \frac{\theta(1-\theta)}{n}.
  \]

---

* **Consistencia:**  
  Observamos que \(\hat{\theta}_{per} = \frac{T_{\text{per}}}{n} = \frac{1}{n}\sum_{i=1}^n Y_i\),  
  donde \(\mathbb{E}[Y_i] = \theta\) y \(\operatorname{Var}(Y_i)=\theta(1-\theta)\).  
  Por la Ley Fuerte de los Grandes Números,
  \[
  \hat{\theta}_{per} \xrightarrow{c.s.} \theta.
  \]
  Por lo tanto, \(\hat{\theta}_{per}\) es **fuertemente consistente**.

\vspace{0.5cm}

* **Distribución asintótica:**  
  Por el Teorema Central del Límite,
  \[
  \sqrt{n}\,(\hat{\theta}_{per} - \theta)
  \xrightarrow{d} N\bigl(0,\theta(1-\theta)\bigr).
  \]

---

## 1.4 Intervalo de confianza para $\theta$

* Sabemos que por TCL:

\[
\sqrt{n}\,\frac{(\hat{\theta}_{per} - \theta)}{\sqrt{\theta(1-\theta)}}
\xrightarrow{d} N\bigl(0,1\bigr).
\]

* Además, por ley débil de los grandes números:

\[
\hat{\theta}_{per} \xrightarrow{p} \theta
\]

---

* Entonces, combinando los resultados anteriores con Slutsky:

\[
\sqrt{n}\,\frac{(\hat{\theta}_{per} - \theta)}{\sqrt{\hat{\theta}_{per}(1-\hat{\theta}_{per})}}
\xrightarrow{d} N\bigl(0,1\bigr).
\]

Como $P(Z\ge1.96) = 0.025$, vale lo siguiente:

\[
P\!\left(-1.96 \le \sqrt{n}\,\frac{\hat{\theta}_{per} - \theta}{\sqrt{\hat{\theta}_{per}(1-\hat{\theta}_{per})}} \le 1.96\right)
\xrightarrow[n\to\infty]{} 0.95.
\]

---

* Finalmente, se deduce el siguiente intervalo de nivel asintótico 0.95:

\[
\boxed{IC_{0.95}(\theta) = \hat{\theta}_{per} \pm 1.96\sqrt{\frac{\hat{\theta}_{per}(1-\hat{\theta}_{per})}{n}}}
\]

---

## 1.5 Cubrimiento empírico

* Para evaluar el cubrimiento empírico del intervalo dado en $1.4$, se llevó a cabo una simulación Monte Carlo para los siguientes valores de n:

\[
10, 20, 50, 100, 1000, 10000
\]


```{r, echo=FALSE, eval=TRUE, size="tiny"}
#fijamos la semilla que se va a utilizar durante todo el tp.
set.seed(43)

tita <- 0.25
ns <- c(10, 20, 50, 100, 1000, 10000) #valores de n para los cuales vamos a evaluar la cobertura
Nrep <- 5000                          #empirica
z <- qnorm(0.975)

cubrimientoN <- 0

#para cada n:
for (j in seq_along(ns)){
  n <- ns[j]
  cubrimiento <- 0
  
  #repito el experimento 5000 veces.
  for(i in 1:Nrep){                                         
    muestra <- rbinom(1,n,tita)
    
    estTita <- muestra/n
    termino <- z * sqrt((estTita*(1-estTita))/n)
    intervalo <- c(estTita - termino, estTita + termino)
    
    cubrimiento[i] <- intervalo[1] <= tita && tita <= intervalo[2]
  }
  
  #promedio de veces que el valor real de tita cayó en el intervalo
  cubrimientoN[j] <- mean(cubrimiento)                  
}

cubrimientoEmpirico <- data.frame(n = ns, cubrimiento = cubrimientoN)
```
---

* Y se obtuvieron estos resultados:

```{r, echo=FALSE, eval=TRUE}
knitr::kable(cubrimientoEmpirico, digits = 4, caption = "Cubrimiento empírico del intervalo")
```

---


* Los resultados obtenidos son coherentes con la teoría. Al tratarse de un intervalo asintótico, el cubrimiento empírico converge hacia el nivel nominal del 0.95 conforme aumenta el tamaño muestral n.

---

\centering
\vspace{2cm}
\Huge
**Parte II**  
\Large
Test imperfecto con $S_e$ y $S_p$ conocidos

---

## 2.0.1 Estimación de $p$ con $T_{per}$

### Estimador de $p$
$$\hat{p} = \frac{T_{per}}{n}$$

### Distribución
$$T_{per} \sim \text{Binomial}(n, p)$$

### Propiedades
- $\mathbb{E}[\hat{p}] = p$
- $\operatorname{Var}(\hat{p}) = \frac{p(1-p)}{n}$
- $\hat{p}$ es EMV de $p$

---

## 2.0.2 $p$ como función de $\theta$, $S_{e}$ y $S_{p}$.

\[
\boxed{p = Se\,\theta + (1-Sp)(1-\theta)}
\]

### Formas equivalentes
\[
p = (Se + Sp - 1)\,\theta + (1-Sp)
\]

\[
\theta = \frac{p + Sp - 1}{Se + Sp - 1}
\]

### Casos límite
\[
\theta = 0 \Rightarrow p = 1 - Sp
\]
\[
\theta = 1 \Rightarrow p = Se
\]

---

## 2.0.3 Comportamiento de $p = P(T=1)$

### Fórmula base
\[
p(\theta,Se,Sp) = Se\,\theta + (1-Sp)(1-\theta)
\]

### Valores de referencia
\[
Se = 0.9, \quad Sp = 0.95, \quad \theta = 0.25
\]
\[
p(0.25) = 0.2625
\]

---

## $p$ vs $\theta$ (fijos $Se$, $Sp$)

### Comportamiento
- **Lineal creciente** en $\theta$


### Límites
\[
\theta = 0 \Rightarrow p = 1 - Sp = 0.05
\]
\[
\theta = 1 \Rightarrow p = Se = 0.9
\]

### Interpretación
- **$\theta$ bajo**: $p$ dominada por falsos positivos
- **$\theta$ alto**: $p$ dominada por verdaderos positivos

---

## $p$ vs $Se$ (fijos $\theta$, $Sp$)

### Comportamiento
- **Lineal creciente** en $Se$
- Pendiente: $\theta = 0.25$

### Efecto
- **$Se$ baja**: Pocos verdaderos positivos
- **$Se$ alta**: Mejor detección → $p$ mayor

### Para $Se = 0.9$:
\[
p = 0.9 \times 0.25 + 0.05 \times 0.75 = 0.2625
\]

---

## $p$ vs $Sp$ (fijos $\theta$, $Se$)

### Comportamiento
- **Lineal decreciente** en $Sp$
- Pendiente: $-(1-\theta) = -0.75$

### Efecto
- **$Sp$ baja**: Muchos falsos positivos → $p$ alto
- **$Sp$ alta**: Menos falsos positivos → $p$ bajo

### Para $Sp = 0.95$:
\[
p = 0.225 + 0.05 \times 0.75 = 0.2625
\]

---

## Conclusiones clave

### Relaciones lineales
1. **$p \nearrow$ con $\theta$** 
2. **$p \nearrow$ con $Se$** 
3. **$p \searrow$ con $Sp$** 

---

## 2.1.4 Estimador de momentos (MoM)

* Por item $2.0.2$, sabemos que:

\[
p = S_{e} \theta + (1-S_{p})(1-\theta)
\]

Reagrupando:
\[
p = (S_{e}+S_{p}-1)\theta + 1 - S_{p}
\]


Entonces:
\[
\theta = \frac{p + S_{p} - 1}{S_{e}+S_{p}-1}
\]

---

* Como $\mathbb{E}[T_{i}] = p$, el estimador de momentos de $p$ es $\hat{p}_{MoM} = \frac{T_{per}}{n}$.

\vspace{0.5cm}

* Finalmente, el estimador plug-in de momentos de $\theta$ es el siguiente:

\[
\boxed{\hat{\theta}_{MoM} = \frac{\hat{p}_{MoM} + S_{p} - 1}{S_{e}+S_{p}-1}}
\]

---

## 2.1.5 Sesgo, varianza y ECM

* **Sesgo**:

  Primero se observa que: 
  
  \[
  \mathbb{E}[\hat{p}_{MoM}] = \mathbb{E}\left[\frac{T_{\text{per}}}{n}\right]= p = (S_{e}+S_{p}-1)\theta + 1 - S_{p}
  \]
  
  Luego:
  
  \[
  \mathbb{E}[\hat{\theta}_{MoM}] = \mathbb{E}\left[\frac{\hat{p}_{MoM}+S_{p}-1}{S_{e}+S_{p}-1}\right] = \frac{\mathbb{E}[\hat{p}_{MoM}] + S_{p} - 1}{S_{e}+S_{p}-1} = \theta
  \]
  
  Por lo tanto $\hat{\theta}_{MoM}$ es un estimador insesgado de $\theta$.

---

* **Varianza**:

  Primero se observa que:

  \[
  Var[\hat{p}_{MoM}] = Var\left[\frac{T_{\text{per}}}{n}\right]=\frac{np(1-p)}{n^2} = \frac{p(1-p)}{n}
  \]
  
  Luego:
  
  \[
  \operatorname{Var}[\hat{\theta}_{MoM}] = \operatorname{Var}\left[\frac{\hat{p}_{MoM}+S_{p}-1}{S_{e}+S_{p}-1}\right] = \frac{\operatorname{Var}[\hat{p}_{MoM} + S_{p} -1]}{(S_{e}+S_{p}-1)^2} =
  \]
  \[
  \frac{\operatorname{Var}[\hat{p}_{MoM}]}{(S_{e}+S_{p}-1)^2} = \frac{p(1-p)}{n(S_{e}+S_{p}-1)^2}
\]

---

* **ECM**:
  
  Como el sesgo es 0:
  
  \[
  \text{ECM}(\hat{\theta}_{MoM})
    = \operatorname{Var}[\hat{\theta}_{MoM}]
    + \mathbb{B}^2[\hat{\theta}_{MoM}]
    =\frac{p(1-p)}{n(S_{e}+S_{p}-1)^2}
  \]

---

* **Consistencia**
  
  Observemos que, por ley fuerte de los grandes números:
  
  \[
  \hat{p}_{MoM} = \frac{T_{per}}{n} \xrightarrow{cs} p
  \]
  
  Luego, como $\hat{\theta}_{MoM}$ es una función continua de $\hat{p}_{MoM}$:
  
  \[
  \hat{\theta}_{MoM} \xrightarrow{cs} \frac{p + S_{p}-1}{S_{e}+S_{p}-1} = \theta
  \]
  
  Por lo tanto, $\hat{\theta}_{MoM}$ es fuertemente consistente.

---

## 2.1.6 Comparación ECM: Test perfecto vs imperfecto

### Fórmulas
\[
\text{ECM}_{\text{perfecto}} = \frac{\theta(1-\theta)}{n}
\]
\[
\text{ECM}_{\text{imperfecto}} = \frac{p(1-p)}{n(S_e+S_p-1)^2}
\]

### Factor de aumento
\[
\boxed{\frac{1}{(S_e+S_p-1)^2}}
\]

### Para $S_e=0.9$, $S_p=0.95$
\[
S_e+S_p-1 = 0.85 \Rightarrow \frac{1}{0.85^2} \approx 1.38
\]
**ECM 38% mayor** con test imperfecto

---

## Comportamiento en función de $n$

```{r, echo=FALSE, fig.height=4.5}
tita <- 0.25
Se <- 0.9
Sp <- 0.95
p <- (Se + Sp - 1)*tita + (1 - Sp)
ns <- 10:1000

ECM_perfecto <- tita*(1 - tita) / ns
ECM_imperfecto <- p*(1 - p) / (ns * (Se + Sp - 1)^2)

plot(ns, ECM_imperfecto, type="l", col="orange", lwd=2,
     xlab="Tamaño muestral (n)", ylab="ECM",
     main="ECM vs n: Comparación entre tests")
lines(ns, ECM_perfecto, col="blue", lwd=2)

legend("topright", legend=c("Test imperfecto", "Test perfecto"),
       col=c("orange", "blue"), lwd=2, cex=0.9)

```

---

## Conclusiones clave

### Observaciones del gráfico
1. **ECM imperfecto > ECM perfecto** para todo $n$
2. Ambas **decrecen** como $1/n$

---

## 2.1.7 Validación: Teórico vs Simulado

### Diseño de simulación
- $R = 10000$ réplicas
- $n \in \{10, 20, 50, 100, 200\}$
- $\theta = 0.25$, $S_e = 0.9$, $S_p = 0.95$
- Estimador: $\hat{\theta}_{MoM}$

### Valores teóricos
\[
\operatorname{Var}_{\text{teórica}} = \frac{p(1-p)}{n(S_e+S_p-1)^2}
\]
\[
\text{ECM}_{\text{teórico}} = \operatorname{Var}_{\text{teórica}} \quad (\text{sesgo}=0)
\]

---

## Sesgo: Simulado vs Teórico (=0)

```{r, echo=FALSE, fig.height=4}
# Código adaptado para mostrar solo el gráfico
tita <- 0.25
Se <- 0.9
Sp <- 0.95
ns <- c(10, 20, 50, 100, 200)
R <- 10000

resultados <- data.frame(n = ns, bias_sim = NA)

for (i in seq_along(ns)) {
  n <- ns[i]
  p_Y <- Se*tita + (1 - Sp)*(1 - tita)
  est_imp <- numeric(R)
  
  for (r in 1:R) {
    T <- rbinom(n, 1, p_Y)
    p_hat <- mean(T)
    est_imp[r] <- (p_hat - (1 - Sp)) / (Se + Sp - 1)
  }
  resultados$bias_sim[i] <- mean(est_imp) - tita
}

plot(resultados$n, resultados$bias_sim, type="b", pch=19,
     xlab="n", ylab="Sesgo",
     main="Sesgo: Simulado vs Teórico",
     ylim=range(resultados$bias_sim))
abline(h = 0, col="blue", lwd=2, lty=2)
legend("topright", legend=c("Sesgo sim.", "Sesgo teórico (0)"),
       col=c("black","blue"), pch=c(19, NA), lty=c(1,2))
```

---

## Varianza: Simulado vs Teórica

```{r, echo=FALSE, fig.height=4}
# Cálculos para varianza
var_teo <- numeric(length(ns))
var_sim <- numeric(length(ns))

for (i in seq_along(ns)) {
  n <- ns[i]
  p_Y <- Se*tita + (1 - Sp)*(1 - tita)
  est_imp <- numeric(R)
  
  for (r in 1:R) {
    T <- rbinom(n, 1, p_Y)
    p_hat <- mean(T)
    est_imp[r] <- (p_hat - (1 - Sp)) / (Se + Sp - 1)
  }
  var_sim[i] <- var(est_imp)
  var_teo[i] <- (p_Y*(1 - p_Y)) / (n * (Se + Sp - 1)^2)
}

plot(ns, var_sim, type="b", pch=19, xlab="n", ylab="Varianza",
     main="Varianza: Simulado vs Teórica",
     ylim=c(0, max(var_sim, var_teo)))
lines(ns, var_teo, type="b", pch=17, col="blue")
legend("topright", legend=c("Var sim.", "Var teórica"),
       col=c("black","blue"), pch=c(19,17))
```

---

## ECM: Simulado vs Teórico

```{r, echo=FALSE, fig.height=4}

# Cálculos para varianza
var_teo <- numeric(length(ns))
var_sim <- numeric(length(ns))

for (i in seq_along(ns)) {
  n <- ns[i]
  p_Y <- Se*tita + (1 - Sp)*(1 - tita)
  est_imp <- numeric(R)
  
  for (r in 1:R) {
    T <- rbinom(n, 1, p_Y)
    p_hat <- mean(T)
    est_imp[r] <- (p_hat - (1 - Sp)) / (Se + Sp - 1)
  }
  var_sim[i] <- var(est_imp)
  var_teo[i] <- (p_Y*(1 - p_Y)) / (n * (Se + Sp - 1)^2)
}

plot(ns, var_sim, type="b", pch=19, xlab="n", ylab="Varianza",
     main="Varianza: Simulado vs Teórica",
     ylim=c(0, max(var_sim, var_teo)))
lines(ns, var_teo, type="b", pch=17, col="blue")
legend("topright", legend=c("Var sim.", "Var teórica"),
       col=c("black","blue"), pch=c(19,17))

```


---

## Conclusiones de la validación

### Confirmaciones
1. **Sesgo aprox 0** en simulación → Insesgabilidad verificada
2. **Varianza simulada aprox Varianza teórica** para todo $n$
3. **ECM simulada aprox ECM teórico** → Fórmulas correctas

### Comportamiento observado
- **Convergencia**: A mayor $n$, mejor ajuste entre lo simulado y lo teorico
- **Consistencia**: Var/ECM decrecen como $1/n$
- **Robustez**: Fórmulas teóricas válidas aún para $n$ pequeño

### Implicaciones
- **Expresiones teóricas** son confiables
- **Estimador MoM** se comporta según la teoría
- **Simulación** valida aproximaciones asintóticas
  
---

## 2.1.8 Bootstrap para $\hat{\theta}_{MoM}$ ($n=10$)

### Parámetros
- $\theta = 0.25$, $S_e = 0.9$, $S_p = 0.95$
- $n = 10$, $B = 5000$ réplicas bootstrap
- Bootstrap no paramétrico

### Método
1. Muestra original: $T_i \sim \text{Bernoulli}(p)$
2. Remuestreo con reemplazo
3. Recalcular $\hat{\theta}_{MoM}$ en cada réplica

---

## Distribución bootstrap ($n=10$)

```{r, echo=FALSE, fig.height=4.5}
tita <- 0.25
Se <- 0.9
Sp <- 0.95
n <- 10
B <- 5000

# Probabilidad real
p_Y <- Se * tita + (1 - Sp) * (1 - tita)

# Muestra original
set.seed(123)  # Para reproducibilidad
T_original <- rbinom(n, 1, p_Y)

# Bootstrap
boot_est <- numeric(B)
for (b in 1:B) {
  T_boot <- sample(T_original, size = n, replace = TRUE)
  p_hat_boot <- mean(T_boot)
  boot_est[b] <- (p_hat_boot - (1 - Sp)) / (Se + Sp - 1)
}

# Histograma
hist(boot_est, breaks = 15, freq = TRUE, col = "lightblue",
     main = "Distribución bootstrap - n = 10",
     xlab = expression(hat(theta)["MoM"]), 
     ylab = "Frecuencia", border = "darkblue")
abline(v = tita, col = "red", lwd = 3, lty = 2)
abline(v = mean(boot_est), col = "darkgreen", lwd = 2, lty = 2)
legend("topright", legend = c(expression(theta*" verdadero"), "Media bootstrap"),
       col = c("red", "darkgreen"), lwd = c(3, 2), lty = c(2, 2), cex = 0.8)
```

---

## Resultados bootstrap

### Estadísticas clave
\[
\text{Media bootstrap} = `r round(mean(boot_est), 4)`
\]
\[
\text{Sesgo bootstrap} = `r round(mean(boot_est) - tita, 4)`
\]
\[
\text{Desvío bootstrap} = `r round(sd(boot_est), 4)`
\]

### Características observadas
1. **Alta dispersión** (gran variabilidad)
2. **Sesgo positivo** 
3. **Distribución asimétrica** hacia derecha
4. **Valores fuera de [0,1]** posibles
5. Se recomienda aumentar $n$ (mas centrado al valor real y disminuir var)

---

## 2.2.9 Intervalos de confianza bootstrap

\vspace{0.5cm}

### Objetivo
Construir intervalos de confianza para $\theta$ basados en el estimador de momentos utilizando bootstrap no paramétrico.

### Método
- A partir de los datos ${T_i}$, se calcula $\hat\theta_{MoM}$ en cada remuestreo.

\vspace{0.2cm}

- Se generan $B = 1000$ réplicas bootstrap:  
  $\hat\theta^{*(b)}_{MoM}$, $b = 1,\dots,B$.
  
\vspace{0.2cm}
  
- Intervalo bootstrap percentil:

\[
IC^{boot}_{0.95} = 
\big[\, Q_{0.025}(\hat\theta^{*}),\; Q_{0.975}(\hat\theta^{*}) \,\big].
\]

---

### Simulación Monte Carlo
- Replicaciones: $R = 700$.
- Tamaños muestrales: $n \in \{10, 20, 50, 100, 1000\}$.
- Para cada réplica se obtiene:
  - **Cubrimiento empírico**: $1\{\theta \in IC^{boot}\}$
  - **Longitud**: $IC^{up} - IC^{low}$

```{r, echo = FALSE}

tita_corregida <- function(p_hat, Se, Sp) {
  (p_hat - (1 - Sp)) / (Se + Sp - 1)
}

#Definimos los valores a utilizar.
tita <- 0.25
Se <- 0.9
Sp <- 0.95
p_Y <- Se * tita + (1 - Sp) * (1 - tita)

ns <-  c(10, 20, 50, 100, 1000)
R <- 700 #replicas Monte Carlo
B <- 1000 #remuestreos bootstrap

z <- qnorm(0.975)

res_list <- vector("list",length(ns))
names(res_list) <- as.character(ns)

#para cada n:
for (j in seq_along(ns)){
  n <- ns[j]
  cubrimientos <- logical(R)
  longitudes <- numeric(R)
  
  #repito el experimento R veces 
  for (r in 1:R){
     T <- rbinom(n,1,p_Y)
     boot_est <- numeric(B)
     
     #genero B muestras bootstrap.
     for (b in 1:B){
       T_boot <- sample(T, size = n, replace = TRUE)
       p_hat_boot <- mean(T_boot)
       boot_est[b] <- tita_corregida(p_hat_boot, Se, Sp)
     }
     
     lower <- quantile(boot_est, probs = 0.025, names = FALSE)
     upper <- quantile(boot_est, probs = 0.975, names = FALSE)
     
     cubrimientos[r] <- (lower <= tita) && (tita <= upper)
     longitudes[r] <- (upper - lower)
  }
  
  #resultados para cada n
  res_list[[j]] <- list(
    n = n,
    cubrimiento = mean(cubrimientos),
    longitud_media = mean(longitudes)
  )
   
}

res_df <- do.call(rbind, lapply(res_list, function(z){
  data.frame(n = z$n,
             cubrimiento = z$cubrimiento,
             longitud_media = z$longitud_media)
}))
rownames(res_df) <- NULL
```

---
  
## 2.2.10 Intervalo de confianza asintótico
  
Recordemos que: 
  
* $\hat{p}_{MoM} = \frac{T_{per}}{n}$
\vspace{0.1cm}
* $\mathbb{E}[\hat{p}_{MoM}] = p$
\vspace{0.1cm}
* $\operatorname{Var}[\hat{p}_{MoM}] = \frac{p(1-p)}{n}$
\vspace{0.1cm}
* $\hat{\theta}_{MoM} = \frac{\hat{p}_{MoM} + S_{p} - 1}{S_{e}+S_{p}-1}$
\vspace{0.1cm}
* $\mathbb{E}[\hat{\theta}_{MoM}] = \theta$
\vspace{0.1cm}
* $\operatorname{Var}[\hat{\theta}_{MoM}] = \frac{p(1-p)}{n(S_{e}+S_{p}-1)^2}$
  
---
  
* Entonces por TCL:
  
\[
\sqrt{n} (\hat{p}_{MoM} - p) \xrightarrow{D}  N\bigl(0,(p(1-p))\bigr)
\]
  
Defino $g(x) = \frac{x+S_{p}-1}{S_{e}+S_{p}-1}$ y $g'(x) = \frac{1}{S_{e} + S_{p} -1}$. Notar que $g(x)$ es $C^1$.
  
\vspace{0.2cm}

* Por Método Delta:
  
\[
\sqrt{n}(g(\hat{p}_{MoM}) - g(p)) \xrightarrow{D} N\bigl(0, \frac{p(1-p)}{(S_{e}+S_{p}-1)^2}\bigr)
\]

---

Luego,
  
\[
\frac{\hat{\theta}_{MoM}-\theta}{\sqrt{\operatorname{Var}[\hat{\theta}_{MoM}]}} \xrightarrow{D} N\bigl(0,1\bigr)
\]
  
  
* Además $\hat{p}_{MoM} = \frac{T_{per}}{n} \xrightarrow{cs} p$, entonces: 
  
\[ 
\sqrt{\frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{p(1-p)}} \xrightarrow{P} 1 
\]
  
debido a que $h(x)= \sqrt{\frac{x(1-x)}{p(1-p)}}$ es continua en $(0,1)$.
  
---
  
Si $\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}] =\frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{n(S_{e}+S_{p}-1)^2}$, usando teorema de Slutsky:
  
\[
\frac{\hat{\theta}_{MoM} - \theta}{\sqrt{\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}]}} = \frac{\hat{\theta}_{MoM} - \theta}{\sqrt{\operatorname{Var}[\hat{\theta}_{MoM}]}\sqrt{\frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{p(1-p)}}} \xrightarrow{D}  N\bigl(0,1\bigr)
\]
  
  
* Por lo tanto, se deduce el siguiente intervalo de nivel asintótico $0.95$:
  
\[
\boxed{IC^{\theta}_{0.95} = \hat{\theta}_{MoM}\pm 1.96\sqrt{\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}]}}
\]
  
donde $\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}] = \frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{n(S_{e}+S_{p}-1)^2}$

```{r, echo=FALSE}
res_listAsint <- vector("list", length(ns))
names(res_listAsint) <- as.character(ns)

#para cada n:
for (j in seq_along(ns)){
  n <- ns[j]
  cubrimientos <- logical(R)
  longitudes <- numeric(R)
  
  #repito el experimento R veces.
  for (r in 1:R){
    T <- rbinom(n, 1, p_Y)
    
    p_hat <- mean(T)
    tita_hat <- tita_corregida(p_hat,Se,Sp)
    est_Var <- (p_hat*(1-p_hat))/(n*(Se+Sp-1)^2)
    
    termino <- z*sqrt(est_Var)
    lower <- tita_hat - termino
    upper <- tita_hat + termino
    
    cubrimientos[r] <- (lower <= tita) && (tita <= upper)
    longitudes[r] <- (upper - lower)
  }
  
  #resultados para cada n.
  res_listAsint[[j]] <- list(
    n = n,
    cubrimiento = mean(cubrimientos),
    longitud_media = mean(longitudes)
  )
}

resAsint_df <- do.call(rbind, lapply(res_listAsint, function(z){
  data.frame(n = z$n,
             cubrimiento = z$cubrimiento,
             longitud_media = z$longitud_media)
}))
rownames(resAsint_df) <- NULL
```

---

## 2.2.11 Comparación entre ambos intervalos

Luego de realizar las simulaciones pertinentes, comparemos los resultados obtenidos.

```{r, echo=FALSE, eval=TRUE}
knitr::kable(res_df, digits = 4, caption = "Bootstrap Percentil")
```

---

```{r, echo=FALSE, eval=TRUE}
knitr::kable(resAsint_df, digits = 4, caption = "Intervalos Asintóticos")
```

---

* El bootstrap parece ser más robusto en muestras pequeñas, lo cual es esperable porque no depende de aproximaciones normales ni del método delta.

\vspace{0.3cm}

* El método asintótico da intervalos ligeramente más largos.

\vspace{0.3cm}

* A medida que aumenta $n$ los resultados convergen a los valores esperados.

---

## 2.3.12 Comportamiento del estimador de momentos

### Definición
El estimador de momentos se obtiene de:
\[
p = Se\,\theta + (1-Sp)(1-\theta)
\]
y reemplazando \(p\) por \(\hat p = T_{\text{per}}/n\):
\[
\hat{\theta}_{MoM} =
\frac{\hat p + Sp - 1}{Se + Sp - 1}.
\]

### Observación clave
- Aunque \(\hat p \in [0,1]\), la transformación es **lineal**, por lo que  
  \(\hat\theta_{MoM}\) **puede salir de \([0,1]\)**.
- Esto ocurre cuando la muestra tiene demasiados o muy pocos positivos.

### Condiciones
\[
\hat\theta_{MoM} < 0
\quad\Longleftrightarrow\quad
\hat p < 1 - Sp,
\]
\[
\hat\theta_{MoM} > 1
\quad\Longleftrightarrow\quad
\hat p > Se.
\]

---

## Ejemplos numéricos

### Valores de referencia
\[
Se = 0.9, \quad Sp = 0.95,
\qquad
1 - Sp = 0.05, \quad Se + Sp - 1 = 0.85.
\]

### Ejemplo 1: \(\hat\theta_{MoM} < 0\)
Si no hay positivos en la muestra:
\[
\hat p = 0.
\]
Entonces:
\[
\hat\theta_{MoM}
= \frac{0 + 0.95 - 1}{0.85}
= \frac{-0.05}{0.85}
\approx -0.0588.
\]

### Ejemplo 2: \(\hat\theta_{MoM} > 1\)
Si la muestra da un valor extremo:
\[
\hat p = 0.95,
\]
entonces:
\[
\hat\theta_{MoM}
= \frac{0.95 + 0.95 - 1}{0.85}
= \frac{0.90}{0.85}
\approx 1.0588.
\]

### Conclusión
- El estimador puede quedar fuera del intervalo válido para una probabilidad.
- Motivación para introducir el **estimador truncado**.

---

## 2.3.13 Estudio del estimador truncado

### Motivación
El estimador de momentos puede tomar valores fuera de \([0,1]\).  
Para evitar valores imposibles se define el estimador **truncado**:

### Definición
\[
\hat\theta_{\text{trunc}} =
\begin{cases}
\hat\theta_{\text{MoM}}, & 0 \le \hat\theta_{\text{MoM}} \le 1,\\[6pt]
0, & \hat\theta_{\text{MoM}} < 0,\\[6pt]
1, & \hat\theta_{\text{MoM}} > 1.
\end{cases}
\]

### Interpretación
- Coincide con \(\hat\theta_{MoM}\) cuando este es válido.
- Recorta valores negativos a 0 y mayores a 1 a 1.
- Introduce **sesgo** para muestras pequeñas, pero evita valores inaceptables.

---

## Simulación Monte Carlo del estimador truncado

### Parámetros usados
- \(\theta = 0.25\), \(Se = 0.9\), \(Sp = 0.95\)
- Tamaños muestrales: \(n = 10,\,100,\,1000\)
- Réplicas: \(N_{\text{rep}} = 10000\)

### Para cada réplica:
1. Generar \(T \sim \text{Binomial}(n, p_{verdadera})\)
2. Calcular \(\hat\theta_{\text{trunc}}\)
3. Estimar:
   - media  
   - sesgo  
   - varianza  
   - ECM = Sesgo\(^2\) + Var

### Tabla de resultados
\begin{table}[H]
\centering
\begin{tabular}{ccccc}
\hline
$n$ & media & sesgo & var & ECM \\
\hline
10   & 0.2485 & -0.00149 & 0.02463 & 0.02463 \\
100  & 0.25005 & 0.000048 & 0.002685 & 0.002685 \\
1000 & 0.25007 & 0.000067 & 0.000263 & 0.000263 \\
\hline
\end{tabular}
\end{table}

---

## Análisis del estimador truncado

### Sesgo
- Para \(n = 10\), el estimador muestra sesgo apreciable.  
  Esto ocurre porque \(\hat\theta_{MoM}\) cae a menudo por debajo de 0 y se trunca.
- El sesgo → 0 cuando \(n\) aumenta (coincide con el estimador original).

### Varianza
- Disminuye al crecer \(n\).
- Para \(n = 10\) es elevada por la alta variabilidad de \(\hat p\).
- Para \(n = 1000\) es muy baja y estable.

### ECM
\[
ECM = \text{Sesgo}^2 + \text{Var}.
\]
- Para muestras pequeñas, ECM grande por sesgo + varianza.
- Para muestras grandes, el ECM es muy pequeño.

### Conclusión
El estimador truncado:
- **es consistente**,  
- **es asintóticamente equivalente** al estimador de momentos,  
- pero **distorsiona muestras pequeñas** debido al truncamiento.

---

## Distribución del estimador truncado

```{r, echo = FALSE}
n_valores <- c(10, 100, 1000)
N_rep <- 10000
theta_verdadera <- 0.25
Se_fijo         <- 0.9
Sp_fijo         <- 0.95
p_verdadera <- Se_fijo * theta_verdadera + (1 - Sp_fijo) * (1 - theta_verdadera)

theta_mom <- function(T_obs, n, Se = Se_fijo, Sp = Sp_fijo) {
  p_muestral <- T_obs / n
  theta_mom_est <- (p_muestral + Sp - 1) / (Se + Sp - 1)
  return(theta_mom_est)
}

# Estimador truncado de theta
theta_trunc <- function(T_obs, n, Se = Se_fijo, Sp = Sp_fijo) {
  theta_mom_est <- theta_mom(T_obs, n, Se, Sp)
  theta_trunc_est <- pmin(1, pmax(0, theta_mom_est))
  return(theta_trunc_est)
}

par(mfrow = c(2, 2))  ## grid para los gráficos

for (n in n_valores) {
  # nueva data para cada n
  T_sim <- rbinom(N_rep, size = n, prob = p_verdadera)
  theta_trunc_sim <- theta_trunc(T_sim, n)
  
  # Histograma
  hist(theta_trunc_sim,
       breaks = 40,
       main = paste("Histograma de theta_trunc, n =", n),
       xlab = expression(hat(theta)[trunc]),
       probability = TRUE)
  
  media_hat <- mean(theta_trunc_sim)
  sd_hat    <- sd(theta_trunc_sim)
  x_grid    <- seq(0, 1, length.out = 200)
  lines(x_grid, dnorm(x_grid, mean = media_hat, sd = sd_hat), col = "red")
}

par(mfrow = c(1, 1))

n <- 1000
T_sim <- rbinom(N_rep, size = n, prob = p_verdadera)
theta_trunc_sim <- theta_trunc(T_sim, n)

qqnorm(theta_trunc_sim,
       main = expression(paste("QQ-plot de ", hat(theta)[trunc], " para n=1000")),
       xlab= "",
       ylab= "")
qqline(theta_trunc_sim)

```

---

### Observaciones de la simulación
- Para \(n = 10\):  
  - La distribución muestra **acumulación en 0 y 1**.  
  - No es aproximadamente normal.
- Para \(n = 100\):  
  - La masa en los bordes disminuye.  
  - La distribución empieza a ser unimodal y más suave.
- Para \(n = 1000\):  
  - El truncamiento ocurre con probabilidad casi nula.  
  - La distribución es bien aproximada por una normal:
\[
\hat\theta_{\text{trunc}} \approx
\mathcal{N}\left(
\theta,\;
\frac{p(1-p)}{n(Se+Sp-1)^2}
\right).
\]

### Conclusión general
- Para muestras grandes, el estimador truncado **preserva la distribución asintótica del MoM**.

---

\centering
\vspace{2cm}
\Huge
**Parte III**  
\Large
Dos muestras (pre-post intervención)

---

* En esta sección analizamos si la prevalencia verdadera de la enfermedad cambió después de implementar una campaña de vacunación. Para ello se toman dos muestras independientes:

- Una **antes** de la campaña, de tamaño \( n_{\text{pre}} \), con número de test positivos \( X_{\text{pre}} \).
- Otra **después**, de tamaño \( n_{\text{post}} \), con número de test positivos \( X_{\text{post}} \).

En ambos casos se utiliza el mismo test diagnóstico imperfecto, caracterizado por su **sensibilidad** \( Se \) y **especificidad** \( Sp \).

---

* Los conteos observados siguen:
\[
X_{\text{pre}} \sim \text{Binomial}(n_{\text{pre}}, p_{\text{pre}}), \quad 
X_{\text{post}} \sim \text{Binomial}(n_{\text{post}}, p_{\text{post}})
\]
donde  
\[
p_A = (Se + Sp - 1)\theta_A + (1 - Sp), \qquad A \in \{\text{pre}, \text{post}\}
\]

* Nuestro objetivo es inferir la **diferencia de prevalencias verdaderas**:
\[
\boxed{\Delta = \theta_{\text{post}} - \theta_{\text{pre}}}
\]

---

## 3.1.1 Test de Hipótesis

Se quiere plantear un test de nivel aproximado $0.05$ para las siguientes hipótesis, basándose en el estimador $\hat{\theta}_{MoM}$:

\[
H_{0} : \Delta = 0 \quad \text{vs.} \quad H_{1} : \Delta \neq 0
\]

---

Tenemos:

\[
\hat{\theta}_{post} = \frac{\hat{p}_{post} + S_{p} - 1}{S_{e}+S_{p}-1} \quad \text{y} \quad \hat{\theta}_{pre} = \frac{\hat{p}_{pre} + S_{p} - 1}{S_{e}+S_{p}-1}
\]

Y por el item $2.1.10$, se deduce que:

\[
\hat{\theta}_{post} \approx N\bigl(\theta_{post},\; \widehat{\operatorname{Var}}(\hat{\theta}_{post})\bigr)
\quad\text{y}\quad
\hat{\theta}_{pre} \approx N\bigl(\theta_{pre},\; \widehat{\operatorname{Var}}(\hat{\theta}_{pre})\bigr)
\]

---

\[
\Rightarrow\quad
\hat{\theta}_{post} - \hat{\theta}_{pre}
\approx
N\!\Bigl(\theta_{post}-\theta_{pre},\; \widehat{\operatorname{Var}}(\hat{\theta}_{post}) + \widehat{\operatorname{Var}}(\hat{\theta}_{pre})\Bigr)
\]

\[
U_{\Delta}(X_{pre},X_{post})
=
\frac{\hat{\theta}_{post} - \hat{\theta}_{pre} - \Delta}
     {\sqrt{\widehat{\operatorname{Var}}(\hat{\theta}_{post}) + \widehat{\operatorname{Var}}(\hat{\theta}_{pre})}}
\approx N(0,1)
\]


* Tenemos un pivote decreciente en $\Delta$ con distribución aproximada conocida independiente de $\Delta$. Entonces, utilizando método del pivote, resulta el siguiente test de nivel aproximado 0.05.

\[
\Phi(X_{pre},X_{post}) =
\begin{cases}
1 & \text{si } \bigl|U_{0}(X_{pre},X_{post})\bigr| > z_{1-\alpha/2} = z_{0.975} \approx 1.96, \\
0 & \text{c.c.}
\end{cases}
\]

---

## 3.1.2 Aplicación en caso ficticio

Vamos a aplicar el test dado en el item anterior a un caso ficticio con $n_{pre} = n_{post} = 100$, $S_{e} = 0.9$, $S_{p} = 0.95$, $\theta_{pre} = 0.2$, $\theta_{post} = 0.15$ y $\alpha = 0.05$.

---

* El estadístico observado tiene el siguiente valor:

```{r, echo=FALSE, eval=TRUE}
# Definimos valores y calculamos U (sin mostrar código)
n_pre <- 100
n_post <- 100
Se <- 0.9
Sp <- 0.95
tita_pre <- 0.2
tita_post <- 0.15

p_pre <- (Se + Sp - 1)* tita_pre + (1 - Sp)
p_post <- (Se + Sp - 1)* tita_post + (1 - Sp)

set.seed(123)  # Para reproducibilidad
Xpre <- rbinom(n_pre, 1, p_pre)
Xpost <- rbinom(n_post, 1, p_post)

p_preHat <- mean(Xpre)
p_postHat <- mean(Xpost)

tita_preHat <- (p_preHat + Sp - 1)/(Se + Sp - 1)
tita_postHat <- (p_postHat + Sp - 1)/(Se + Sp - 1)

Var_preHat <- (p_preHat*(1-p_preHat))/(n_pre*(Se+Sp-1)^2)
Var_postHat <- (p_postHat*(1-p_postHat))/(n_post*(Se+Sp-1)^2)

U <- (tita_postHat - tita_preHat)/(sqrt(Var_postHat + Var_preHat))

cat("U =", round(U, 4))
```

Por lo tanto, no hay evidencia suficiente como para rechazar $H_{0}$ a nivel aproximado 0.05. Esto quiere decir que no se afirma que la vacuna es realmente efectiva. Es razonable porque la diferencia real entre prevalencias es pequeña ($0.05$).

---

* ¿Qué pasa si achicamos la muestra? 

- Para $n = 50$, obtenemos el siguiente resultado:

```{r, echo=FALSE, eval=TRUE}
n_pre <- 50
n_post <- 50

set.seed(123)
Xpre <- rbinom(n_pre, 1, p_pre)
Xpost <- rbinom(n_post, 1, p_post)

p_preHat <- mean(Xpre)
p_postHat <- mean(Xpost)

tita_preHat <- (p_preHat + Sp - 1)/(Se + Sp - 1)
tita_postHat <- (p_postHat + Sp - 1)/(Se + Sp - 1)

Var_preHat <- (p_preHat*(1-p_preHat))/(n_pre*(Se+Sp-1)^2)
Var_postHat <- (p_postHat*(1-p_postHat))/(n_post*(Se+Sp-1)^2)

U50 <- (tita_postHat - tita_preHat)/(sqrt(Var_postHat + Var_preHat))

cat("U (n=50) =", round(U50, 4))
```

El valor del estadístico observado sigue estando en la región de aceptación. Igualmente, al haber menos muestras la varianza aumenta y el resultado es distinto de 0.

- Para $n = 10$, obtenemos el siguiente resultado:

```{r, echo=FALSE, eval=TRUE}
n_pre <- 10
n_post <- 10

set.seed(123)
Xpre <- rbinom(n_pre, 1, p_pre)
Xpost <- rbinom(n_post, 1, p_post)

p_preHat <- mean(Xpre)
p_postHat <- mean(Xpost)

tita_preHat <- (p_preHat + Sp - 1)/(Se + Sp - 1)
tita_postHat <- (p_postHat + Sp - 1)/(Se + Sp - 1)

Var_preHat <- (p_preHat*(1-p_preHat))/(n_pre*(Se+Sp-1)^2)
Var_postHat <- (p_postHat*(1-p_postHat))/(n_post*(Se+Sp-1)^2)

U10 <- (tita_postHat - tita_preHat)/(sqrt(Var_postHat + Var_preHat))

cat("U (n=10) =", round(U10, 4))
```

Para una muestra tan pequeña el test se vuelve inestable y es practicamente inútil, ya que nuetsro test es de nivel asintótico.

---

## 3.1.3 Intervalo de confianza de nivel asintotico 0.95 para $\Delta$

Usamos el estimador de momentos (no truncado):

\[
\hat\theta_A \;=\; \frac{\hat p_A + (Sp - 1)}{Se + Sp - 1}, 
\qquad A \in \{\text{pre}, \text{post}\},
\]

donde \(\hat p_A = X_A / n_A\) y \(X_A\) es el número de tests positivos observados.


El pivote utilizado es:

\[
Z \;=\; 
\frac{
\widehat{\Delta} - \Delta
}{
\sqrt{
\widehat{Var}(\hat\theta_{\text{post}}) +
\widehat{Var}(\hat\theta_{\text{pre}})
}
},
\]

el cual tiene distribución aproximada \(N(0,1)\).

---

El intervalo de confianza asintótico al 95% para la diferencia

\[
\Delta = \theta_{\text{post}} - \theta_{\text{pre}}
\]

es

\[
\widehat{\Delta} \;\pm\;
1.96 \sqrt{
\widehat{Var}(\hat\theta_{\text{post}}) +
\widehat{Var}(\hat\theta_{\text{pre}})
}.
\]

donde \(\widehat{\Delta} = \hat\theta_{\text{post}} - \hat\theta_{\text{pre}}\).

```{r, echo=FALSE, eval=TRUE}

# Estimador de Delta y su desvío estándar
DeltaHat <- tita_postHat - tita_preHat
se_Delta <- sqrt(Var_preHat + Var_postHat)

# Intervalo asintotico 95%
z <- qnorm(0.975)
IC_lower <- DeltaHat - z * se_Delta
IC_upper <- DeltaHat + z * se_Delta

cat("DeltaHat =", round(DeltaHat, 4), "\n")
cat("IC 95% para Delta: [", round(IC_lower, 4), ",", round(IC_upper, 4), "]\n")

```

El intervalo calculado fue:

\[
IC_{95\%}(\Delta)
=
[-0.3259,\; 0.5612].
\]

---

### Observaciones

- **Incluye al 0**, no hay evidencia suficiente para decir que hay un cambio real entre pre y post. 
- **Intervalo bastante ancho**, hay alta incertidumbre.
- **Limite superior es bastante grande** puede haber aumento grande entre pre y post.
- **Limite inferior negativo**, tambien puede haber una disminucion moderada.

---

## 3.1.4 Nivel empírico del test.

Se quiere calcular el nivel empírico del test dado en $3.1.2$. Para ello, se define una grilla de valores de $n$ para calcular el nivel para cada valor. Se sabe que el nivel de un test está definido por el supremo de los errores de tipo 1. Entonces, también se define una grilla de valores de $\theta$ y se realizan las simulaciones pertinentes.

```{r, echo=FALSE}
#Definimos los valores a utilizar.
Nrep <- 2000
ns <- c(10, 20, 50, 100, 1000, 10000)
alpha <- 0.05
Se <- 0.9
Sp <- 0.95
z <- qnorm(0.975)

# Como queremos nivel, definimos prevalencias iguales para pre y post (H0 delta = 0).
#Además queremos el supremo de los errores de tipo 1, entonces hay que variar tita.
grid_tita <- seq(0.01, 0.99, length.out = 20)
  

#Vector que va a tener el nivel empírico para cada n.
nivelN <- numeric(length(ns))


#para cada n:
for (r in seq_along(ns)){
  n <- ns[r]
  
  #vector que va a tener error de tipo 1 para cada tita.
  errorTipo1 <- numeric(length(grid_tita))
  
  #para cada tita:
  for (j in seq_along(grid_tita)){
    tita <- grid_tita[j]
    p <- (Se + Sp - 1)* tita + (1 - Sp)
    
    #vector que va a tener si rechazo o no el test en cada pos.
    rechazos <- numeric(Nrep)
    
    #repito el experimento Nrep veces:
    for(i in 1:Nrep){                                        
      Xpre <- rbinom(n,1,p)
      Xpost <- rbinom(n,1,p)
      
      #Ahora calculamos U(Xpre, Xpost):
      p_preHat <- mean(Xpre)
      p_postHat <- mean(Xpost)
      
      tita_preHat <- (p_preHat + Sp - 1)/(Se + Sp - 1)
      tita_postHat <- (p_postHat + Sp - 1)/(Se + Sp - 1)
      
      Var_preHat <- (p_preHat*(1-p_preHat))/(n*(Se+Sp-1)^2)
      Var_postHat <- (p_postHat*(1-p_postHat))/(n*(Se+Sp-1)^2)
      
      U <- (tita_postHat - tita_preHat)/(sqrt(Var_postHat + Var_preHat)) 
      
      #rechazo o no H0.
      rechazos[i] <- abs(U) > z
    }
    
    #proporción de rechazos.(ignoro nan en caso de que el p estimado sea 0 o 1 
    #pues sucede un div por 0)
    errorTipo1[j] <- mean(rechazos, na.rm = TRUE)                    
    
  }
  
  nivelN[r] <- max(errorTipo1)
}

nivelEmpirico <- data.frame(n = ns, nivel = nivelN)

```

---

* Se obtuvieron los siguientes resultados:

```{r, echo=FALSE}
knitr::kable(nivelEmpirico, digits = 4, caption = "Nivel empírico del test")
```

Se observa claramente el comportamiento asintótico del test. A medida que aumenta n, el nivel del test se acerca a 0.05.