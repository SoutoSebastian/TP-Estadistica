---
title: "Trabajo Práctico – IECD"
author: "Grupo 11"
date: "2025-12-8"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introducción

## Objetivo del trabajo

Análisis de propiedades estadísticas de tests diagnósticos:

1. **Test perfecto** (baseline)
2. **Test imperfecto** con $S_e$ y $S_p$ conocidos  
3. **Dos muestras** (pre-post intervención)

---

# Parte I: Test perfecto (baseline)

## 1.1 Distribución de $T_{per}$

### Contexto
- Población con prevalencia $\theta = P(Y=1)$
- Test perfecto: $Se = Sp = 1$
- $Y_i \sim \text{Bernoulli}(\theta)$, i.i.d.

### Variable de interés
$$T_{per} = \sum_{i=1}^n Y_i$$

### Distribución
$$T_{per} \sim \text{Binomial}(n,\theta)$$

$$\boxed{P(T_{per} = k) = \binom{n}{k}\theta^{k}(1-\theta)^{n-k}}$$

---

## 1.2 Estimador de Máxima Verosimilitud

### Función de verosimilitud
$$L(\theta) = \prod_{i=1}^n \theta^{Y_i}(1-\theta)^{1-Y_i} = (1-\theta)^{N_0}\,\theta^{N_1}$$

### Log-verosimilitud
$$\ell(\theta) = N_0 \ln(1-\theta) + N_1 \ln(\theta)$$

### Estimador EMV
$$\hat{\theta}_{per} = \frac{N_1}{n} = \frac{T_{per}}{n}$$

---

## 1.3 Propiedades del estimador

### Sesgo
$$\mathbb{E}[\hat{\theta}_{per}] = \theta \quad \text{(insesgado)}$$

### Varianza
$$\operatorname{Var}(\hat{\theta}_{per}) = \frac{\theta(1-\theta)}{n}$$

### Error Cuadrático Medio
$$\text{ECM}(\hat{\theta}_{per}) = \frac{\theta(1-\theta)}{n}$$

---

### Consistencia
$$\hat{\theta}_{per} \xrightarrow{c.s.} \theta$$

### Distribución asintótica
$$\sqrt{n}\,(\hat{\theta}_{per} - \theta) \xrightarrow{d} N\bigl(0,\theta(1-\theta)\bigr)$$

---

## 1.4 Intervalo de confianza para $\theta$

### Por TCL y Slutsky
$$\sqrt{n}\,\frac{(\hat{\theta}_{per} - \theta)}{\sqrt{\hat{\theta}_{per}(1-\hat{\theta}_{per})}} \xrightarrow{d} N\bigl(0,1\bigr)$$

### Intervalo de confianza 95%
$$IC_{0.95}(\theta) = \hat{\theta}_{per} \pm 1.96\sqrt{\frac{\hat{\theta}_{per}(1-\hat{\theta}_{per})}{n}}$$

---

## 1.5 Cubrimiento empírico

### Simulación Monte Carlo

```{r, echo=FALSE, eval=TRUE, warning=FALSE}
set.seed(43)
tita <- 0.25
ns <- c(10, 20, 50, 100, 1000, 10000)
Nrep <- 5000
z <- qnorm(0.975)
cubrimientoN <- numeric(length(ns))

for (j in seq_along(ns)){
  n <- ns[j]
  cubrimiento <- numeric(Nrep)
  
  for(i in 1:Nrep){
    muestra <- rbinom(1,n,tita)
    estTita <- muestra/n
    termino <- z * sqrt((estTita*(1-estTita))/n)
    intervalo <- c(estTita - termino, estTita + termino)
    cubrimiento[i] <- intervalo[1] <= tita && tita <= intervalo[2]
  }
  cubrimientoN[j] <- mean(cubrimiento)
}

cubrimientoEmpirico <- data.frame(n = ns, cubrimiento = cubrimientoN)
```

```{r}
knitr::kable(cubrimientoEmpirico, 
             col.names = c("n", "Cubrimiento"),
             digits = 4,
             caption = "Cubrimiento empírico para diferentes n")
```


---

# Parte II: Test imperfecto con $S_e$ y $S_p$ conocidos

## 2.0.1 Estimación de $p$ con $T_{per}$

### Estimador de $p$
$$\hat{p} = \frac{T_{per}}{n}$$

### Distribución
$$T_{per} \sim \text{Binomial}(n, p)$$

### Propiedades
- $\mathbb{E}[\hat{p}] = p$
- $\operatorname{Var}(\hat{p}) = \frac{p(1-p)}{n}$
- $\hat{p}$ es EMV de $p$

---

## 2.0.2 $p$ como función de $\theta$, $S_{e}$ y $S_{p}$.

\[
\boxed{p = Se\,\theta + (1-Sp)(1-\theta)}
\]

### Formas equivalentes
\[
p = (Se + Sp - 1)\,\theta + (1-Sp)
\]

\[
\theta = \frac{p + Sp - 1}{Se + Sp - 1}
\]

### Casos límite
\[
\theta = 0 \Rightarrow p = 1 - Sp
\]
\[
\theta = 1 \Rightarrow p = Se
\]

---

## 2.0.3 Comportamiento de $p = P(T=1)$

### Fórmula base
\[
p(\theta,Se,Sp) = Se\,\theta + (1-Sp)(1-\theta)
\]

### Valores de referencia
\[
Se = 0.9, \quad Sp = 0.95, \quad \theta = 0.25
\]
\[
p(0.25) = 0.2625
\]

---

## $p$ vs $\theta$ (fijos $Se$, $Sp$)

### Comportamiento
- **Lineal creciente** en $\theta$


### Límites
\[
\theta = 0 \Rightarrow p = 1 - Sp = 0.05
\]
\[
\theta = 1 \Rightarrow p = Se = 0.9
\]

### Interpretación
- **$\theta$ bajo**: $p$ dominada por falsos positivos
- **$\theta$ alto**: $p$ dominada por verdaderos positivos

---

## $p$ vs $Se$ (fijos $\theta$, $Sp$)

### Comportamiento
- **Lineal creciente** en $Se$
- Pendiente: $\theta = 0.25$

### Efecto
- **$Se$ baja**: Pocos verdaderos positivos
- **$Se$ alta**: Mejor detección → $p$ mayor

### Para $Se = 0.9$:
\[
p = 0.9 \times 0.25 + 0.05 \times 0.75 = 0.2625
\]

---

## $p$ vs $Sp$ (fijos $\theta$, $Se$)

### Comportamiento
- **Lineal decreciente** en $Sp$
- Pendiente: $-(1-\theta) = -0.75$

### Efecto
- **$Sp$ baja**: Muchos falsos positivos → $p$ alto
- **$Sp$ alta**: Menos falsos positivos → $p$ bajo

### Para $Sp = 0.95$:
\[
p = 0.225 + 0.05 \times 0.75 = 0.2625
\]

---

## Conclusiones clave

### Relaciones lineales
1. **$p \nearrow$ con $\theta$** 
2. **$p \nearrow$ con $Se$** 
3. **$p \searrow$ con $Sp$** 

---

## 2.1.4 Estimador de momentos (MoM) 

### Fórmula final
\[
\boxed{\hat{\theta}_{MoM} = \frac{\hat{p}_{MoM} + S_p - 1}{S_e + S_p - 1}}
\]

### Donde
\[
\hat{p}_{MoM} = \frac{T_{per}}{n}
\]

---

## 2.1.5 Propiedades del estimador MoM

### Sesgo
\[
\boxed{\mathbb{E}[\hat{\theta}_{MoM}] = \theta}
\]
**Conclusión**: Estimador insesgado

### Varianza
\[
\boxed{\operatorname{Var}(\hat{\theta}_{MoM}) = \frac{p(1-p)}{n(S_e+S_p-1)^2}}
\]

### Error Cuadrático Medio
\[
\boxed{\text{ECM}(\hat{\theta}_{MoM}) = \frac{p(1-p)}{n(S_e+S_p-1)^2}}
\]
(Sesgo = 0 → ECM = Varianza)

---

## Consistencia y forma de $p$

### Consistencia
\[
\boxed{\hat{\theta}_{MoM} \xrightarrow{c.s.} \theta}
\]
- $\hat{p}_{MoM} \xrightarrow{c.s.} p$ (Ley fuerte)
- Función continua de $\hat{p}_{MoM}$

---

## 2.1.6 Comparación ECM: Test perfecto vs imperfecto

### Fórmulas
\[
\text{ECM}_{\text{perfecto}} = \frac{\theta(1-\theta)}{n}
\]
\[
\text{ECM}_{\text{imperfecto}} = \frac{p(1-p)}{n(S_e+S_p-1)^2}
\]

### Factor de aumento
\[
\boxed{\frac{1}{(S_e+S_p-1)^2}}
\]

### Para $S_e=0.9$, $S_p=0.95$
\[
S_e+S_p-1 = 0.85 \Rightarrow \frac{1}{0.85^2} \approx 1.38
\]
**ECM 38% mayor** con test imperfecto

---

## Comportamiento en función de $n$

```{r, echo=FALSE, fig.height=4.5}
tita <- 0.25
Se <- 0.9
Sp <- 0.95
p <- (Se + Sp - 1)*tita + (1 - Sp)
ns <- 10:1000

ECM_perfecto <- tita*(1 - tita) / ns
ECM_imperfecto <- p*(1 - p) / (ns * (Se + Sp - 1)^2)

plot(ns, ECM_imperfecto, type="l", col="orange", lwd=2,
     xlab="Tamaño muestral (n)", ylab="ECM",
     main="ECM vs n: Comparación entre tests")
lines(ns, ECM_perfecto, col="blue", lwd=2)

legend("topright", legend=c("Test imperfecto", "Test perfecto"),
       col=c("orange", "blue"), lwd=2, cex=0.9)

```

---

## Conclusiones clave

### Observaciones del gráfico
1. **ECM imperfecto > ECM perfecto** para todo $n$
2. Ambas **decrecen** como $1/n$

---

## 2.1.7 Validación: Teórico vs Simulado

### Diseño de simulación
- $R = 10000$ réplicas
- $n \in \{10, 20, 50, 100, 200\}$
- $\theta = 0.25$, $S_e = 0.9$, $S_p = 0.95$
- Estimador: $\hat{\theta}_{MoM}$

### Valores teóricos
\[
\operatorname{Var}_{\text{teórica}} = \frac{p(1-p)}{n(S_e+S_p-1)^2}
\]
\[
\text{ECM}_{\text{teórico}} = \operatorname{Var}_{\text{teórica}} \quad (\text{sesgo}=0)
\]

---

## Sesgo: Simulado vs Teórico (=0)

```{r, echo=FALSE, fig.height=4}
# Código adaptado para mostrar solo el gráfico
tita <- 0.25
Se <- 0.9
Sp <- 0.95
ns <- c(10, 20, 50, 100, 200)
R <- 10000

resultados <- data.frame(n = ns, bias_sim = NA)

for (i in seq_along(ns)) {
  n <- ns[i]
  p_Y <- Se*tita + (1 - Sp)*(1 - tita)
  est_imp <- numeric(R)
  
  for (r in 1:R) {
    T <- rbinom(n, 1, p_Y)
    p_hat <- mean(T)
    est_imp[r] <- (p_hat - (1 - Sp)) / (Se + Sp - 1)
  }
  resultados$bias_sim[i] <- mean(est_imp) - tita
}

plot(resultados$n, resultados$bias_sim, type="b", pch=19,
     xlab="n", ylab="Sesgo",
     main="Sesgo: Simulado vs Teórico",
     ylim=range(resultados$bias_sim))
abline(h = 0, col="blue", lwd=2, lty=2)
legend("topright", legend=c("Sesgo sim.", "Sesgo teórico (0)"),
       col=c("black","blue"), pch=c(19, NA), lty=c(1,2))
```

---

## Varianza: Simulado vs Teórica

```{r, echo=FALSE, fig.height=4}
# Cálculos para varianza
var_teo <- numeric(length(ns))
var_sim <- numeric(length(ns))

for (i in seq_along(ns)) {
  n <- ns[i]
  p_Y <- Se*tita + (1 - Sp)*(1 - tita)
  est_imp <- numeric(R)
  
  for (r in 1:R) {
    T <- rbinom(n, 1, p_Y)
    p_hat <- mean(T)
    est_imp[r] <- (p_hat - (1 - Sp)) / (Se + Sp - 1)
  }
  var_sim[i] <- var(est_imp)
  var_teo[i] <- (p_Y*(1 - p_Y)) / (n * (Se + Sp - 1)^2)
}

plot(ns, var_sim, type="b", pch=19, xlab="n", ylab="Varianza",
     main="Varianza: Simulado vs Teórica",
     ylim=c(0, max(var_sim, var_teo)))
lines(ns, var_teo, type="b", pch=17, col="blue")
legend("topright", legend=c("Var sim.", "Var teórica"),
       col=c("black","blue"), pch=c(19,17))
```

---

## ECM: Simulado vs Teórico

```{r, echo=FALSE, fig.height=4}
# Cálculos para ECM
ecm_sim <- numeric(length(ns))
ecm_teo <- var_teo  # insesgado

plot(ns, ecm_sim, type="b", pch=19, xlab="n", ylab="ECM",
     main="ECM: Simulado vs Teórico",
     ylim=c(0, max(ecm_sim, ecm_teo)))
lines(ns, ecm_teo, type="b", pch=17, col="blue")
legend("topright", legend=c("ECM sim.", "ECM teórico"),
       col=c("black","blue"), pch=c(19,17))
```


---

## Conclusiones de la validación

### Confirmaciones
1. **Sesgo aprox 0** en simulación → Insesgabilidad verificada
2. **Varianza simulada aprox Varianza teórica** para todo $n$
3. **ECM simulada aprox ECM teórico** → Fórmulas correctas

### Comportamiento observado
- **Convergencia**: A mayor $n$, mejor ajuste teórico-simulado
- **Consistencia**: Var/ECM decrecen como $1/n$
- **Robustez**: Fórmulas teóricas válidas aún para $n$ pequeño

### Implicaciones
- **Expresiones teóricas** son confiables
- **Estimador MoM** se comporta según teoría
- **Simulación** valida aproximaciones asintóticas

---

## 2.1.8 Bootstrap para $\hat{\theta}_{MoM}$ ($n=10$)

### Parámetros
- $\theta = 0.25$, $S_e = 0.9$, $S_p = 0.95$
- $n = 10$, $B = 5000$ réplicas bootstrap
- Bootstrap no paramétrico

### Método
1. Muestra original: $T_i \sim \text{Bernoulli}(p)$
2. Remuestreo con reemplazo
3. Recalcular $\hat{\theta}_{MoM}$ en cada réplica

---

## Distribución bootstrap ($n=10$)

```{r, echo=FALSE, fig.height=4.5}
tita <- 0.25
Se <- 0.9
Sp <- 0.95
n <- 10
B <- 5000

# Probabilidad real
p_Y <- Se * tita + (1 - Sp) * (1 - tita)

# Muestra original
set.seed(123)  # Para reproducibilidad
T_original <- rbinom(n, 1, p_Y)

# Bootstrap
boot_est <- numeric(B)
for (b in 1:B) {
  T_boot <- sample(T_original, size = n, replace = TRUE)
  p_hat_boot <- mean(T_boot)
  boot_est[b] <- (p_hat_boot - (1 - Sp)) / (Se + Sp - 1)
}

# Histograma
hist(boot_est, breaks = 15, freq = TRUE, col = "lightblue",
     main = "Distribución bootstrap - n = 10",
     xlab = expression(hat(theta)["MoM"]), 
     ylab = "Frecuencia", border = "darkblue")
abline(v = tita, col = "red", lwd = 3, lty = 2)
abline(v = mean(boot_est), col = "darkgreen", lwd = 2, lty = 2)
legend("topright", legend = c(expression(theta*" verdadero"), "Media bootstrap"),
       col = c("red", "darkgreen"), lwd = c(3, 2), lty = c(2, 2), cex = 0.8)
```

---

## Resultados bootstrap

### Estadísticas clave
\[
\text{Media bootstrap} = `r round(mean(boot_est), 4)`
\]
\[
\text{Sesgo bootstrap} = `r round(mean(boot_est) - tita, 4)`
\]
\[
\text{Desvío bootstrap} = `r round(sd(boot_est), 4)`
\]

### Características observadas
1. **Alta dispersión** (gran variabilidad)
2. **Sesgo positivo** 
3. **Distribución asimétrica** hacia derecha
4. **Valores fuera de [0,1]** posibles

---

## IC Bootstrap Percentil - Método

### Objetivo
Construir IC para $\theta$ usando bootstrap no paramétrico

### Algoritmo
1. Para cada $n \in \{10, 20, 50, 100, 1000\}$
2. $R = 700$ réplicas Monte Carlo
3. $B = 1000$ remuestreos bootstrap
4. Calcular $\hat{\theta}_{MoM}$ en cada bootstrap
5. IC = cuantiles 2.5% y 97.5%

### Fórmula bootstrap
\[
IC_{\text{boot}}^{0.95} = \left[ Q_{0.025}(\hat{\theta}^*), Q_{0.975}(\hat{\theta}^*) \right]
\]
donde $\hat{\theta}^*$ son estimaciones bootstrap

---

## IC Asintótico - Resultado final

### Estimador y varianza estimada
\[
\hat{\theta}_{MoM} = \frac{\hat{p} + S_p - 1}{S_e + S_p - 1}
\]
\[
\widehat{\operatorname{Var}}(\hat{\theta}_{MoM}) = \frac{\hat{p}(1-\hat{p})}{n(S_e+S_p-1)^2}
\]

### Intervalo de confianza 95%
\[
\boxed{IC_{\text{asint}}^{0.95} = \hat{\theta}_{MoM} \pm 1.96\sqrt{\frac{\hat{p}(1-\hat{p})}{n(S_e+S_p-1)^2}}}
\]

### Fundamentos
- **TCL + Método Delta** → Normalidad asintótica
- **Slutsky** → Reemplazar $p$ por $\hat{p}$
- **Nivel**: 0.95 asintótico ($z_{0.975} = 1.96$)

---

## Resultados: Bootstrap vs Asintótico

### Cubrimiento empírico y longitud

```{r, echo=FALSE}
# Tabla Bootstrap
res_df <- data.frame(
  n = c(10, 20, 50, 100, 1000),
  cubrimiento = c(0.9329, 0.9186, 0.9314, 0.9429, 0.9514),
  longitud = c(0.5680, 0.4285, 0.2782, 0.2006, 0.0638)
)

knitr::kable(res_df, digits = 4, 
             col.names = c("n", "Cubrimiento", "Longitud media"),
             caption = "IC Bootstrap Percentil (R=700, B=1000)")
```

---

## Resultados: Intervalos Asintóticos

```{r, echo=FALSE}
# Tabla Asintótico
resAsint_df <- data.frame(
  n = c(10, 20, 50, 100, 1000),
  cubrimiento = c(0.9257, 0.9186, 0.9200, 0.9414, 0.9457),
  longitud = c(0.5930, 0.4366, 0.2836, 0.2013, 0.0641)
)

knitr::kable(resAsint_df, digits = 4,
             col.names = c("n", "Cubrimiento", "Longitud media"),
             caption = "IC Asintótico (R=700)")
```

---

### Conclusiones
1. **Bootstrap más robusto** para $n$ pequeño
2. **Asintótico adecuado** para $n \geq 50$
3. **Longitudes similares** en ambos métodos
4. **Convergencia** cuando $n$ crece

---

## 2.2.9 Intervalos de confianza bootstrap

### Objetivo
Construir intervalos de confianza para $\theta$ basados en el estimador de momentos  
utilizando bootstrap no paramétrico.

### Método
- A partir de los datos ${T_i}$ se calcula $\hat\theta_{MoM}$ en cada remuestreo.
- Se generan $B = 1000$ réplicas bootstrap:  
  $\hat\theta^{*(b)}_{MoM}$, $b = 1,\dots,B$.
- Intervalo bootstrap percentil:
\[
IC^{boot}_{0.95} = 
\big[\, Q_{0.025}(\hat\theta^{*}),\; Q_{0.975}(\hat\theta^{*}) \,\big].
\]

### Simulación Monte Carlo
- Replicaciones: $R = 700$.
- Tamaños muestrales: $n \in \{10, 20, 50, 100, 1000\}$.
- Para cada réplica se obtiene:
  - **Cubrimiento empírico**: $\mathbb{1}\{\theta \in IC^{boot}\}$
  - **Longitud**: $IC^{up} - IC^{low}$

---

### Resultados (resumen)
- Buen cubrimiento para todos los $n$.
- Robusto para $n$ pequeños.
- Longitud disminuye al aumentar $n$.

---

## 2.2.10 Intervalo de confianza asintótico

### Idea
A partir del estimador de momentos:
\[
\hat\theta_{MoM}=\frac{\hat p + Sp - 1}{Se + Sp - 1},
\]
donde $\hat p = T_{\text{per}}/n$.

### Varianza estimada
\[
\widehat{\mathrm{Var}}(\hat\theta_{MoM}) =
\frac{\hat p(1 - \hat p)}{n(Se + Sp - 1)^2}.
\]

### Intervalo de confianza asintótico (95%)
\[
IC^{asint}_{0.95}
= 
\hat\theta_{MoM}
\pm
1.96\,
\sqrt{
\frac{\hat p(1 - \hat p)}{n(Se + Sp - 1)^2}
}.
\]

### Fundamentación teórica
- TCL aplicado a $\hat p$  
- Método Delta para la transformación  
- Slutsky justifica reemplazar $p$ por $\hat p$

---

## 2.2.10 Resultados: Intervalos Asintóticos

### Cubrimiento empírico y longitud media

\begin{table}[H]
\centering
\begin{tabular}{ccc}
\hline
$n$ & Cubrimiento & Longitud media \\
\hline
10   & 0.9257 & 0.5930 \\
20   & 0.9186 & 0.4366 \\
50   & 0.9200 & 0.2836 \\
100  & 0.9414 & 0.2013 \\
1000 & 0.9457 & 0.0641 \\
\hline
\end{tabular}
\end{table}

### Observaciones
- Cubrimiento similar al bootstrap para $n \ge 50$.## 2.2.11 Comparación entre IC Bootstrap y Asintótico

### Métricas comparadas
- **Cubrimiento empírico**
- **Longitud promedio del intervalo**
- **Comportamiento según n**

### Resultados generales
- Ambos métodos alcanzan cubrimiento cercano a 0.95.
- Para **n pequeño**, el *bootstrap percentil*:
  - Tiene **mejor cubrimiento**.
  - Produce intervalos **ligeramente más cortos**.
- El IC asintótico depende de la aproximación normal:
  - Se vuelve confiable recién para **n ≥ 50**.
- Para n grande, ambos intervalos **convergen** y son casi indistinguibles.

---

## 2.2.11 Comparación: Bootstrap vs Asintótico

### Cubrimiento y longitud media (R = 700)

\begin{table}[H]
\centering
\begin{tabular}{ccccc}
\hline
$n$ & Cub. Boot & Len. Boot & Cub. Asint & Len. Asint \\
\hline
10   & 0.9329 & 0.5680 & 0.9257 & 0.5930 \\
20   & 0.9186 & 0.4285 & 0.9186 & 0.4366 \\
50   & 0.9314 & 0.2782 & 0.9200 & 0.2836 \\
100  & 0.9429 & 0.2006 & 0.9414 & 0.2013 \\
1000 & 0.9514 & 0.0638 & 0.9457 & 0.0641 \\
\hline
\end{tabular}
\end{table}

### Conclusión
- Bootstrap es **más robusto** para muestras chicas.
- Asintótico funciona bien a partir de tamaños moderados.
- En ambos casos, la longitud disminuye con n.

- Intervalo ligeramente más largo que el bootstrap.
- A medida que $n$ crece, ambos métodos se vuelven casi indistinguibles.

---

## 2.3.12 Comportamiento del estimador de momentos

### Definición
El estimador de momentos se obtiene de:
\[
p = Se\,\theta + (1-Sp)(1-\theta)
\]
y reemplazando \(p\) por \(\hat p = T_{\text{per}}/n\):
\[
\hat{\theta}_{MoM} =
\frac{\hat p + Sp - 1}{Se + Sp - 1}.
\]

### Observación clave
- Aunque \(\hat p \in [0,1]\), la transformación es **lineal**, por lo que  
  \(\hat\theta_{MoM}\) **puede salir de \([0,1]\)**.
- Esto ocurre cuando la muestra tiene demasiados o muy pocos positivos.

### Condiciones
\[
\hat\theta_{MoM} < 0
\quad\Longleftrightarrow\quad
\hat p < 1 - Sp,
\]
\[
\hat\theta_{MoM} > 1
\quad\Longleftrightarrow\quad
\hat p > Se.
\]

---

## Ejemplos numéricos

### Valores de referencia
\[
Se = 0.9, \quad Sp = 0.95,
\qquad
1 - Sp = 0.05, \quad Se + Sp - 1 = 0.85.
\]

### Ejemplo 1: \(\hat\theta_{MoM} < 0\)
Si no hay positivos en la muestra:
\[
\hat p = 0.
\]
Entonces:
\[
\hat\theta_{MoM}
= \frac{0 + 0.95 - 1}{0.85}
= \frac{-0.05}{0.85}
\approx -0.0588.
\]

### Ejemplo 2: \(\hat\theta_{MoM} > 1\)
Si la muestra da un valor extremo:
\[
\hat p = 0.95,
\]
entonces:
\[
\hat\theta_{MoM}
= \frac{0.95 + 0.95 - 1}{0.85}
= \frac{0.90}{0.85}
\approx 1.0588.
\]

### Conclusión
- El estimador puede quedar fuera del intervalo válido para una probabilidad.
- Motivación para introducir el **estimador truncado**.

---

## 2.3.13 Estudio del estimador truncado

### Motivación
El estimador de momentos puede tomar valores fuera de \([0,1]\).  
Para evitar valores imposibles se define el estimador **truncado**:

### Definición
\[
\hat\theta_{\text{trunc}} =
\begin{cases}
\hat\theta_{\text{MoM}}, & 0 \le \hat\theta_{\text{MoM}} \le 1,\\[6pt]
0, & \hat\theta_{\text{MoM}} < 0,\\[6pt]
1, & \hat\theta_{\text{MoM}} > 1.
\end{cases}
\]

### Interpretación
- Coincide con \(\hat\theta_{MoM}\) cuando este es válido.
- Recorta valores negativos a 0 y mayores a 1 a 1.
- Introduce **sesgo** para muestras pequeñas, pero evita valores inaceptables.

---

## Simulación Monte Carlo del estimador truncado

### Parámetros usados
- \(\theta = 0.25\), \(Se = 0.9\), \(Sp = 0.95\)
- Tamaños muestrales: \(n = 10,\,100,\,1000\)
- Réplicas: \(N_{\text{rep}} = 10000\)

### Para cada réplica:
1. Generar \(T \sim \text{Binomial}(n, p_{verdadera})\)
2. Calcular \(\hat\theta_{\text{trunc}}\)
3. Estimar:
   - media  
   - sesgo  
   - varianza  
   - ECM = Sesgo\(^2\) + Var

### Tabla de resultados
\begin{table}[H]
\centering
\begin{tabular}{ccccc}
\hline
$n$ & media & sesgo & var & ECM \\
\hline
10   & 0.2485 & -0.00149 & 0.02463 & 0.02463 \\
100  & 0.25005 & 0.000048 & 0.002685 & 0.002685 \\
1000 & 0.25007 & 0.000067 & 0.000263 & 0.000263 \\
\hline
\end{tabular}
\end{table}

---

## Análisis del estimador truncado

### Sesgo
- Para \(n = 10\), el estimador muestra sesgo apreciable.  
  Esto ocurre porque \(\hat\theta_{MoM}\) cae a menudo por debajo de 0 y se trunca.
- El sesgo → 0 cuando \(n\) aumenta (coincide con el estimador original).

### Varianza
- Disminuye al crecer \(n\).
- Para \(n = 10\) es elevada por la alta variabilidad de \(\hat p\).
- Para \(n = 1000\) es muy baja y estable.

### ECM
\[
ECM = \text{Sesgo}^2 + \text{Var}.
\]
- Para muestras pequeñas, ECM grande por sesgo + varianza.
- Para muestras grandes, el ECM es muy pequeño.

### Conclusión
El estimador truncado:
- **es consistente**,  
- **es asintóticamente equivalente** al estimador de momentos,  
- pero **distorsiona muestras pequeñas** debido al truncamiento.

---

## Distribución del estimador truncado

```{r, echo = FALSE}
set.seed(43)
par(mfrow = c(2, 2))  ## grid para los gráficos

for (n in n_valores) {
  # nueva data para cada n
  T_sim <- rbinom(N_rep, size = n, prob = p_verdadera)
  theta_trunc_sim <- theta_trunc(T_sim, n)
  
  # Histograma
  hist(theta_trunc_sim,
       breaks = 40,
       main = paste("Histograma de theta_trunc, n =", n),
       xlab = expression(hat(theta)[trunc]),
       probability = TRUE)
  
  media_hat <- mean(theta_trunc_sim)
  sd_hat    <- sd(theta_trunc_sim)
  x_grid    <- seq(0, 1, length.out = 200)
  lines(x_grid, dnorm(x_grid, mean = media_hat, sd = sd_hat), col = "red")
}

par(mfrow = c(1, 1))

n <- 1000
T_sim <- rbinom(N_rep, size = n, prob = p_verdadera)
theta_trunc_sim <- theta_trunc(T_sim, n)

qqnorm(theta_trunc_sim,
       main = expression(paste("QQ-plot de ", hat(theta)[trunc], " para n=1000")),
       xlab= "",
       ylab= "")
qqline(theta_trunc_sim)

```

---

### Observaciones de la simulación
- Para \(n = 10\):  
  - La distribución muestra **acumulación en 0 y 1**.  
  - No es aproximadamente normal.
- Para \(n = 100\):  
  - La masa en los bordes disminuye.  
  - La distribución empieza a ser unimodal y más suave.
- Para \(n = 1000\):  
  - El truncamiento ocurre con probabilidad casi nula.  
  - La distribución es bien aproximada por una normal:
\[
\hat\theta_{\text{trunc}} \approx
\mathcal{N}\left(
\theta,\;
\frac{p(1-p)}{n(Se+Sp-1)^2}
\right).
\]

### Conclusión general
- Para muestras grandes, el estimador truncado **preserva la distribución asintótica del MoM**.

---


