---
title: "Trabajo Práctico – IECD"
author: "Grupo 11"
date: "2025-12-08"
output:
  beamer_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introducción

## Objetivo del trabajo

Análisis de propiedades estadísticas de tests diagnósticos:

1. **Test perfecto** (baseline)
2. **Test imperfecto** con $S_e$ y $S_p$ conocidos  
3. **Dos muestras** (pre-post intervención)

---

\centering
\vspace{2cm}
\Huge
**Parte I**  
\Large
Test perfecto (baseline)

---

# 1.1 Distribución de $T_{per}$

## Motivación

- Estudiamos primero un caso ideal: el test diagnóstico **no comete errores**.
- Esto equivale a suponer:
  \[
  Se = 1, \qquad Sp = 1.
  \]
- En este escenario, el resultado del test coincide exactamente con el estado verdadero $Y$.
- Objetivo del punto 1.1:
  \[
  \text{Mostrar que } T_{per} \sim \text{Binomial}(n,\theta).
  \]

---

## Modelo del estado verdadero

- Cada individuo $i$ puede estar enfermo ($Y_i = 1$) o sano ($Y_i = 0$).
- Modelamos:
  \[
  Y_i \sim \text{Bernoulli}(\theta), \qquad i = 1,\dots,n,
  \]
  donde $\theta = P(Y = 1)$ es la prevalencia verdadera.
- Como $Se = Sp = 1$:
  - lo que observamos en el test coincide exactamente con $Y_i$;
  - no hay error de medición.
  
---

## Número de individuos enfermos en la muestra

- Definimos:
  \[
  T_{per} = \sum_{i=1}^n Y_i.
  \]

- Interpretación:
  - $T_{per}$ cuenta la cantidad de personas enfermas en la muestra.
  - Es la suma de $n$ variables Bernoulli independientes con el mismo parámetro $\theta$.
  
---

## Resultado

- La suma de $n$ variables Bernoulli independientes con parámetro $\theta$ sigue una binomial:
  \[
  T_{per} \sim \text{Binomial}(n,\theta).
  \]

- Para $k = 0,1,\dots,n$:
  \[
  P(T_{per} = k)
    = \binom{n}{k} \theta^k (1 - \theta)^{n-k}.
  \]

De esta forma, $T_{per} \sim \text{Binomial}(n, \theta)$

---

## 1.2 Estimador de Máxima Verosimilitud

## Planteo

- Seguimos en el caso de **test perfecto**:
  \[
  Y_i \sim \text{Bernoulli}(\theta), \quad i = 1,\dots,n,
  \]
  independientes e idénticamente distribuidas.
- Definimos:
  \[
  T_{per} = \sum_{i=1}^n Y_i.
  \]
- Nuestro objetivo en este punto es encontrar el **estimador de máxima verosimilitud (EMV)** de $\theta$.

- Notación útil:
  - $N_1 = \sum_{i=1}^n Y_i = T_{per}$: número de enfermos en la muestra.
  - $N_0 = n - N_1$: número de sanos en la muestra.

---

## Función de verosimilitud

- Dada la muestra $Y_1,\dots,Y_n$, la función de verosimilitud es:
  \[
  L(\theta)
    = \prod_{i=1}^n P_\theta(Y_i)
    = \prod_{i=1}^n \theta^{Y_i} (1-\theta)^{1-Y_i}.
  \]

- Reagrupando términos:
  \[
  L(\theta)
    = \theta^{\sum_{i=1}^n Y_i}
      (1-\theta)^{\sum_{i=1}^n (1-Y_i)}
    = \theta^{N_1} (1-\theta)^{N_0}.
  \]

- Trabajamos con la **log-verosimilitud**:
  \[
  \ell(\theta) = \log L(\theta)
    = N_1 \log(\theta) + N_0 \log(1-\theta).
  \]

---

- Derivamos la log-verosimilitud respecto de $\theta$:
  \[
  \ell'(\theta)
    = \frac{d}{d\theta}\big[\,N_1 \log(\theta) + N_0 \log(1-\theta)\,\big]
    = \frac{N_1}{\theta} - \frac{N_0}{1-\theta}.
  \]

- Buscamos $\hat{\theta}$ tal que $\ell'(\hat{\theta}) = 0$:
  \[
  \frac{N_1}{\hat{\theta}} - \frac{N_0}{1-\hat{\theta}} = 0
  \quad\Longrightarrow\quad
  \frac{N_1}{\hat{\theta}} = \frac{N_0}{1-\hat{\theta}}.
  \]

- Despejando:
  \[
  N_1 (1-\hat{\theta}) = N_0 \hat{\theta}
  \quad\Longrightarrow\quad
  N_1 = (N_0 + N_1)\hat{\theta} = n\,\hat{\theta}.
  \]

- Por lo tanto:
  \[
  \hat{\theta}_{per} = \frac{N_1}{n}.
  \]

---

## Verificación de máximo e interpretación

- Segunda derivada:
  \[
  \ell''(\theta)
    = -\frac{N_1}{\theta^2} - \frac{N_0}{(1-\theta)^2} < 0
    \quad \text{para todo } \theta \in (0,1).
  \]
- Luego, el punto crítico encontrado corresponde a un **máximo global** de la verosimilitud.

- Como $N_1 = T_{per}$, podemos escribir:
  \[
  \hat{\theta}_{per}
    = \frac{N_1}{n}
    = \frac{T_{per}}{n}.
  \]

### Interpretación

- El EMV de $\theta$ es simplemente la **proporción muestral de individuos enfermos**.
- En el caso de test perfecto, el estimador natural de la prevalencia es la cantidad de enfermos observados / tamaño de la muestra.

---

## 1.3 Sesgo, Varianza, Error cuadrático medio, consistencia y distribución asintótica

* **Sesgo:**  
  El estimador \(\hat{\theta}_{per} = \frac{T_{\text{per}}}{n}\) es insesgado porque
  \[
  \mathbb{E}[\hat{\theta}_{per}]
    = \mathbb{E}\left[\frac{T_{\text{per}}}{n}\right]
    = \frac{1}{n}\mathbb{E}[T_{\text{per}}]
    = \frac{n\theta}{n}
    = \theta.
  \]
  Usamos que \(T_{\text{per}} \sim \mathrm{Binomial}(n,\theta)\), por lo que  \(\mathbb{E}[T_{\text{per}}] = n\theta\).

---

* **Varianza:**  
  \[
  \operatorname{Var}(\hat{\theta}_{per})
    = \operatorname{Var}\left(\frac{T_{\text{per}}}{n}\right)
    = \frac{1}{n^2}\operatorname{Var}(T_{\text{per}})
    = \frac{n\theta(1-\theta)}{n^2}
    = \frac{\theta(1-\theta)}{n}.
  \]
  También utilizamos que \(T_{\text{per}}\) es binomial.
  
\vspace{0.5cm}

* **Error cuadrático medio (ECM):**  
  Como el sesgo es cero,
  \[
  \text{ECM}(\hat{\theta}_{per})
    = \operatorname{Var}(\hat{\theta}_{per})
    + \mathbb{B}^2(\hat{\theta}_{per})
    = \frac{\theta(1-\theta)}{n}.
  \]

---

* **Consistencia:**  
  Observamos que \(\hat{\theta}_{per} = \frac{T_{\text{per}}}{n} = \frac{1}{n}\sum_{i=1}^n Y_i\),  
  donde \(\mathbb{E}[Y_i] = \theta\) y \(\operatorname{Var}(Y_i)=\theta(1-\theta)\).  
  Por la Ley Fuerte de los Grandes Números,
  \[
  \hat{\theta}_{per} \xrightarrow{c.s.} \theta.
  \]
  Por lo tanto, \(\hat{\theta}_{per}\) es **fuertemente consistente**.

\vspace{0.5cm}

* **Distribución asintótica:**  
  Por el Teorema Central del Límite,
  \[
  \sqrt{n}\,(\hat{\theta}_{per} - \theta)
  \xrightarrow{d} N\bigl(0,\theta(1-\theta)\bigr).
  \]

---

## 1.4 Intervalo de confianza para $\theta$

* Sabemos que por TCL:

\[
\sqrt{n}\,\frac{(\hat{\theta}_{per} - \theta)}{\sqrt{\theta(1-\theta)}}
\xrightarrow{d} N\bigl(0,1\bigr).
\]

* Además, por ley débil de los grandes números:

\[
\hat{\theta}_{per} \xrightarrow{p} \theta
\]

---

* Entonces, combinando los resultados anteriores con Slutsky:

\[
\sqrt{n}\,\frac{(\hat{\theta}_{per} - \theta)}{\sqrt{\hat{\theta}_{per}(1-\hat{\theta}_{per})}}
\xrightarrow{d} N\bigl(0,1\bigr).
\]

Como $P(Z\ge1.96) = 0.025$, vale lo siguiente:

\[
P\!\left(-1.96 \le \sqrt{n}\,\frac{\hat{\theta}_{per} - \theta}{\sqrt{\hat{\theta}_{per}(1-\hat{\theta}_{per})}} \le 1.96\right)
\xrightarrow[n\to\infty]{} 0.95.
\]

---

* Finalmente, se deduce el siguiente intervalo de nivel asintótico 0.95:

\[
\boxed{IC_{0.95}(\theta) = \hat{\theta}_{per} \pm 1.96\sqrt{\frac{\hat{\theta}_{per}(1-\hat{\theta}_{per})}{n}}}
\]

---

## 1.5 Cubrimiento empírico

* Para evaluar el cubrimiento empírico del intervalo dado en $1.4$, se llevó a cabo una simulación Monte Carlo para los siguientes valores de n:

\[
10, 20, 50, 100, 1000, 10000
\]


```{r, echo=FALSE, eval=TRUE, size="tiny"}
#fijamos la semilla que se va a utilizar durante todo el tp.
set.seed(43)

tita <- 0.25
ns <- c(10, 20, 50, 100, 1000, 10000) #valores de n para los cuales vamos a evaluar la cobertura
Nrep <- 5000                          #empirica
z <- qnorm(0.975)

cubrimientoN <- 0

#para cada n:
for (j in seq_along(ns)){
  n <- ns[j]
  cubrimiento <- 0
  
  #repito el experimento 5000 veces.
  for(i in 1:Nrep){                                         
    muestra <- rbinom(1,n,tita)
    
    estTita <- muestra/n
    termino <- z * sqrt((estTita*(1-estTita))/n)
    intervalo <- c(estTita - termino, estTita + termino)
    
    cubrimiento[i] <- intervalo[1] <= tita && tita <= intervalo[2]
  }
  
  #promedio de veces que el valor real de tita cayó en el intervalo
  cubrimientoN[j] <- mean(cubrimiento)                  
}

cubrimientoEmpirico <- data.frame(n = ns, cubrimiento = cubrimientoN)
```
---

* Y se obtuvieron estos resultados:

```{r, echo=FALSE, eval=TRUE}
knitr::kable(cubrimientoEmpirico, digits = 4, caption = "Cubrimiento empírico del intervalo")
```

---


* Los resultados obtenidos son coherentes con la teoría. Al tratarse de un intervalo asintótico, el cubrimiento empírico converge hacia el nivel nominal del 0.95 conforme aumenta el tamaño muestral n.

---

\centering
\vspace{2cm}
\Huge
**Parte II**  
\Large
Test imperfecto con $S_e$ y $S_p$ conocidos

---

## 2.0.1 Estimación de $p$ con $T_{per}$

## Nuevo escenario

- Ahora el test **no es perfecto**.
- Características del test:
  \[
  Se = P(T = 1 \mid Y = 1), \qquad Sp = P(T = 0 \mid Y = 0).
  \]
- El resultado observado del test se llama $T$ (1 = positivo, 0 = negativo).

- En este punto definimos:
  \[
  p = P(T = 1)
  \]
  es decir, la **probabilidad de que el test dé positivo**.
  
---

## Datos observados

- Tomamos una muestra de tamaño $n$.
- Para cada individuo observamos el resultado del test:
  \[
  T_1, T_2, \dots, T_n \sim \text{i.i.d. Bernoulli}(p).
  \]

- Definimos:
  \[
  T_{per} = \sum_{i=1}^n T_i,
  \]
  que ahora representa **la cantidad de tests positivos**, no la cantidad de enfermos reales.

- Entonces:
  \[
  T_{per} \sim \text{Binomial}(n,p).
  \]
  
---

## Construcción del estimador

- La esperanza de la variable binomial es:
  \[
  E[T_{per}] = np.
  \]

- El estimador natural es la proporción de tests positivos observados:
  \[
  \hat{p} = \frac{T_{per}}{n}.
  \]

### Propiedades inmediatas

- Es el **estimador de máxima verosimilitud** para $p$.
- Es el **estimador de momentos** para $p$.
- Es simplemente:
  \[
  \hat{p} = \text{proporción muestral de tests positivos}.
  \]

---

## Interpretación

- En el caso imperfecto, $\hat{p}$ NO es un estimador directo de la prevalencia.
- $\hat{p}$ mide qué fracción de la muestra obtuvo un resultado positivo en el test

- Más adelante usaremos la relación entre $p$, $\theta$, $Se$ y $Sp$ para estimar $\theta$.

- Esta relación clave será:
  \[
  p = P(T = 1) = Se \cdot \theta + (1 - Sp)(1 - \theta).
  \]
  *(Item 2.0.2)*

- Por ahora, lo único que necesitamos es:
  \[
  \hat{p} = \frac{T_{per}}{n}.
  \]

---

## 2.0.2 $p$ como función de $\theta$, $S_{e}$ y $S_{p}$.

## Objetivo

- Queremos expresar:
  \[
  p = P(T = 1)
  \]
  en función de:
  - la prevalencia verdadera $\theta = P(Y=1)$,
  - la sensibilidad $Se$,
  - la especificidad $Sp$.

- Esta relación permitirá, más adelante, **estimar $\theta$** usando el test imperfecto.

---

## Paso 1: Probabilidad total

\[
p = P(T = 1)
\]

Descomponemos según el estado verdadero $Y$:

\[
P(T = 1)
  = P(T = 1 \mid Y = 1)P(Y=1)
  + P(T = 1 \mid Y = 0)P(Y=0).
\]

Reemplazamos:

- $P(T=1 \mid Y=1) = Se$,
- $P(Y=1) = \theta$,
- $P(Y=0) = 1 - \theta$,
- $P(T=1 \mid Y=0) = 1 - Sp$.

Obtenemos:

\[
p = Se \cdot \theta + (1 - Sp)(1 - \theta).
\]

---

## Forma final

Podemos escribir:

\[
p = (Se + Sp - 1)\,\theta + (1 - Sp).
\]

### Observaciones

- La expresión es **lineal en $\theta$**.
- El coeficiente $(Se + Sp - 1)$ determina la “calidad” del test.
  - Si $Se + Sp - 1 = 0$, el test **no aporta información** (p = 1 - Sp).
  - Si $Se + Sp - 1 > 0$, el test permite recuperar parte de la prevalencia.
- El término constante $(1 - Sp)$ es la **probabilidad de falso positivo** cuando $$\theta$ = 0$.

---

## ¿Qué nos dice esta fórmula?

- El test puede dar positivo por dos razones:
  1. **Verdadero positivo**: la persona está enferma y el test la detecta.
     \[
     Se \cdot \theta
     \]
  2. **Falso positivo**: la persona está sana pero el test falla.
     \[
     (1 - Sp)(1 - \theta)
     \]

- Por eso, la probabilidad total de test positivo es:
  \[
  p = \text{Verdaderos positivos} + \text{Falsos positivos}.
  \]

---

## 2.0.3 Comportamiento de $p = P(T=1)$

## Recordatorio

- Tenemos:
  \[
  p = P(T = 1) = Se \cdot \theta + (1 - Sp)(1 - \theta).
  \]
- También:
  \[
  p(\theta, Se, Sp) = (Se + Sp - 1)\,\theta + (1 - Sp).
  \]

- En este punto queremos ver cómo cambia $p$ en función de:
  1. $\theta$ (prevalencia),
  2. $Se$ (sensibilidad),
  3. $Sp$ (especificidad),

  fijando los otros dos parámetros.
  
---

## Caso (a): variamos $\theta$, fijamos $Se$ y $Sp$

- Fijamos:
  \[
  Se = 0.9, \qquad Sp = 0.95.
  \]
- En función de $\theta$:
  \[
  p(\theta) = Se \cdot \theta + (1 - Sp)(1 - \theta).
  \]

- Esto es una **función lineal y creciente** en $\theta$.

- Valores extremos:
  - Si $\theta \to 0$:
    \[
    p(\theta) \approx 1 - Sp = 0.05
    \quad \text{(sólo falsos positivos).}
    \]
  - Si $\theta = 1$:
    \[
    p(1) = Se = 0.9
    \quad \text{(todos enfermos, sólo verdaderos positivos).}
    \]

- Para $\theta = 0.25$:
  \[
  p(0.25) = 0.9 \times 0.25 + 0.05 \times 0.75 = 0.2625.
  \]

---

```{r, echo=FALSE}

## Valores fijos
Se_fijo  <- 0.9
Sp_fijo  <- 0.95
theta_fijo <- 0.25

## a
theta_grid <- seq(0, 1, length.out = 1000)
p_theta <- Se_fijo * theta_grid + (1 - Sp_fijo) * (1 - theta_grid)

plot(theta_grid, p_theta, type = "l",
     xlab = expression(theta),
     ylab = "p",
     main = "Probabilidad de test positivo vs. theta")
abline(v = theta_fijo, col = "gray", lty = 2)
abline(h = Se_fijo * theta_fijo + (1 - Sp_fijo) * (1 - theta_fijo),
       col = "gray", lty = 2)


```

---

## Caso (b): variamos $Se$, fijamos $\theta$ y $Sp$

- Fijamos:
  \[
  \theta = 0.25, \qquad Sp = 0.95.
  \]

- En función de $Se$:
  \[
  p(Se) = Se \cdot \theta + (1 - Sp)(1 - \theta)
        = 0.25 \cdot Se + 0.05 \cdot 0.75.
  \]

- Es una función **lineal y creciente** en $Se$.

- Interpretación:
  - Si $Se$ es muy baja, el test casi no detecta enfermos $\rightarrow$ $p$ se mantiene cerca del nivel de falsos positivos.
  - A medida que aumenta $Se$, sube la proporción de **verdaderos positivos**, y por eso aumenta $p$.

---

```{r, echo=FALSE}
## b
Se_grid <- seq(0, 1, length.out = 1000)
p_Se <- Se_grid * theta_fijo + (1 - Sp_fijo) * (1 - theta_fijo)

plot(Se_grid, p_Se, type = "l",
     xlab = "Se",
     ylab = "p",
     main = "Probabilidad de test positivo vs. sensibilidad")
abline(v = Se_fijo, col = "gray", lty = 2)
abline(h = Se_fijo * theta_fijo + (1 - Sp_fijo) * (1 - theta_fijo),
       col = "gray", lty = 2)
```

---

## Caso (c): variamos $Sp$, fijamos $\theta$ y $Se$

- Fijamos:
  \[
  \theta = 0.25, \qquad Se = 0.9.
  \]

- En función de $Sp$:
  \[
  p(Sp) = Se \cdot \theta + (1 - Sp)(1 - \theta)
        = 0.9 \cdot 0.25 + (1 - Sp)\cdot 0.75.
  \]

- Es una función **lineal y decreciente** en $Sp$.

- Interpretación:
  - Si $Sp$ es baja $\rightarrow$ muchos falsos positivos $\rightarrow$ $p$ es alto, aunque la prevalencia no sea muy grande.
  - Al aumentar $Sp$, se reducen los falsos positivos $\rightarrow$ disminuye $p$.

---

```{r,echo=FALSE}

## c
Sp_grid <- seq(0, 1, length.out = 1000)
p_Sp <- Se_fijo * theta_fijo + (1 - Sp_grid) * (1 - theta_fijo)

plot(Sp_grid, p_Sp, type = "l",
     xlab = "Sp",
     ylab = "p",
     main = "Probabilidad de test positivo vs. especificidad")
abline(v = Sp_fijo, col = "gray", lty = 2)
abline(h = Se_fijo * theta_fijo + (1 - Sp_fijo) * (1 - theta_fijo),
       col = "gray", lty = 2)

```

---

## Comportamiento de $p$

- $p$ vs $\theta$ (con $Se, Sp$ fijos):
  - Recta **creciente**; va de $1-Sp$ hasta $Se$.

- $p$ vs $Se$ (con $\theta, Sp$ fijos):
  - Recta **creciente**; al aumentar $Se$ suben los verdaderos positivos.

- $p$ vs $Sp$ (con $\theta, Se$ fijos):
  - Recta **decreciente**; al aumentar $Sp$ bajan los falsos positivos.

---

## 2.1.4 Estimador de momentos (MoM)

* Por item $2.0.2$, sabemos que:

\[
p = S_{e} \theta + (1-S_{p})(1-\theta)
\]

Reagrupando:
\[
p = (S_{e}+S_{p}-1)\theta + 1 - S_{p}
\]


Entonces:
\[
\theta = \frac{p + S_{p} - 1}{S_{e}+S_{p}-1}
\]

---

* Como $\mathbb{E}[T_{i}] = p$, el estimador de momentos de $p$ es $\hat{p}_{MoM} = \frac{T_{per}}{n}$.

\vspace{0.5cm}

* Finalmente, el estimador plug-in de momentos de $\theta$ es el siguiente:

\[
\boxed{\hat{\theta}_{MoM} = \frac{\hat{p}_{MoM} + S_{p} - 1}{S_{e}+S_{p}-1}}
\]

---

## 2.1.5 Sesgo, varianza y ECM

* **Sesgo**:

  Primero se observa que: 
  
  \[
  \mathbb{E}[\hat{p}_{MoM}] = \mathbb{E}\left[\frac{T_{\text{per}}}{n}\right]= p = (S_{e}+S_{p}-1)\theta + 1 - S_{p}
  \]
  
  Luego:
  
  \[
  \mathbb{E}[\hat{\theta}_{MoM}] = \mathbb{E}\left[\frac{\hat{p}_{MoM}+S_{p}-1}{S_{e}+S_{p}-1}\right] = \frac{\mathbb{E}[\hat{p}_{MoM}] + S_{p} - 1}{S_{e}+S_{p}-1} = \theta
  \]
  
  Por lo tanto $\hat{\theta}_{MoM}$ es un estimador insesgado de $\theta$.

---

* **Varianza**:

  Primero se observa que:

  \[
  Var[\hat{p}_{MoM}] = Var\left[\frac{T_{\text{per}}}{n}\right]=\frac{np(1-p)}{n^2} = \frac{p(1-p)}{n}
  \]
  
  Luego:
  
  \[
  \operatorname{Var}[\hat{\theta}_{MoM}] = \operatorname{Var}\left[\frac{\hat{p}_{MoM}+S_{p}-1}{S_{e}+S_{p}-1}\right] = \frac{\operatorname{Var}[\hat{p}_{MoM} + S_{p} -1]}{(S_{e}+S_{p}-1)^2} =
  \]
  \[
  \frac{\operatorname{Var}[\hat{p}_{MoM}]}{(S_{e}+S_{p}-1)^2} = \frac{p(1-p)}{n(S_{e}+S_{p}-1)^2}
\]

---

* **ECM**:
  
  Como el sesgo es 0:
  
  \[
  \text{ECM}(\hat{\theta}_{MoM})
    = \operatorname{Var}[\hat{\theta}_{MoM}]
    + \mathbb{B}^2[\hat{\theta}_{MoM}]
    =\frac{p(1-p)}{n(S_{e}+S_{p}-1)^2}
  \]

---

* **Consistencia**
  
  Observemos que, por ley fuerte de los grandes números:
  
  \[
  \hat{p}_{MoM} = \frac{T_{per}}{n} \xrightarrow{cs} p
  \]
  
  Luego, como $\hat{\theta}_{MoM}$ es una función continua de $\hat{p}_{MoM}$:
  
  \[
  \hat{\theta}_{MoM} \xrightarrow{cs} \frac{p + S_{p}-1}{S_{e}+S_{p}-1} = \theta
  \]
  
  Por lo tanto, $\hat{\theta}_{MoM}$ es fuertemente consistente.

---

## 2.1.6 Comparación ECM: Test perfecto vs imperfecto

### Fórmulas
\[
\text{ECM}_{\text{perfecto}} = \frac{\theta(1-\theta)}{n}
\]
\[
\text{ECM}_{\text{imperfecto}} = \frac{p(1-p)}{n(S_e+S_p-1)^2}
\]

### Factor de aumento
\[
\boxed{\frac{1}{(S_e+S_p-1)^2}}
\]

### Para $S_e=0.9$, $S_p=0.95$
\[
S_e+S_p-1 = 0.85 \Rightarrow \frac{1}{0.85^2} \approx 1.38
\]
**ECM 38% mayor** con test imperfecto

---

## Comportamiento en función de $n$

```{r, echo=FALSE, fig.height=4.5}
tita <- 0.25
Se <- 0.9
Sp <- 0.95
p <- (Se + Sp - 1)*tita + (1 - Sp)
ns <- 10:1000

ECM_perfecto <- tita*(1 - tita) / ns
ECM_imperfecto <- p*(1 - p) / (ns * (Se + Sp - 1)^2)

plot(ns, ECM_imperfecto, type="l", col="orange", lwd=2,
     xlab="Tamaño muestral (n)", ylab="ECM",
     main="ECM vs n: Comparación entre tests")
lines(ns, ECM_perfecto, col="blue", lwd=2)

legend("topright", legend=c("Test imperfecto", "Test perfecto"),
       col=c("orange", "blue"), lwd=2, cex=0.9)

```

---

## Conclusiones clave

### Observaciones del gráfico
1. **ECM imperfecto > ECM perfecto** para todo $n$
2. Ambas **decrecen** como $1/n$

---

## 2.1.7 Validación: Teórico vs Simulado

### Diseño de simulación
- $R = 10000$ réplicas
- $n \in \{10, 20, 50, 100, 200\}$
- $\theta = 0.25$, $S_e = 0.9$, $S_p = 0.95$
- Estimador: $\hat{\theta}_{MoM}$

### Valores teóricos
\[
\operatorname{Var}_{\text{teórica}} = \frac{p(1-p)}{n(S_e+S_p-1)^2}
\]
\[
\text{ECM}_{\text{teórico}} = \operatorname{Var}_{\text{teórica}} \quad (\text{sesgo}=0)
\]

---

## Sesgo: Simulado vs Teórico (=0)

```{r, echo=FALSE, fig.height=4}
# Código adaptado para mostrar solo el gráfico
tita <- 0.25
Se <- 0.9
Sp <- 0.95
ns <- c(10, 20, 50, 100, 200)
R <- 10000

resultados <- data.frame(n = ns, bias_sim = NA)

for (i in seq_along(ns)) {
  n <- ns[i]
  p_Y <- Se*tita + (1 - Sp)*(1 - tita)
  est_imp <- numeric(R)
  
  for (r in 1:R) {
    T <- rbinom(n, 1, p_Y)
    p_hat <- mean(T)
    est_imp[r] <- (p_hat - (1 - Sp)) / (Se + Sp - 1)
  }
  resultados$bias_sim[i] <- mean(est_imp) - tita
}

plot(resultados$n, resultados$bias_sim, type="b", pch=19,
     xlab="n", ylab="Sesgo",
     main="Sesgo: Simulado vs Teórico",
     ylim=range(resultados$bias_sim))
abline(h = 0, col="blue", lwd=2, lty=2)
legend("topright", legend=c("Sesgo sim.", "Sesgo teórico (0)"),
       col=c("black","blue"), pch=c(19, NA), lty=c(1,2))
```

---

## Varianza: Simulado vs Teórica

```{r, echo=FALSE, fig.height=4}
# Cálculos para varianza
var_teo <- numeric(length(ns))
var_sim <- numeric(length(ns))

for (i in seq_along(ns)) {
  n <- ns[i]
  p_Y <- Se*tita + (1 - Sp)*(1 - tita)
  est_imp <- numeric(R)
  
  for (r in 1:R) {
    T <- rbinom(n, 1, p_Y)
    p_hat <- mean(T)
    est_imp[r] <- (p_hat - (1 - Sp)) / (Se + Sp - 1)
  }
  var_sim[i] <- var(est_imp)
  var_teo[i] <- (p_Y*(1 - p_Y)) / (n * (Se + Sp - 1)^2)
}

plot(ns, var_sim, type="b", pch=19, xlab="n", ylab="Varianza",
     main="Varianza: Simulado vs Teórica",
     ylim=c(0, max(var_sim, var_teo)))
lines(ns, var_teo, type="b", pch=17, col="blue")
legend("topright", legend=c("Var sim.", "Var teórica"),
       col=c("black","blue"), pch=c(19,17))
```

---

## ECM: Simulado vs Teórico

```{r, echo=FALSE, fig.height=4}

# Cálculos para varianza
var_teo <- numeric(length(ns))
var_sim <- numeric(length(ns))

for (i in seq_along(ns)) {
  n <- ns[i]
  p_Y <- Se*tita + (1 - Sp)*(1 - tita)
  est_imp <- numeric(R)
  
  for (r in 1:R) {
    T <- rbinom(n, 1, p_Y)
    p_hat <- mean(T)
    est_imp[r] <- (p_hat - (1 - Sp)) / (Se + Sp - 1)
  }
  var_sim[i] <- var(est_imp)
  var_teo[i] <- (p_Y*(1 - p_Y)) / (n * (Se + Sp - 1)^2)
}

plot(ns, var_sim, type="b", pch=19, xlab="n", ylab="Varianza",
     main="Varianza: Simulado vs Teórica",
     ylim=c(0, max(var_sim, var_teo)))
lines(ns, var_teo, type="b", pch=17, col="blue")
legend("topright", legend=c("Var sim.", "Var teórica"),
       col=c("black","blue"), pch=c(19,17))

```


---

## Conclusiones de la validación

### Confirmaciones
1. **Sesgo aprox 0** en simulación → Insesgabilidad verificada
2. **Varianza simulada aprox Varianza teórica** para todo $n$
3. **ECM simulada aprox ECM teórico** → Fórmulas correctas

### Comportamiento observado
- **Convergencia**: A mayor $n$, mejor ajuste entre lo simulado y lo teorico
- **Consistencia**: Var/ECM decrecen como $1/n$
- **Robustez**: Fórmulas teóricas válidas aún para $n$ pequeño

### Implicaciones
- **Expresiones teóricas** son confiables
- **Estimador MoM** se comporta según la teoría
- **Simulación** valida aproximaciones asintóticas
  
---

## 2.1.8 Bootstrap para $\hat{\theta}_{MoM}$ ($n=10$)

### Parámetros
- $\theta = 0.25$, $S_e = 0.9$, $S_p = 0.95$
- $n = 10$, $B = 5000$ réplicas bootstrap
- Bootstrap no paramétrico

### Método
1. Muestra original: $T_i \sim \text{Bernoulli}(p)$
2. Remuestreo con reemplazo
3. Recalcular $\hat{\theta}_{MoM}$ en cada réplica

---

## Distribución bootstrap ($n=10$)

```{r, echo=FALSE, fig.height=4.5}
tita <- 0.25
Se <- 0.9
Sp <- 0.95
n <- 10
B <- 5000

# Probabilidad real
p_Y <- Se * tita + (1 - Sp) * (1 - tita)

# Muestra original
set.seed(123)  # Para reproducibilidad
T_original <- rbinom(n, 1, p_Y)

# Bootstrap
boot_est <- numeric(B)
for (b in 1:B) {
  T_boot <- sample(T_original, size = n, replace = TRUE)
  p_hat_boot <- mean(T_boot)
  boot_est[b] <- (p_hat_boot - (1 - Sp)) / (Se + Sp - 1)
}

# Histograma
hist(boot_est, breaks = 15, freq = TRUE, col = "lightblue",
     main = "Distribución bootstrap - n = 10",
     xlab = expression(hat(theta)["MoM"]), 
     ylab = "Frecuencia", border = "darkblue")
abline(v = tita, col = "red", lwd = 3, lty = 2)
abline(v = mean(boot_est), col = "darkgreen", lwd = 2, lty = 2)
legend("topright", legend = c(expression(theta*" verdadero"), "Media bootstrap"),
       col = c("red", "darkgreen"), lwd = c(3, 2), lty = c(2, 2), cex = 0.8)
```

---

## Resultados bootstrap

### Estadísticas clave
\[
\text{Media bootstrap} = `r round(mean(boot_est), 4)`
\]
\[
\text{Sesgo bootstrap} = `r round(mean(boot_est) - tita, 4)`
\]
\[
\text{Desvío bootstrap} = `r round(sd(boot_est), 4)`
\]

### Características observadas
1. **Alta dispersión** (gran variabilidad)
2. **Sesgo positivo** 
3. **Distribución asimétrica** hacia derecha
4. **Valores fuera de [0,1]** posibles
5. Se recomienda aumentar $n$ (mas centrado al valor real y disminuir var)

---

## 2.2.9 Intervalos de confianza bootstrap

\vspace{0.5cm}

### Objetivo
Construir intervalos de confianza para $\theta$ basados en el estimador de momentos utilizando bootstrap no paramétrico.

### Método
- A partir de los datos ${T_i}$, se calcula $\hat\theta_{MoM}$ en cada remuestreo.

\vspace{0.2cm}

- Se generan $B = 1000$ réplicas bootstrap:  
  $\hat\theta^{*(b)}_{MoM}$, $b = 1,\dots,B$.
  
\vspace{0.2cm}
  
- Intervalo bootstrap percentil:

\[
IC^{boot}_{0.95} = 
\big[\, Q_{0.025}(\hat\theta^{*}),\; Q_{0.975}(\hat\theta^{*}) \,\big].
\]

---

### Simulación Monte Carlo
- Replicaciones: $R = 700$.
- Tamaños muestrales: $n \in \{10, 20, 50, 100, 1000\}$.
- Para cada réplica se obtiene:
  - **Cubrimiento empírico**: $1\{\theta \in IC^{boot}\}$
  - **Longitud**: $IC^{up} - IC^{low}$

```{r, echo = FALSE}

tita_corregida <- function(p_hat, Se, Sp) {
  (p_hat - (1 - Sp)) / (Se + Sp - 1)
}

#Definimos los valores a utilizar.
tita <- 0.25
Se <- 0.9
Sp <- 0.95
p_Y <- Se * tita + (1 - Sp) * (1 - tita)

ns <-  c(10, 20, 50, 100, 1000)
R <- 700 #replicas Monte Carlo
B <- 1000 #remuestreos bootstrap

z <- qnorm(0.975)

res_list <- vector("list",length(ns))
names(res_list) <- as.character(ns)

#para cada n:
for (j in seq_along(ns)){
  n <- ns[j]
  cubrimientos <- logical(R)
  longitudes <- numeric(R)
  
  #repito el experimento R veces 
  for (r in 1:R){
     T <- rbinom(n,1,p_Y)
     boot_est <- numeric(B)
     
     #genero B muestras bootstrap.
     for (b in 1:B){
       T_boot <- sample(T, size = n, replace = TRUE)
       p_hat_boot <- mean(T_boot)
       boot_est[b] <- tita_corregida(p_hat_boot, Se, Sp)
     }
     
     lower <- quantile(boot_est, probs = 0.025, names = FALSE)
     upper <- quantile(boot_est, probs = 0.975, names = FALSE)
     
     cubrimientos[r] <- (lower <= tita) && (tita <= upper)
     longitudes[r] <- (upper - lower)
  }
  
  #resultados para cada n
  res_list[[j]] <- list(
    n = n,
    cubrimiento = mean(cubrimientos),
    longitud_media = mean(longitudes)
  )
   
}

res_df <- do.call(rbind, lapply(res_list, function(z){
  data.frame(n = z$n,
             cubrimiento = z$cubrimiento,
             longitud_media = z$longitud_media)
}))
rownames(res_df) <- NULL
```

---
  
## 2.2.10 Intervalo de confianza asintótico
  
Recordemos que: 
  
* $\hat{p}_{MoM} = \frac{T_{per}}{n}$
\vspace{0.1cm}
* $\mathbb{E}[\hat{p}_{MoM}] = p$
\vspace{0.1cm}
* $\operatorname{Var}[\hat{p}_{MoM}] = \frac{p(1-p)}{n}$
\vspace{0.1cm}
* $\hat{\theta}_{MoM} = \frac{\hat{p}_{MoM} + S_{p} - 1}{S_{e}+S_{p}-1}$
\vspace{0.1cm}
* $\mathbb{E}[\hat{\theta}_{MoM}] = \theta$
\vspace{0.1cm}
* $\operatorname{Var}[\hat{\theta}_{MoM}] = \frac{p(1-p)}{n(S_{e}+S_{p}-1)^2}$
  
---
  
* Entonces por TCL:
  
\[
\sqrt{n} (\hat{p}_{MoM} - p) \xrightarrow{D}  N\bigl(0,(p(1-p))\bigr)
\]
  
Defino $g(x) = \frac{x+S_{p}-1}{S_{e}+S_{p}-1}$ y $g'(x) = \frac{1}{S_{e} + S_{p} -1}$. Notar que $g(x)$ es $C^1$.
  
\vspace{0.2cm}

* Por Método Delta:
  
\[
\sqrt{n}(g(\hat{p}_{MoM}) - g(p)) \xrightarrow{D} N\bigl(0, \frac{p(1-p)}{(S_{e}+S_{p}-1)^2}\bigr)
\]

---

Luego,
  
\[
\frac{\hat{\theta}_{MoM}-\theta}{\sqrt{\operatorname{Var}[\hat{\theta}_{MoM}]}} \xrightarrow{D} N\bigl(0,1\bigr)
\]
  
  
* Además $\hat{p}_{MoM} = \frac{T_{per}}{n} \xrightarrow{cs} p$, entonces: 
  
\[ 
\sqrt{\frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{p(1-p)}} \xrightarrow{P} 1 
\]
  
debido a que $h(x)= \sqrt{\frac{x(1-x)}{p(1-p)}}$ es continua en $(0,1)$.
  
---
  
Si $\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}] =\frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{n(S_{e}+S_{p}-1)^2}$, usando teorema de Slutsky:
  
\[
\frac{\hat{\theta}_{MoM} - \theta}{\sqrt{\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}]}} = \frac{\hat{\theta}_{MoM} - \theta}{\sqrt{\operatorname{Var}[\hat{\theta}_{MoM}]}\sqrt{\frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{p(1-p)}}} \xrightarrow{D}  N\bigl(0,1\bigr)
\]
  
  
* Por lo tanto, se deduce el siguiente intervalo de nivel asintótico $0.95$:
  
\[
\boxed{IC^{\theta}_{0.95} = \hat{\theta}_{MoM}\pm 1.96\sqrt{\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}]}}
\]
  
donde $\widehat{\operatorname{Var}}[\hat{\theta}_{MoM}] = \frac{\hat{p}_{MoM}(1-\hat{p}_{MoM})}{n(S_{e}+S_{p}-1)^2}$

```{r, echo=FALSE}
res_listAsint <- vector("list", length(ns))
names(res_listAsint) <- as.character(ns)

#para cada n:
for (j in seq_along(ns)){
  n <- ns[j]
  cubrimientos <- logical(R)
  longitudes <- numeric(R)
  
  #repito el experimento R veces.
  for (r in 1:R){
    T <- rbinom(n, 1, p_Y)
    
    p_hat <- mean(T)
    tita_hat <- tita_corregida(p_hat,Se,Sp)
    est_Var <- (p_hat*(1-p_hat))/(n*(Se+Sp-1)^2)
    
    termino <- z*sqrt(est_Var)
    lower <- tita_hat - termino
    upper <- tita_hat + termino
    
    cubrimientos[r] <- (lower <= tita) && (tita <= upper)
    longitudes[r] <- (upper - lower)
  }
  
  #resultados para cada n.
  res_listAsint[[j]] <- list(
    n = n,
    cubrimiento = mean(cubrimientos),
    longitud_media = mean(longitudes)
  )
}

resAsint_df <- do.call(rbind, lapply(res_listAsint, function(z){
  data.frame(n = z$n,
             cubrimiento = z$cubrimiento,
             longitud_media = z$longitud_media)
}))
rownames(resAsint_df) <- NULL
```

---

## 2.2.11 Comparación entre ambos intervalos

Luego de realizar las simulaciones pertinentes, comparemos los resultados obtenidos.

```{r, echo=FALSE, eval=TRUE}
knitr::kable(res_df, digits = 4, caption = "Bootstrap Percentil")
```

---

```{r, echo=FALSE, eval=TRUE}
knitr::kable(resAsint_df, digits = 4, caption = "Intervalos Asintóticos")
```

---

* El bootstrap parece ser más robusto en muestras pequeñas, lo cual es esperable porque no depende de aproximaciones normales ni del método delta.

\vspace{0.3cm}

* El método asintótico da intervalos ligeramente más largos.

\vspace{0.3cm}

* A medida que aumenta $n$ los resultados convergen a los valores esperados.

---

## 2.3.12 Comportamiento del estimador de momentos

## El estimador puede quedar fuera de $[0,1]$

Recordemos el estimador de momentos:
\[
\hat{\theta}_{MoM} = \frac{\hat{p} + Sp - 1}{Se + Sp - 1}.
\]

- La prevalencia verdadera satisface:
  \[
  0 \le \theta \le 1.
  \]

- Sin embargo, **el estimador $\hat{\theta}_{MoM}$ NO necesariamente cumple**  
  \[
  0 \le \hat{\theta}_{MoM} \le 1.
  \]

---

### ¿Por qué ocurre esto?

- Porque $\hat{p}$ es una proporción muestral sujeta a variabilidad.
- Cuando la muestra es pequeña o el test es poco informativo  
  ($Se + Sp - 1$ cercano a 0), la fórmula puede devolver:
  - valores **negativos**, o
  - valores **mayores a 1**.

### Consecuencia

- Aparece la necesidad de un **estimador truncado** para garantizar valores válidos.

---

## Casos típicos

1. **$\hat{p}$ muy bajo** pero el test tiene muchos falsos positivos  
   $\rightarrow$ el numerador puede volverse negativo.

2. **$\hat{p}$ muy alto** pero el test tiene baja sensibilidad  
   $\rightarrow$ el estimador puede superar 1.

3. **Muestras pequeñas ($n$ chico)**  
   $\rightarrow$ mayor variabilidad en $\hat{p}$ $\rightarrow$ más frecuencias fuera de $[0,1]$.

4. **Test débil** ($Se + Sp - 1$ pequeño):  
   $\rightarrow$ divide por un número muy chico $\rightarrow$ el estimador “explota”.
   
---

# Ejemplo concreto

Supongamos un test con:

- $Se = 0.90$
- $Sp = 0.95$

Entonces:

\[
Se + Sp - 1 = 0.90 + 0.95 - 1 = 0.85.
\]

Tomemos una muestra donde la proporción de tests positivos es muy baja:

\[
\hat{p} = 0.02.
\]

Calculemos el estimador de momentos:

\[
\hat{\theta}_{MoM}
= \frac{\hat{p} + Sp - 1}{Se + Sp - 1}
= \frac{0.02 + 0.95 - 1}{0.85}
= \frac{-0.03}{0.85}
\approx -0.035.
\]

---

### Interpretación

- La prevalencia **no puede ser negativa**, pero el estimador de momentos sí puede producir valores $< 0$.
- Esto sucede porque $\hat{p}$ es muy bajo y el test genera falsos positivos.
- **Motiva el uso del estimador truncado**, que en este caso devolvería:

\[
\hat{\theta}_{trunc} = 0.
\]

---

## 2.3.13 Estudio del estimador truncado

## Definición del estimador truncado

\[
\hat{\theta}_{trunc} =
\begin{cases}
\hat{\theta}_{MoM}, & 0 \le \hat{\theta}_{MoM} \le 1,\\[4pt]
0, & \hat{\theta}_{MoM} < 0,\\[4pt]
1, & \hat{\theta}_{MoM} > 1.
\end{cases}
\]

Este estimador **siempre produce valores válidos**.

---

## Queremos estudiar, para $n = 10, 100, 1000$:

1. **Sesgo** de $\hat{\theta}_{trunc}$
2. **Varianza**
3. **ECM**
4. **Distribución aproximada**

## Parámetros usados

- $\theta = 0.25$
- $Se = 0.90$
- $Sp = 0.95$

Simulamos $N_{rep}$ réplicas (típicamente 10,000).

---

```{r, echo=FALSE}
# Parámetros
theta_verdadera <- 0.25
Se_fijo         <- 0.9
Sp_fijo         <- 0.95

# Probabilidad verdadera de test positivo bajo el modelo
p_verdadera <- Se_fijo * theta_verdadera + (1 - Sp_fijo) * (1 - theta_verdadera)

# Número de réplicas para Monte Carlo
N_rep <- 10000


# Funciones para los estimadores

# Estimador de momentos de theta
theta_mom <- function(T_obs, n, Se = Se_fijo, Sp = Sp_fijo) {
  p_muestral <- T_obs / n
  theta_mom_est <- (p_muestral + Sp - 1) / (Se + Sp - 1)
  return(theta_mom_est)
}

# Estimador truncado de theta
theta_trunc <- function(T_obs, n, Se = Se_fijo, Sp = Sp_fijo) {
  theta_mom_est <- theta_mom(T_obs, n, Se, Sp)
  theta_trunc_est <- pmin(1, pmax(0, theta_mom_est))
  return(theta_trunc_est)
}

## Tamaños muestrales a estudiar
n_valores <- c(10, 100, 1000)

## Data frame para almacenar resultados
resultados <- data.frame(
  n     = n_valores,
  media = NA_real_,
  sesgo = NA_real_,
  var   = NA_real_,
  ECM   = NA_real_
)

for (i in seq_along(n_valores)) {
  n <- n_valores[i]
  # Simular T_obs ~ Binomial(n, p_verdadera) N_rep veces
  T_sim <- rbinom(N_rep, size = n, prob = p_verdadera)
  # Estimaciones truncadas
  theta_trunc_sim <- theta_trunc(T_sim, n)
  # media
  media_hat <- mean(theta_trunc_sim)
  # sesgo
  sesgo_hat <- media_hat - theta_verdadera
  # varianza
  var_hat <- var(theta_trunc_sim)
  # ECM
  ECM_hat <- mean((theta_trunc_sim - theta_verdadera)^2)
  
  # resultados
  resultados$media[i] <- media_hat
  resultados$sesgo[i] <- sesgo_hat
  resultados$var[i]   <- var_hat
  resultados$ECM[i]   <- ECM_hat
}

```

## Resultados

Se obtiene lo siguiente:
```{r}
knitr::kable(resultados, digits = 9, caption = "Resultados")
```

---

De esta forma, se observa lo siguiente:

- $\underline{\text{Sesgo:}}$
Para $n=10$ el estimador presenta un sesgo notable. Esto se debe a que el estimador de momentos frecuentemente cae por debajo de $0$ y es truncado a cero, lo cual desplaza el valor medio del estimador hacia la región central del intervalo. A medida que el tamaño muestral aumenta, la frecuencia de truncamientos disminuye y el sesgo se aproxima a cero. En consecuencia, el estimador truncado es asintóticamente insesgado.


- $\underline{\text{Varianza:}}$
La varianza disminuye al crecer $n$, como es esperable para un estimador consistente. Para $n=10$ la varianza es elevada debido a la alta variabilidad de $\hat p$, mientras que para $n=1000$ el estimador muestra muy poca dispersión.

---

- $\underline{\text{Error cuadrático medio:}}$
El ECM refleja el compromiso entre sesgo y varianza:
\[
ECM = \operatorname{Sesgo}^2 + \operatorname{Var}.
\]
Para tamaños muestrales pequeños, el ECM se ve afectado tanto por el sesgo inducido por el truncamiento como por la alta varianza. Para tamaños muestrales grandes, el ECM resulta muy pequeño, consistente con la convergencia del estimador.

---

- $\underline{\text{Distribución asintótica:}}$
observemos los siguientes gráficos para la distribución asintótica:

```{r, echo=FALSE}
set.seed(43)

par(mfrow = c(2, 2))  ## grid para los gráficos

for (n in n_valores) {
  # nueva data para cada n
  T_sim <- rbinom(N_rep, size = n, prob = p_verdadera)
  theta_trunc_sim <- theta_trunc(T_sim, n)
  
  # Histograma
  hist(theta_trunc_sim,
       breaks = 40,
       main = paste("Histograma de theta_trunc, n =", n),
       xlab = expression(hat(theta)[trunc]),
       probability = TRUE)
  
  media_hat <- mean(theta_trunc_sim)
  sd_hat    <- sd(theta_trunc_sim)
  x_grid    <- seq(0, 1, length.out = 200)
  lines(x_grid, dnorm(x_grid, mean = media_hat, sd = sd_hat), col = "red")
}

par(mfrow = c(1, 1))

n <- 1000
T_sim <- rbinom(N_rep, size = n, prob = p_verdadera)
theta_trunc_sim <- theta_trunc(T_sim, n)
```

---

```{r, echo=FALSE}
qqnorm(theta_trunc_sim,
       main = expression(paste("QQ-plot de ", hat(theta)[trunc], " para n=1000")),
       xlab= "",
       ylab= "")
qqline(theta_trunc_sim)

```

---

Para $n$ pequeños, la distribución empírica de $\hat\theta_{\text{trunc}}$ muestra acumulación de masa en los puntos $0$ y $1$, debido al truncamiento. Por ello, la distribución no es aproximadamente normal. Sin embargo, para $n$ grandes el truncamiento ocurre con probabilidad prácticamente nula, y la distribución empírica se aproxima bien a una normal, coincidiendo en este caso con la distribución asintótica del estimador de momentos no truncado.

Para finalizar, estos resultados,  en conjunto, muestran que el truncamiento introduce sesgo en muestras pequeñas, pero el estimador es asintóticamente equivalente al estimador de momentos original, preservando sus propiedades cuando $n$ es grande.

---

\centering
\vspace{2cm}
\Huge
**Parte III**  
\Large
Dos muestras (pre-post intervención)

---

* En esta sección analizamos si la prevalencia verdadera de la enfermedad cambió después de implementar una campaña de vacunación. Para ello se toman dos muestras independientes:

- Una **antes** de la campaña, de tamaño \( n_{\text{pre}} \), con número de test positivos \( X_{\text{pre}} \).
- Otra **después**, de tamaño \( n_{\text{post}} \), con número de test positivos \( X_{\text{post}} \).

En ambos casos se utiliza el mismo test diagnóstico imperfecto, caracterizado por su **sensibilidad** \( Se \) y **especificidad** \( Sp \).

---

* Los conteos observados siguen:
\[
X_{\text{pre}} \sim \text{Binomial}(n_{\text{pre}}, p_{\text{pre}}), \quad 
X_{\text{post}} \sim \text{Binomial}(n_{\text{post}}, p_{\text{post}})
\]
donde  
\[
p_A = (Se + Sp - 1)\theta_A + (1 - Sp), \qquad A \in \{\text{pre}, \text{post}\}
\]

* Nuestro objetivo es inferir la **diferencia de prevalencias verdaderas**:
\[
\boxed{\Delta = \theta_{\text{post}} - \theta_{\text{pre}}}
\]

---

## 3.1.1 Test de Hipótesis

Se quiere plantear un test de nivel aproximado $0.05$ para las siguientes hipótesis, basándose en el estimador $\hat{\theta}_{MoM}$:

\[
H_{0} : \Delta = 0 \quad \text{vs.} \quad H_{1} : \Delta \neq 0
\]

---

Tenemos:

\[
\hat{\theta}_{post} = \frac{\hat{p}_{post} + S_{p} - 1}{S_{e}+S_{p}-1} \quad \text{y} \quad \hat{\theta}_{pre} = \frac{\hat{p}_{pre} + S_{p} - 1}{S_{e}+S_{p}-1}
\]

Y por el item $2.1.10$, se deduce que:

\[
\hat{\theta}_{post} \approx N\bigl(\theta_{post},\; \widehat{\operatorname{Var}}(\hat{\theta}_{post})\bigr)
\quad\text{y}\quad
\hat{\theta}_{pre} \approx N\bigl(\theta_{pre},\; \widehat{\operatorname{Var}}(\hat{\theta}_{pre})\bigr)
\]

---

\[
\Rightarrow\quad
\hat{\theta}_{post} - \hat{\theta}_{pre}
\approx
N\!\Bigl(\theta_{post}-\theta_{pre},\; \widehat{\operatorname{Var}}(\hat{\theta}_{post}) + \widehat{\operatorname{Var}}(\hat{\theta}_{pre})\Bigr)
\]

\[
U_{\Delta}(X_{pre},X_{post})
=
\frac{\hat{\theta}_{post} - \hat{\theta}_{pre} - \Delta}
     {\sqrt{\widehat{\operatorname{Var}}(\hat{\theta}_{post}) + \widehat{\operatorname{Var}}(\hat{\theta}_{pre})}}
\approx N(0,1)
\]


* Tenemos un pivote decreciente en $\Delta$ con distribución aproximada conocida independiente de $\Delta$. Entonces, utilizando método del pivote, resulta el siguiente test de nivel aproximado 0.05.

\[
\Phi(X_{pre},X_{post}) =
\begin{cases}
1 & \text{si } \bigl|U_{0}(X_{pre},X_{post})\bigr| > z_{1-\alpha/2} = z_{0.975} \approx 1.96, \\
0 & \text{c.c.}
\end{cases}
\]

---

## 3.1.2 Aplicación en caso ficticio

Vamos a aplicar el test dado en el item anterior a un caso ficticio con $n_{pre} = n_{post} = 100$, $S_{e} = 0.9$, $S_{p} = 0.95$, $\theta_{pre} = 0.2$, $\theta_{post} = 0.15$ y $\alpha = 0.05$.

---

* El estadístico observado tiene el siguiente valor:

```{r, echo=FALSE, eval=TRUE}
# Definimos valores y calculamos U (sin mostrar código)
n_pre <- 100
n_post <- 100
Se <- 0.9
Sp <- 0.95
tita_pre <- 0.2
tita_post <- 0.15

p_pre <- (Se + Sp - 1)* tita_pre + (1 - Sp)
p_post <- (Se + Sp - 1)* tita_post + (1 - Sp)

set.seed(123)  # Para reproducibilidad
Xpre <- rbinom(n_pre, 1, p_pre)
Xpost <- rbinom(n_post, 1, p_post)

p_preHat <- mean(Xpre)
p_postHat <- mean(Xpost)

tita_preHat <- (p_preHat + Sp - 1)/(Se + Sp - 1)
tita_postHat <- (p_postHat + Sp - 1)/(Se + Sp - 1)

Var_preHat <- (p_preHat*(1-p_preHat))/(n_pre*(Se+Sp-1)^2)
Var_postHat <- (p_postHat*(1-p_postHat))/(n_post*(Se+Sp-1)^2)

U <- (tita_postHat - tita_preHat)/(sqrt(Var_postHat + Var_preHat))

cat("U =", round(U, 4))
```

Por lo tanto, no hay evidencia suficiente como para rechazar $H_{0}$ a nivel aproximado 0.05. Esto quiere decir que no se afirma que la vacuna es realmente efectiva. Es razonable porque la diferencia real entre prevalencias es pequeña ($0.05$).

---

* ¿Qué pasa si achicamos la muestra? 

- Para $n = 50$, obtenemos el siguiente resultado:

```{r, echo=FALSE, eval=TRUE}
n_pre <- 50
n_post <- 50

set.seed(123)
Xpre <- rbinom(n_pre, 1, p_pre)
Xpost <- rbinom(n_post, 1, p_post)

p_preHat <- mean(Xpre)
p_postHat <- mean(Xpost)

tita_preHat <- (p_preHat + Sp - 1)/(Se + Sp - 1)
tita_postHat <- (p_postHat + Sp - 1)/(Se + Sp - 1)

Var_preHat <- (p_preHat*(1-p_preHat))/(n_pre*(Se+Sp-1)^2)
Var_postHat <- (p_postHat*(1-p_postHat))/(n_post*(Se+Sp-1)^2)

U50 <- (tita_postHat - tita_preHat)/(sqrt(Var_postHat + Var_preHat))

cat("U (n=50) =", round(U50, 4))
```

El valor del estadístico observado sigue estando en la región de aceptación. Igualmente, al haber menos muestras la varianza aumenta y el resultado es distinto de 0.

- Para $n = 10$, obtenemos el siguiente resultado:

```{r, echo=FALSE, eval=TRUE}
n_pre <- 10
n_post <- 10

set.seed(123)
Xpre <- rbinom(n_pre, 1, p_pre)
Xpost <- rbinom(n_post, 1, p_post)

p_preHat <- mean(Xpre)
p_postHat <- mean(Xpost)

tita_preHat <- (p_preHat + Sp - 1)/(Se + Sp - 1)
tita_postHat <- (p_postHat + Sp - 1)/(Se + Sp - 1)

Var_preHat <- (p_preHat*(1-p_preHat))/(n_pre*(Se+Sp-1)^2)
Var_postHat <- (p_postHat*(1-p_postHat))/(n_post*(Se+Sp-1)^2)

U10 <- (tita_postHat - tita_preHat)/(sqrt(Var_postHat + Var_preHat))

cat("U (n=10) =", round(U10, 4))
```

Para una muestra tan pequeña el test se vuelve inestable y es practicamente inútil, ya que nuetsro test es de nivel asintótico.

---

## 3.1.3 Intervalo de confianza de nivel asintotico 0.95 para $\Delta$

Usamos el estimador de momentos (no truncado):

\[
\hat\theta_A \;=\; \frac{\hat p_A + (Sp - 1)}{Se + Sp - 1}, 
\qquad A \in \{\text{pre}, \text{post}\},
\]

donde \(\hat p_A = X_A / n_A\) y \(X_A\) es el número de tests positivos observados.


El pivote utilizado es:

\[
Z \;=\; 
\frac{
\widehat{\Delta} - \Delta
}{
\sqrt{
\widehat{Var}(\hat\theta_{\text{post}}) +
\widehat{Var}(\hat\theta_{\text{pre}})
}
},
\]

el cual tiene distribución aproximada \(N(0,1)\).

---

El intervalo de confianza asintótico al 95% para la diferencia

\[
\Delta = \theta_{\text{post}} - \theta_{\text{pre}}
\]

es

\[
\widehat{\Delta} \;\pm\;
1.96 \sqrt{
\widehat{Var}(\hat\theta_{\text{post}}) +
\widehat{Var}(\hat\theta_{\text{pre}})
}.
\]

donde \(\widehat{\Delta} = \hat\theta_{\text{post}} - \hat\theta_{\text{pre}}\).

```{r, echo=FALSE, eval=TRUE}

# Estimador de Delta y su desvío estándar
DeltaHat <- tita_postHat - tita_preHat
se_Delta <- sqrt(Var_preHat + Var_postHat)

# Intervalo asintotico 95%
z <- qnorm(0.975)
IC_lower <- DeltaHat - z * se_Delta
IC_upper <- DeltaHat + z * se_Delta

cat("DeltaHat =", round(DeltaHat, 4), "\n")
cat("IC 95% para Delta: [", round(IC_lower, 4), ",", round(IC_upper, 4), "]\n")

```

El intervalo calculado fue:

\[
IC_{95\%}(\Delta)
=
[-0.3259,\; 0.5612].
\]

---

### Observaciones

- **Incluye al 0**, no hay evidencia suficiente para decir que hay un cambio real entre pre y post. 
- **Intervalo bastante ancho**, hay alta incertidumbre.
- **Limite superior es bastante grande** puede haber aumento grande entre pre y post.
- **Limite inferior negativo**, tambien puede haber una disminucion moderada.

---

## 3.1.4 Nivel empírico del test.

Se quiere calcular el nivel empírico del test dado en $3.1.2$. Para ello, se define una grilla de valores de $n$ para calcular el nivel para cada valor. Se sabe que el nivel de un test está definido por el supremo de los errores de tipo 1. Entonces, también se define una grilla de valores de $\theta$ y se realizan las simulaciones pertinentes.

```{r, echo=FALSE}
#Definimos los valores a utilizar.
Nrep <- 2000
ns <- c(10, 20, 50, 100, 1000, 10000)
alpha <- 0.05
Se <- 0.9
Sp <- 0.95
z <- qnorm(0.975)

# Como queremos nivel, definimos prevalencias iguales para pre y post (H0 delta = 0).
#Además queremos el supremo de los errores de tipo 1, entonces hay que variar tita.
grid_tita <- seq(0.01, 0.99, length.out = 20)
  

#Vector que va a tener el nivel empírico para cada n.
nivelN <- numeric(length(ns))


#para cada n:
for (r in seq_along(ns)){
  n <- ns[r]
  
  #vector que va a tener error de tipo 1 para cada tita.
  errorTipo1 <- numeric(length(grid_tita))
  
  #para cada tita:
  for (j in seq_along(grid_tita)){
    tita <- grid_tita[j]
    p <- (Se + Sp - 1)* tita + (1 - Sp)
    
    #vector que va a tener si rechazo o no el test en cada pos.
    rechazos <- numeric(Nrep)
    
    #repito el experimento Nrep veces:
    for(i in 1:Nrep){                                        
      Xpre <- rbinom(n,1,p)
      Xpost <- rbinom(n,1,p)
      
      #Ahora calculamos U(Xpre, Xpost):
      p_preHat <- mean(Xpre)
      p_postHat <- mean(Xpost)
      
      tita_preHat <- (p_preHat + Sp - 1)/(Se + Sp - 1)
      tita_postHat <- (p_postHat + Sp - 1)/(Se + Sp - 1)
      
      Var_preHat <- (p_preHat*(1-p_preHat))/(n*(Se+Sp-1)^2)
      Var_postHat <- (p_postHat*(1-p_postHat))/(n*(Se+Sp-1)^2)
      
      U <- (tita_postHat - tita_preHat)/(sqrt(Var_postHat + Var_preHat)) 
      
      #rechazo o no H0.
      rechazos[i] <- abs(U) > z
    }
    
    #proporción de rechazos.(ignoro nan en caso de que el p estimado sea 0 o 1 
    #pues sucede un div por 0)
    errorTipo1[j] <- mean(rechazos, na.rm = TRUE)                    
    
  }
  
  nivelN[r] <- max(errorTipo1)
}

nivelEmpirico <- data.frame(n = ns, nivel = nivelN)

```

---

* Se obtuvieron los siguientes resultados:

```{r, echo=FALSE}
knitr::kable(nivelEmpirico, digits = 4, caption = "Nivel empírico del test")
```

Se observa claramente el comportamiento asintótico del test. A medida que aumenta n, el nivel del test se acerca a 0.05.